2025-05-29 19:16:35,605 - INFO - root - Hello! This is Joey-NMT (version 2.2.0).
2025-05-29 19:16:35,606 - INFO - joeynmt.helpers -                           cfg.name : transformer_bpe_2000
2025-05-29 19:16:35,606 - INFO - joeynmt.helpers -                cfg.joeynmt_version : 2.0.0
2025-05-29 19:16:35,606 - INFO - joeynmt.helpers -                  cfg.data.src.lang : it
2025-05-29 19:16:35,606 - INFO - joeynmt.helpers -                 cfg.data.src.level : bpe
2025-05-29 19:16:35,606 - INFO - joeynmt.helpers -             cfg.data.src.lowercase : False
2025-05-29 19:16:35,606 - INFO - joeynmt.helpers -       cfg.data.src.max_sent_length : 100
2025-05-29 19:16:35,606 - INFO - joeynmt.helpers -              cfg.data.src.voc_file : bpe/2000/2000.vocab
2025-05-29 19:16:35,606 - INFO - joeynmt.helpers -        cfg.data.src.tokenizer_type : subword-nmt
2025-05-29 19:16:35,606 - INFO - joeynmt.helpers -   cfg.data.src.tokenizer_cfg.codes : bpe/2000/codes.codes
2025-05-29 19:16:35,606 - INFO - joeynmt.helpers -                  cfg.data.trg.lang : de
2025-05-29 19:16:35,606 - INFO - joeynmt.helpers -                 cfg.data.trg.level : bpe
2025-05-29 19:16:35,606 - INFO - joeynmt.helpers -             cfg.data.trg.lowercase : False
2025-05-29 19:16:35,606 - INFO - joeynmt.helpers -       cfg.data.trg.max_sent_length : 100
2025-05-29 19:16:35,606 - INFO - joeynmt.helpers -              cfg.data.trg.voc_file : bpe/2000/2000.vocab
2025-05-29 19:16:35,606 - INFO - joeynmt.helpers -        cfg.data.trg.tokenizer_type : subword-nmt
2025-05-29 19:16:35,606 - INFO - joeynmt.helpers -   cfg.data.trg.tokenizer_cfg.codes : bpe/2000/codes.codes
2025-05-29 19:16:35,606 - INFO - joeynmt.helpers -                     cfg.data.train : scripts/data/train_100k.it-de
2025-05-29 19:16:35,606 - INFO - joeynmt.helpers -                       cfg.data.dev : scripts/data/dev.it-de
2025-05-29 19:16:35,606 - INFO - joeynmt.helpers -                      cfg.data.test : scripts/data/test.it-de
2025-05-29 19:16:35,606 - INFO - joeynmt.helpers -              cfg.data.dataset_type : plain
2025-05-29 19:16:35,606 - INFO - joeynmt.helpers -                 cfg.data.bpe_codes : bpe/2000/codes.codes
2025-05-29 19:16:35,606 - INFO - joeynmt.helpers - cfg.data.special_symbols.unk_token : <unk>
2025-05-29 19:16:35,606 - INFO - joeynmt.helpers -    cfg.data.special_symbols.unk_id : 0
2025-05-29 19:16:35,606 - INFO - joeynmt.helpers - cfg.data.special_symbols.pad_token : <pad>
2025-05-29 19:16:35,606 - INFO - joeynmt.helpers -    cfg.data.special_symbols.pad_id : 1
2025-05-29 19:16:35,607 - INFO - joeynmt.helpers - cfg.data.special_symbols.bos_token : <s>
2025-05-29 19:16:35,607 - INFO - joeynmt.helpers -    cfg.data.special_symbols.bos_id : 2
2025-05-29 19:16:35,607 - INFO - joeynmt.helpers - cfg.data.special_symbols.eos_token : </s>
2025-05-29 19:16:35,607 - INFO - joeynmt.helpers -    cfg.data.special_symbols.eos_id : 3
2025-05-29 19:16:35,607 - INFO - joeynmt.helpers -              cfg.testing.beam_size : 5
2025-05-29 19:16:35,607 - INFO - joeynmt.helpers -                  cfg.testing.alpha : 1.0
2025-05-29 19:16:35,607 - INFO - joeynmt.helpers -           cfg.training.random_seed : 42
2025-05-29 19:16:35,607 - INFO - joeynmt.helpers -             cfg.training.optimizer : adam
2025-05-29 19:16:35,607 - INFO - joeynmt.helpers -         cfg.training.normalization : tokens
2025-05-29 19:16:35,607 - INFO - joeynmt.helpers -         cfg.training.learning_rate : 0.0003
2025-05-29 19:16:35,607 - INFO - joeynmt.helpers -            cfg.training.batch_size : 2048
2025-05-29 19:16:35,607 - INFO - joeynmt.helpers -            cfg.training.batch_type : token
2025-05-29 19:16:35,607 - INFO - joeynmt.helpers -       cfg.training.eval_batch_size : 1024
2025-05-29 19:16:35,607 - INFO - joeynmt.helpers -       cfg.training.eval_batch_type : token
2025-05-29 19:16:35,607 - INFO - joeynmt.helpers -            cfg.training.scheduling : plateau
2025-05-29 19:16:35,607 - INFO - joeynmt.helpers -              cfg.training.patience : 8
2025-05-29 19:16:35,607 - INFO - joeynmt.helpers -          cfg.training.weight_decay : 0.0
2025-05-29 19:16:35,607 - INFO - joeynmt.helpers -       cfg.training.decrease_factor : 0.7
2025-05-29 19:16:35,607 - INFO - joeynmt.helpers - cfg.training.early_stopping_metric : ppl
2025-05-29 19:16:35,607 - INFO - joeynmt.helpers -                cfg.training.epochs : 10
2025-05-29 19:16:35,607 - INFO - joeynmt.helpers -       cfg.training.validation_freq : 500
2025-05-29 19:16:35,607 - INFO - joeynmt.helpers -          cfg.training.logging_freq : 100
2025-05-29 19:16:35,607 - INFO - joeynmt.helpers -           cfg.training.eval_metric : bleu
2025-05-29 19:16:35,607 - INFO - joeynmt.helpers -             cfg.training.model_dir : models/transformer_bpe_2000/
2025-05-29 19:16:35,607 - INFO - joeynmt.helpers -             cfg.training.overwrite : True
2025-05-29 19:16:35,607 - INFO - joeynmt.helpers -               cfg.training.shuffle : True
2025-05-29 19:16:35,607 - INFO - joeynmt.helpers -              cfg.training.use_cuda : True
2025-05-29 19:16:35,607 - INFO - joeynmt.helpers -     cfg.training.max_output_length : 100
2025-05-29 19:16:35,607 - INFO - joeynmt.helpers -     cfg.training.print_valid_sents : [0, 1, 2, 3, 4]
2025-05-29 19:16:35,607 - INFO - joeynmt.helpers -       cfg.training.label_smoothing : 0.3
2025-05-29 19:16:35,607 - INFO - joeynmt.helpers -              cfg.model.initializer : xavier_uniform
2025-05-29 19:16:35,607 - INFO - joeynmt.helpers -         cfg.model.bias_initializer : zeros
2025-05-29 19:16:35,607 - INFO - joeynmt.helpers -                cfg.model.init_gain : 1.0
2025-05-29 19:16:35,607 - INFO - joeynmt.helpers -        cfg.model.embed_initializer : xavier_uniform
2025-05-29 19:16:35,607 - INFO - joeynmt.helpers -          cfg.model.embed_init_gain : 1.0
2025-05-29 19:16:35,607 - INFO - joeynmt.helpers -          cfg.model.tied_embeddings : True
2025-05-29 19:16:35,607 - INFO - joeynmt.helpers -             cfg.model.tied_softmax : True
2025-05-29 19:16:35,607 - INFO - joeynmt.helpers -             cfg.model.encoder.type : transformer
2025-05-29 19:16:35,607 - INFO - joeynmt.helpers -       cfg.model.encoder.num_layers : 4
2025-05-29 19:16:35,607 - INFO - joeynmt.helpers -        cfg.model.encoder.num_heads : 2
2025-05-29 19:16:35,607 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.embedding_dim : 256
2025-05-29 19:16:35,608 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.scale : True
2025-05-29 19:16:35,608 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.dropout : 0
2025-05-29 19:16:35,608 - INFO - joeynmt.helpers -      cfg.model.encoder.hidden_size : 256
2025-05-29 19:16:35,608 - INFO - joeynmt.helpers -          cfg.model.encoder.ff_size : 512
2025-05-29 19:16:35,608 - INFO - joeynmt.helpers -          cfg.model.encoder.dropout : 0
2025-05-29 19:16:35,608 - INFO - joeynmt.helpers -             cfg.model.decoder.type : transformer
2025-05-29 19:16:35,608 - INFO - joeynmt.helpers -       cfg.model.decoder.num_layers : 1
2025-05-29 19:16:35,608 - INFO - joeynmt.helpers -        cfg.model.decoder.num_heads : 2
2025-05-29 19:16:35,608 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.embedding_dim : 256
2025-05-29 19:16:35,608 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.scale : True
2025-05-29 19:16:35,608 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.dropout : 0
2025-05-29 19:16:35,608 - INFO - joeynmt.helpers -      cfg.model.decoder.hidden_size : 256
2025-05-29 19:16:35,608 - INFO - joeynmt.helpers -          cfg.model.decoder.ff_size : 512
2025-05-29 19:16:35,608 - INFO - joeynmt.helpers -          cfg.model.decoder.dropout : 0
2025-05-29 19:16:35,896 - INFO - joeynmt.data - [DEBUG] Attempting to build tokenizer...
2025-05-29 19:16:35,896 - INFO - joeynmt.data - [DEBUG] Building subword-nmt tokenizer with config: {'src': {'lang': 'it', 'level': 'bpe', 'lowercase': False, 'max_sent_length': 100, 'voc_file': 'bpe/2000/2000.vocab', 'tokenizer_type': 'subword-nmt', 'tokenizer_cfg': {'codes': 'bpe/2000/codes.codes'}}, 'trg': {'lang': 'de', 'level': 'bpe', 'lowercase': False, 'max_sent_length': 100, 'voc_file': 'bpe/2000/2000.vocab', 'tokenizer_type': 'subword-nmt', 'tokenizer_cfg': {'codes': 'bpe/2000/codes.codes'}}, 'train': 'scripts/data/train_100k.it-de', 'dev': 'scripts/data/dev.it-de', 'test': 'scripts/data/test.it-de', 'dataset_type': 'plain', 'bpe_codes': 'bpe/2000/codes.codes', 'special_symbols': {'unk_token': '<unk>', 'unk_id': 0, 'pad_token': '<pad>', 'pad_id': 1, 'bos_token': '<s>', 'bos_id': 2, 'eos_token': '</s>', 'eos_id': 3}}
2025-05-29 19:16:35,901 - INFO - joeynmt.tokenizers - it tokenizer: SubwordNMTTokenizer(level=bpe, lowercase=False, normalize=False, filter_by_length=(-1, -1), pretokenizer=none, tokenizer=BPE, separator=@@, dropout=0.0)
2025-05-29 19:16:35,901 - INFO - joeynmt.tokenizers - de tokenizer: SubwordNMTTokenizer(level=bpe, lowercase=False, normalize=False, filter_by_length=(-1, -1), pretokenizer=none, tokenizer=BPE, separator=@@, dropout=0.0)
2025-05-29 19:16:35,901 - INFO - joeynmt.data - [DEBUG] Tokenizer built: {'it': SubwordNMTTokenizer(level=bpe, lowercase=False, normalize=False, filter_by_length=(-1, -1), pretokenizer=none, tokenizer=BPE, separator=@@, dropout=0.0), 'de': SubwordNMTTokenizer(level=bpe, lowercase=False, normalize=False, filter_by_length=(-1, -1), pretokenizer=none, tokenizer=BPE, separator=@@, dropout=0.0)}
2025-05-29 19:16:35,901 - INFO - joeynmt.data - Loading train set...
2025-05-29 19:16:36,048 - INFO - joeynmt.data - Building vocabulary...
2025-05-29 19:16:36,067 - INFO - joeynmt.data - Loading dev set...
2025-05-29 19:16:36,069 - INFO - joeynmt.data - Loading test set...
2025-05-29 19:16:36,072 - INFO - joeynmt.data - Data loaded.
2025-05-29 19:16:36,072 - INFO - joeynmt.data - Train dataset: PlaintextDataset(split=train, len=100001, src_lang=it, trg_lang=de, has_trg=True, random_subset=-1)
2025-05-29 19:16:36,072 - INFO - joeynmt.data - Valid dataset: PlaintextDataset(split=dev, len=923, src_lang=it, trg_lang=de, has_trg=True, random_subset=-1)
2025-05-29 19:16:36,072 - INFO - joeynmt.data -  Test dataset: PlaintextDataset(split=test, len=1567, src_lang=it, trg_lang=de, has_trg=True, random_subset=-1)
2025-05-29 19:16:36,073 - INFO - joeynmt.data - First training example:
	[SRC] M@@ ol@@ to, molto semplic@@ e.
	[TRG] S@@ ehr@@ , sehr einf@@ ach@@ .
2025-05-29 19:16:36,073 - INFO - joeynmt.data - First 10 Src tokens: (0) <unk> (1) <pad> (2) <s> (3) </s> (4) e (5) a (6) di (7) , (8) che (9) in
2025-05-29 19:16:36,073 - INFO - joeynmt.data - First 10 Trg tokens: (0) <unk> (1) <pad> (2) <s> (3) </s> (4) e (5) a (6) di (7) , (8) che (9) in
2025-05-29 19:16:36,073 - INFO - joeynmt.data - Number of unique Src tokens (vocab_size): 1797
2025-05-29 19:16:36,073 - INFO - joeynmt.data - Number of unique Trg tokens (vocab_size): 1797
2025-05-29 19:16:36,073 - INFO - joeynmt.model - Building an encoder-decoder model...
2025-05-29 19:16:36,157 - INFO - joeynmt.model - Enc-dec model built.
2025-05-29 19:16:36,160 - INFO - joeynmt.model - Total params: 3359232
2025-05-29 19:16:36,160 - DEBUG - joeynmt.model - Trainable parameters: ['decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'encoder.layers.3.feed_forward.layer_norm.bias', 'encoder.layers.3.feed_forward.layer_norm.weight', 'encoder.layers.3.feed_forward.pwff_layer.0.bias', 'encoder.layers.3.feed_forward.pwff_layer.0.weight', 'encoder.layers.3.feed_forward.pwff_layer.3.bias', 'encoder.layers.3.feed_forward.pwff_layer.3.weight', 'encoder.layers.3.layer_norm.bias', 'encoder.layers.3.layer_norm.weight', 'encoder.layers.3.src_src_att.k_layer.bias', 'encoder.layers.3.src_src_att.k_layer.weight', 'encoder.layers.3.src_src_att.output_layer.bias', 'encoder.layers.3.src_src_att.output_layer.weight', 'encoder.layers.3.src_src_att.q_layer.bias', 'encoder.layers.3.src_src_att.q_layer.weight', 'encoder.layers.3.src_src_att.v_layer.bias', 'encoder.layers.3.src_src_att.v_layer.weight', 'src_embed.lut.weight']
2025-05-29 19:16:36,160 - INFO - joeynmt.training - Model(
	encoder=TransformerEncoder(num_layers=4, num_heads=2, alpha=1.0, layer_norm="pre", activation=ReLU()),
	decoder=TransformerDecoder(num_layers=1, num_heads=2, alpha=1.0, layer_norm="post", activation=ReLU()),
	src_embed=Embeddings(embedding_dim=256, vocab_size=1797),
	trg_embed=Embeddings(embedding_dim=256, vocab_size=1797),
	loss_function=XentLoss(criterion=KLDivLoss(), smoothing=0.3))
2025-05-29 19:16:37,553 - INFO - joeynmt.builders - Adam(lr=0.0003, weight_decay=0.0, betas=(0.9, 0.999))
2025-05-29 19:16:37,554 - INFO - joeynmt.builders - ReduceLROnPlateau(mode=min, threshold_mode=abs, eps=0.0, factor=0.7, patience=8)
2025-05-29 19:16:37,554 - INFO - joeynmt.training - Train stats:
	device: cuda
	n_gpu: 1
	16-bits training: False
	gradient accumulation: 1
	batch size per device: 2048
	effective batch size (w. parallel & accumulation): 2048
2025-05-29 19:16:37,554 - INFO - joeynmt.training - EPOCH 1
2025-05-29 19:16:40,372 - INFO - joeynmt.training - Epoch   1, Step:      100, Batch Loss:     3.978665, Batch Acc: 0.035381, Tokens per Sec:    25478, Lr: 0.000300
2025-05-29 19:16:42,734 - INFO - joeynmt.training - Epoch   1, Step:      200, Batch Loss:     3.807269, Batch Acc: 0.055568, Tokens per Sec:    29551, Lr: 0.000300
2025-05-29 19:16:45,273 - INFO - joeynmt.training - Epoch   1, Step:      300, Batch Loss:     3.597550, Batch Acc: 0.076804, Tokens per Sec:    27673, Lr: 0.000300
2025-05-29 19:16:47,799 - INFO - joeynmt.training - Epoch   1, Step:      400, Batch Loss:     3.492415, Batch Acc: 0.083377, Tokens per Sec:    27819, Lr: 0.000300
2025-05-29 19:16:50,459 - INFO - joeynmt.training - Epoch   1, Step:      500, Batch Loss:     3.524165, Batch Acc: 0.084207, Tokens per Sec:    26260, Lr: 0.000300
2025-05-29 19:16:50,459 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:16:50,459 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:17:06,900 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   3.52, ppl:  33.69, acc:   0.09, generation: 16.4182[sec], evaluation: 0.0000[sec]
2025-05-29 19:17:06,901 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:17:07,002 - INFO - joeynmt.training - Example #0
2025-05-29 19:17:07,002 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:17:07,002 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:17:07,002 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und']
2025-05-29 19:17:07,002 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:17:07,002 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:17:07,002 - INFO - joeynmt.training - 	Hypothesis: Und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und
2025-05-29 19:17:07,002 - INFO - joeynmt.training - Example #1
2025-05-29 19:17:07,003 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:17:07,003 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:17:07,003 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und']
2025-05-29 19:17:07,003 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:17:07,003 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:17:07,003 - INFO - joeynmt.training - 	Hypothesis: Und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und
2025-05-29 19:17:07,003 - INFO - joeynmt.training - Example #2
2025-05-29 19:17:07,003 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:17:07,003 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:17:07,003 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und']
2025-05-29 19:17:07,003 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:17:07,003 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:17:07,003 - INFO - joeynmt.training - 	Hypothesis: Und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und
2025-05-29 19:17:07,003 - INFO - joeynmt.training - Example #3
2025-05-29 19:17:07,003 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:17:07,003 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:17:07,003 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und']
2025-05-29 19:17:07,004 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:17:07,004 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:17:07,004 - INFO - joeynmt.training - 	Hypothesis: Und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und
2025-05-29 19:17:07,004 - INFO - joeynmt.training - Example #4
2025-05-29 19:17:07,004 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:17:07,004 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:17:07,004 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und']
2025-05-29 19:17:07,004 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:17:07,004 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:17:07,004 - INFO - joeynmt.training - 	Hypothesis: Und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und
2025-05-29 19:17:09,374 - INFO - joeynmt.training - Epoch   1, Step:      600, Batch Loss:     3.431116, Batch Acc: 0.086662, Tokens per Sec:    28306, Lr: 0.000300
2025-05-29 19:17:11,635 - INFO - joeynmt.training - Epoch   1, Step:      700, Batch Loss:     3.415370, Batch Acc: 0.088691, Tokens per Sec:    32660, Lr: 0.000300
2025-05-29 19:17:13,811 - INFO - joeynmt.training - Epoch   1, Step:      800, Batch Loss:     3.483546, Batch Acc: 0.088124, Tokens per Sec:    31675, Lr: 0.000300
2025-05-29 19:17:16,152 - INFO - joeynmt.training - Epoch   1, Step:      900, Batch Loss:     3.531196, Batch Acc: 0.089823, Tokens per Sec:    29840, Lr: 0.000300
2025-05-29 19:17:18,547 - INFO - joeynmt.training - Epoch   1, Step:     1000, Batch Loss:     3.463717, Batch Acc: 0.093232, Tokens per Sec:    28994, Lr: 0.000300
2025-05-29 19:17:18,547 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:17:18,547 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:17:34,136 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   3.42, ppl:  30.47, acc:   0.09, generation: 15.5680[sec], evaluation: 0.0000[sec]
2025-05-29 19:17:34,136 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:17:34,235 - INFO - joeynmt.training - Example #0
2025-05-29 19:17:34,235 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:17:34,235 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:17:34,236 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'und', 'und', 'und', 'wir', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'wir', 'und', 'wir', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'wir', 'und', 'wir', 'und', 'und', 'und', 'und', 'und', 'wir', 'und', 'wir', 'und', 'wir', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'wir', 'und', 'wir', 'und', 'und', 'und', 'wir', 'und', 'wir', 'und', 'und', 'und', 'wir', 'und', 'wir', 'und', 'wir', 'und', 'wir', 'und', 'wir', 'und', 'wir', 'und', 'wir', 'und', 'wir', 'und', 'wir', 'und', 'wir', 'und', 'wir', 'und', 'wir', 'und', 'wir', 'und', 'wir', 'und', 'wir', 'und', 'wir', 'und', 'wir', 'und', 'wir']
2025-05-29 19:17:34,236 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:17:34,236 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:17:34,236 - INFO - joeynmt.training - 	Hypothesis: Und und und und wir und und und und und und und und und und und und und und und und wir und wir und und und und und und und und wir und wir und und und und und wir und wir und wir und und und und und und und und und und und und und und und und und und und und wir und wir und und und wir und wir und und und wir und wir und wir und wir und wir und wir und wir und wir und wir und wir und wir und wir und wir und wir und wir und wir und wir und wir
2025-05-29 19:17:34,236 - INFO - joeynmt.training - Example #1
2025-05-29 19:17:34,236 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:17:34,236 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:17:34,236 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'wir', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'wir', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'wir', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'wir', 'und', 'wir', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'wir', 'und', 'wir', 'und', 'wir', 'und', 'und', 'wir', 'und', 'wir', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'wir', 'und', 'wir', 'und']
2025-05-29 19:17:34,237 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:17:34,237 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:17:34,237 - INFO - joeynmt.training - 	Hypothesis: Und und und und und und und und und und und und und und und und und und und und und und wir und und und und und und und und und und und und und und und und und und und wir und und und und und und und und und und und und und und und und und und und und und und wir und und und und und und und und und und und und und wir und wir und und und und und und und und wir und wir und wir und und wir und wir und und und und und und und und wir und wir und
2025-05-29 19:17:34,237 - INFO - joeynmt.training - Example #2
2025-05-29 19:17:34,237 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:17:34,237 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:17:34,237 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'wir', 'und', 'wir', 'und', 'wir', 'und', 'wir', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'wir', 'und', 'wir', 'und']
2025-05-29 19:17:34,237 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:17:34,237 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:17:34,237 - INFO - joeynmt.training - 	Hypothesis: Und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und wir und wir und wir und wir und und und und und und und und und und und wir und wir und
2025-05-29 19:17:34,237 - INFO - joeynmt.training - Example #3
2025-05-29 19:17:34,237 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:17:34,237 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:17:34,237 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'und', 'wir', 'und', 'wir', 'und', 'wir', 'und', 'wir', 'und', 'wir', 'und', 'und', 'und', 'wir', 'und', 'wir', 'und', 'wir', 'und', 'wir', 'und', 'wir', 'und', 'wir', 'und', 'wir', 'und', 'wir', 'und', 'wir', 'und', 'wir', 'und', 'wir', 'und', 'wir', 'und', 'wir', 'und', 'wir', 'und', 'wir', 'und', 'wir', 'und', 'wir', 'und', 'wir', 'und', 'wir', 'und', 'und', 'und', 'und', 'und', 'wir', 'und', 'wir', 'und', 'wir', 'und', 'und', 'wir', 'und', 'wir', 'und', 'wir', 'und', 'wir', 'und', 'wir', 'und', 'wir', 'und', 'und', 'und', 'wir', 'und', 'wir', 'und', 'wir', 'und', 'wir', 'und', 'wir', 'und', 'wir', 'und', 'wir', 'und', 'wir', 'und', 'wir', 'und', 'wir', 'und', 'wir', 'und', 'wir', 'und', 'wir', 'und', 'wir', 'und', 'wir', 'und', 'wir', 'und', 'wir', 'und', 'wir']
2025-05-29 19:17:34,238 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:17:34,238 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:17:34,238 - INFO - joeynmt.training - 	Hypothesis: Und und wir und wir und wir und wir und wir und und und wir und wir und wir und wir und wir und wir und wir und wir und wir und wir und wir und wir und wir und wir und wir und wir und wir und wir und wir und und und und und wir und wir und wir und und wir und wir und wir und wir und wir und wir und und und wir und wir und wir und wir und wir und wir und wir und wir und wir und wir und wir und wir und wir und wir und wir und wir und wir und wir
2025-05-29 19:17:34,238 - INFO - joeynmt.training - Example #4
2025-05-29 19:17:34,238 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:17:34,238 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:17:34,238 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und']
2025-05-29 19:17:34,238 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:17:34,238 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:17:34,238 - INFO - joeynmt.training - 	Hypothesis: Und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und
2025-05-29 19:17:37,742 - INFO - joeynmt.training - Epoch   1, Step:     1100, Batch Loss:     3.386526, Batch Acc: 0.093670, Tokens per Sec:    19468, Lr: 0.000300
2025-05-29 19:17:40,118 - INFO - joeynmt.training - Epoch   1, Step:     1200, Batch Loss:     3.406114, Batch Acc: 0.095656, Tokens per Sec:    30112, Lr: 0.000300
2025-05-29 19:17:42,620 - INFO - joeynmt.training - Epoch   1, Step:     1300, Batch Loss:     3.344988, Batch Acc: 0.096463, Tokens per Sec:    28833, Lr: 0.000300
2025-05-29 19:17:44,926 - INFO - joeynmt.training - Epoch   1, Step:     1400, Batch Loss:     3.364067, Batch Acc: 0.100861, Tokens per Sec:    31643, Lr: 0.000300
2025-05-29 19:17:47,212 - INFO - joeynmt.training - Epoch   1, Step:     1500, Batch Loss:     3.348863, Batch Acc: 0.102435, Tokens per Sec:    32265, Lr: 0.000300
2025-05-29 19:17:47,213 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:17:47,213 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:18:02,771 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   3.31, ppl:  27.42, acc:   0.11, generation: 15.5464[sec], evaluation: 0.0000[sec]
2025-05-29 19:18:02,772 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:18:02,865 - INFO - joeynmt.training - Example #0
2025-05-29 19:18:02,865 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:18:02,865 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:18:02,865 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'die', 'M@@', '<unk>', 'n@@', 'nen', 'die', 'M@@', '<unk>', 'n@@', 'nen', 'die', 'M@@', '<unk>', 'n@@', 'nen', 'die', 'M@@', '<unk>', 'n@@', 'nen', 'die', 'M@@', '<unk>', 'n@@', 'nen', 'die', 'M@@', '<unk>', 'n@@', 'nen', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 't', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und']
2025-05-29 19:18:02,865 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:18:02,866 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:18:02,866 - INFO - joeynmt.training - 	Hypothesis: Und die M<unk> nnen die M<unk> nnen die M<unk> nnen die M<unk> nnen die M<unk> nnen die M<unk> nnen die M<unk> nnt und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und
2025-05-29 19:18:02,866 - INFO - joeynmt.training - Example #1
2025-05-29 19:18:02,866 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:18:02,866 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:18:02,866 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'die', 'M@@', '<unk>', 'n@@', 'nen', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'te', 'die', 'M@@', '<unk>', 'n@@', 'nen', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'n@@', '<unk>', 'n@@', 'nen', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'n@@', 'en.', '</s>']
2025-05-29 19:18:02,866 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:18:02,866 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:18:02,866 - INFO - joeynmt.training - 	Hypothesis: Und die M<unk> nnen die M<unk> nnte die M<unk> nnen die M<unk> nnn<unk> nnen die M<unk> nnnen.
2025-05-29 19:18:02,866 - INFO - joeynmt.training - Example #2
2025-05-29 19:18:02,866 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:18:02,866 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:18:02,866 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'die', 'M@@', '<unk>', 'n@@', 'nen', 'die', 'M@@', '<unk>', 'n@@', 'nen', 'die', 'M@@', '<unk>', 'n@@', 'nen', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'n@@', 't', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und', 'und']
2025-05-29 19:18:02,866 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:18:02,867 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:18:02,867 - INFO - joeynmt.training - 	Hypothesis: Und die M<unk> nnen die M<unk> nnen die M<unk> nnen die M<unk> nnnt und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und und
2025-05-29 19:18:02,867 - INFO - joeynmt.training - Example #3
2025-05-29 19:18:02,867 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:18:02,867 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:18:02,867 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'die', 'M@@', '<unk>', 'n@@', 'nen', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'n@@', '<unk>', 'n@@', 'n@@', 'n@@', 'en.', '</s>']
2025-05-29 19:18:02,867 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:18:02,867 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:18:02,867 - INFO - joeynmt.training - 	Hypothesis: Und die M<unk> nnen die M<unk> nnn<unk> nnnen.
2025-05-29 19:18:02,867 - INFO - joeynmt.training - Example #4
2025-05-29 19:18:02,867 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:18:02,867 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:18:02,867 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'die', 'der', 'M@@', '<unk>', 'n@@', 'nen', 'die', 'M@@', '<unk>', 'n@@', 'nen', 'die', 'M@@', '<unk>', 'n@@', 'nen', 'die', 'M@@', '<unk>', 'n@@', 'nen', 'die', 'M@@', '<unk>', 'n@@', 'nen', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'n@@', 'en.', '</s>']
2025-05-29 19:18:02,867 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:18:02,867 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:18:02,867 - INFO - joeynmt.training - 	Hypothesis: Und die der M<unk> nnen die M<unk> nnen die M<unk> nnen die M<unk> nnen die M<unk> nnen die M<unk> nnnen.
2025-05-29 19:18:05,165 - INFO - joeynmt.training - Epoch   1, Step:     1600, Batch Loss:     3.346838, Batch Acc: 0.110860, Tokens per Sec:    29001, Lr: 0.000300
2025-05-29 19:18:07,537 - INFO - joeynmt.training - Epoch   1, Step:     1700, Batch Loss:     3.169137, Batch Acc: 0.113312, Tokens per Sec:    29254, Lr: 0.000300
2025-05-29 19:18:10,988 - INFO - joeynmt.training - Epoch   1, Step:     1800, Batch Loss:     3.263694, Batch Acc: 0.118130, Tokens per Sec:    20950, Lr: 0.000300
2025-05-29 19:18:13,457 - INFO - joeynmt.training - Epoch   1, Step:     1900, Batch Loss:     3.202572, Batch Acc: 0.127830, Tokens per Sec:    28302, Lr: 0.000300
2025-05-29 19:18:15,833 - INFO - joeynmt.training - Epoch   1, Step:     2000, Batch Loss:     3.118073, Batch Acc: 0.132101, Tokens per Sec:    30275, Lr: 0.000300
2025-05-29 19:18:15,834 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:18:15,834 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:18:26,966 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   3.13, ppl:  22.80, acc:   0.14, generation: 11.1248[sec], evaluation: 0.0000[sec]
2025-05-29 19:18:26,966 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:18:27,067 - INFO - joeynmt.training - Example #0
2025-05-29 19:18:27,067 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:18:27,067 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:18:27,067 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'ich', 'm@@', '<unk>', 'n@@', 'nen', 'wir', 'die', 'M@@', '<unk>', 'n@@', 'nen', 'und', 'die', 'M@@', '<unk>', 'n@@', 'nen', 'und', 'die', 'S@@', 'o@@', 'o@@', 'z@@', 'z@@', 'eich@@', 'n@@', '<unk>', 'n@@', 'n@@', 'n@@', 'en.', '</s>']
2025-05-29 19:18:27,067 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:18:27,067 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:18:27,067 - INFO - joeynmt.training - 	Hypothesis: Und ich habe ich m<unk> nnen wir die M<unk> nnen und die M<unk> nnen und die Soozzeichn<unk> nnnen.
2025-05-29 19:18:27,067 - INFO - joeynmt.training - Example #1
2025-05-29 19:18:27,068 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:18:27,068 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:18:27,068 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'm@@', '<unk>', 'n@@', 'nen', 'wir', 'die', 'K@@', '<unk>', 'n@@', 'n@@', 'n@@', 'at@@', '<unk>', 'n@@', 'nen', 'wir', 'die', 'S@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'z@@', 'z@@', 'z@@', 'ei@@', 'ten', 'und', 'die', 'K@@', '<unk>', 'r@@', 'en', 'und', 'die', 'K@@', '<unk>', 'r@@', 'en', 'und', 'die', 'K@@', '<unk>', 'r@@', 'de', 'und', 'die', 'K@@', '<unk>', 'n@@', 'n@@', 'n@@', 'n@@', 'n@@', '<unk>', 'r@@', 'en.', '</s>']
2025-05-29 19:18:27,068 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:18:27,068 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:18:27,068 - INFO - joeynmt.training - 	Hypothesis: Und ich m<unk> nnen wir die K<unk> nnnat<unk> nnen wir die Soooooozzzeiten und die K<unk> ren und die K<unk> ren und die K<unk> rde und die K<unk> nnnnn<unk> ren.
2025-05-29 19:18:27,068 - INFO - joeynmt.training - Example #2
2025-05-29 19:18:27,068 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:18:27,068 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:18:27,068 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', '<unk>', 'n@@', 'nen', 'wir', 'die', 'K@@', '<unk>', 'r@@', '<unk>', 'r@@', 'lich', 'in', 'der', 'S@@', 'o@@', 'o@@', 'ch@@', 's@@', 's@@', 's@@', 's@@', '<unk>', 'n@@', 'n@@', 'en.', '</s>']
2025-05-29 19:18:27,068 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:18:27,068 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:18:27,068 - INFO - joeynmt.training - 	Hypothesis: Und ich habe ich ich ich ich ich ich <unk> nnen wir die K<unk> r<unk> rlich in der Soochssss<unk> nnen.
2025-05-29 19:18:27,068 - INFO - joeynmt.training - Example #3
2025-05-29 19:18:27,068 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:18:27,068 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:18:27,068 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'ein', 'M@@', '<unk>', 'r@@', 'der@@', 'n', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'en.', '</s>']
2025-05-29 19:18:27,068 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:18:27,068 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:18:27,069 - INFO - joeynmt.training - 	Hypothesis: Und das ist ein M<unk> rdern und die M<unk> nnen.
2025-05-29 19:18:27,069 - INFO - joeynmt.training - Example #4
2025-05-29 19:18:27,069 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:18:27,069 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:18:27,069 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'm@@', '<unk>', 'n@@', 'nen', 'wir', 'die', 'K@@', '<unk>', 'r@@', '<unk>', 'r@@', 'de', 'und', 'die', 'M@@', '<unk>', 'r@@', 'de', 'und', 'die', 'S@@', 'o@@', 'ch@@', 's@@', '<unk>', 'r@@', 'de', 'und', 'die', 'S@@', 'o@@', 'ch@@', 's@@', 's@@', 's@@', 's@@', 's@@', 's@@', '<unk>', 'r@@', 'de', 'und', 'die', 'K@@', '<unk>', 'n@@', 'n@@', 'en.', '</s>']
2025-05-29 19:18:27,069 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:18:27,069 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:18:27,069 - INFO - joeynmt.training - 	Hypothesis: Und ich m<unk> nnen wir die K<unk> r<unk> rde und die M<unk> rde und die Sochs<unk> rde und die Sochssssss<unk> rde und die K<unk> nnen.
2025-05-29 19:18:29,414 - INFO - joeynmt.training - Epoch   1, Step:     2100, Batch Loss:     3.017181, Batch Acc: 0.139314, Tokens per Sec:    28759, Lr: 0.000300
2025-05-29 19:18:31,721 - INFO - joeynmt.training - Epoch   1, Step:     2200, Batch Loss:     3.106184, Batch Acc: 0.145921, Tokens per Sec:    30076, Lr: 0.000300
2025-05-29 19:18:34,078 - INFO - joeynmt.training - Epoch   1, Step:     2300, Batch Loss:     3.071836, Batch Acc: 0.151461, Tokens per Sec:    29407, Lr: 0.000300
2025-05-29 19:18:36,289 - INFO - joeynmt.training - Epoch   1, Step:     2400, Batch Loss:     3.024184, Batch Acc: 0.154719, Tokens per Sec:    31259, Lr: 0.000300
2025-05-29 19:18:38,775 - INFO - joeynmt.training - Epoch   1, Step:     2500, Batch Loss:     2.999721, Batch Acc: 0.159678, Tokens per Sec:    28355, Lr: 0.000300
2025-05-29 19:18:38,775 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:18:38,776 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:18:49,795 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.95, ppl:  19.05, acc:   0.16, generation: 11.0132[sec], evaluation: 0.0000[sec]
2025-05-29 19:18:49,795 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:18:49,892 - INFO - joeynmt.training - Example #0
2025-05-29 19:18:49,892 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:18:49,892 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:18:49,893 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'ein', 'paar', 'M@@', '<unk>', 'r@@', 'k@@', 'e', 'M@@', '<unk>', 'n@@', 'n@@', 'en,', 'die', 'K@@', '<unk>', 'r@@', '<unk>', 'r@@', 'de', 'und', 'die', 'K@@', '<unk>', 'n@@', 'der@@', 'n', 'und', 'die', 'K@@', '<unk>', 'r@@', '<unk>', 'r@@', 'de', 'und', 'die', 'K@@', '<unk>', 'r@@', '<unk>', 'r@@', 'de', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per@@', 'per@@', 'ten', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per@@', 'ten', 'und', 'die', 'K@@', '<unk>', 'r@@', '<unk>', 'r@@', 'z@@', 'z@@', 'en', 'und', 'die', 'K@@', '<unk>', 'n@@', 'n@@', 'n@@', 'en.', '</s>']
2025-05-29 19:18:49,893 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:18:49,893 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:18:49,893 - INFO - joeynmt.training - 	Hypothesis: Und das ist ein paar M<unk> rke M<unk> nnen, die K<unk> r<unk> rde und die K<unk> ndern und die K<unk> r<unk> rde und die K<unk> r<unk> rde und die K<unk> rperperten und die K<unk> rperten und die K<unk> r<unk> rzzen und die K<unk> nnnen.
2025-05-29 19:18:49,893 - INFO - joeynmt.training - Example #1
2025-05-29 19:18:49,893 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:18:49,893 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:18:49,893 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'ein', 'paar', 'M@@', '<unk>', 'r@@', 'k@@', 'e', 'M@@', '<unk>', 'n@@', 'n@@', 'en.', '</s>']
2025-05-29 19:18:49,893 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:18:49,893 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:18:49,893 - INFO - joeynmt.training - 	Hypothesis: Und das ist ein paar M<unk> rke M<unk> nnen.
2025-05-29 19:18:49,893 - INFO - joeynmt.training - Example #2
2025-05-29 19:18:49,893 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:18:49,893 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:18:49,893 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'ein', 'paar', 'M@@', '<unk>', 'r@@', 'k@@', 'te', 'der', 'K@@', '<unk>', 'n@@', 'n@@', 'en.', '</s>']
2025-05-29 19:18:49,893 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:18:49,894 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:18:49,894 - INFO - joeynmt.training - 	Hypothesis: Und das ist ein paar M<unk> rkte der K<unk> nnen.
2025-05-29 19:18:49,894 - INFO - joeynmt.training - Example #3
2025-05-29 19:18:49,894 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:18:49,894 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:18:49,894 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'ein', 'M@@', 'et@@', 'et@@', 'et@@', 'er', 'M@@', '<unk>', 'r@@', 'k@@', 'te', 'und', 'das', 'M@@', '<unk>', 'n@@', 'n@@', 'en.', '</s>']
2025-05-29 19:18:49,894 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:18:49,894 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:18:49,894 - INFO - joeynmt.training - 	Hypothesis: Und das ist ein Meteteter M<unk> rkte und das M<unk> nnen.
2025-05-29 19:18:49,894 - INFO - joeynmt.training - Example #4
2025-05-29 19:18:49,894 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:18:49,894 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:18:49,894 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'ein', 'paar', 'M@@', '<unk>', 'r@@', 'k@@', 'e', 'M@@', '<unk>', 'n@@', 'n@@', 'en.', '</s>']
2025-05-29 19:18:49,894 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:18:49,894 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:18:49,894 - INFO - joeynmt.training - 	Hypothesis: Und das ist ein paar M<unk> rke M<unk> nnen.
2025-05-29 19:18:52,191 - INFO - joeynmt.training - Epoch   1, Step:     2600, Batch Loss:     2.930746, Batch Acc: 0.166505, Tokens per Sec:    29617, Lr: 0.000300
2025-05-29 19:18:54,623 - INFO - joeynmt.training - Epoch   1, Step:     2700, Batch Loss:     2.845389, Batch Acc: 0.169451, Tokens per Sec:    29882, Lr: 0.000300
2025-05-29 19:18:56,776 - INFO - joeynmt.training - Epoch   1, Step:     2800, Batch Loss:     2.942060, Batch Acc: 0.172957, Tokens per Sec:    32128, Lr: 0.000300
2025-05-29 19:18:59,326 - INFO - joeynmt.training - Epoch   1, Step:     2900, Batch Loss:     2.881948, Batch Acc: 0.178166, Tokens per Sec:    28323, Lr: 0.000300
2025-05-29 19:19:01,611 - INFO - joeynmt.training - Epoch   1, Step:     3000, Batch Loss:     2.872367, Batch Acc: 0.179431, Tokens per Sec:    29941, Lr: 0.000300
2025-05-29 19:19:01,612 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:19:01,612 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:19:18,133 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.83, ppl:  17.00, acc:   0.18, generation: 16.5071[sec], evaluation: 0.0000[sec]
2025-05-29 19:19:18,133 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:19:18,226 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/500.ckpt
2025-05-29 19:19:18,232 - INFO - joeynmt.training - Example #0
2025-05-29 19:19:18,232 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:19:18,232 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:19:18,233 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'die', 'M@@', '<unk>', 'n@@', 'der@@', ',', 'dass', 'die', 'die', 'M@@', '<unk>', 'n@@', 'der@@', 'n', 'und', 'die', 'M@@', '<unk>', 'n@@', 'der@@', 'n', 'und', 'die', 'M@@', '<unk>', 'n@@', 'der@@', 'n', 'und', 'die', 'M@@', '<unk>', 'n@@', 'der@@', ',', 'die', 'die', 'die', 'die', 'K@@', '<unk>', 'n@@', 'n@@', 'en,', 'die', 'die', 'die', 'die', 'M@@', '<unk>', 'n@@', 'der@@', 'ung', 'der', 'M@@', '<unk>', 'n@@', 'der@@', ',', 'die', 'die', 'die', 'die', 'M@@', '<unk>', 'n@@', 'der@@', 't', 'und', 'die', 'M@@', '<unk>', 'n@@', 'der@@', 'n', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'en,', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'K@@', '<unk>', 'h@@', 'l@@', 'te', 'der', 'M@@', '<unk>', 'n@@', 'n@@', 'te', 'der', 'M@@', '<unk>', 'h@@', 'el@@', 'el@@']
2025-05-29 19:19:18,233 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:19:18,233 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:19:18,233 - INFO - joeynmt.training - 	Hypothesis: Und ich habe die M<unk> nder, dass die die M<unk> ndern und die M<unk> ndern und die M<unk> ndern und die M<unk> nder, die die die die K<unk> nnen, die die die die M<unk> nderung der M<unk> nder, die die die die M<unk> ndert und die M<unk> ndern und die M<unk> nnen, die die die die die die die die die die K<unk> hlte der M<unk> nnte der M<unk> helel
2025-05-29 19:19:18,233 - INFO - joeynmt.training - Example #1
2025-05-29 19:19:18,233 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:19:18,233 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:19:18,233 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'die', 'M@@', '<unk>', 'n@@', 'der@@', ',', 'die', 'die', 'die', 'M@@', '<unk>', 'n@@', 'der@@', 'n', 'und', 'die', 'M@@', '<unk>', 'n@@', 'der@@', 'n', 'und', 'die', 'M@@', '<unk>', 'n@@', 'der@@', 'n', 'und', 'die', 'M@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:19:18,233 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:19:18,233 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:19:18,233 - INFO - joeynmt.training - 	Hypothesis: Und ich habe die M<unk> nder, die die die M<unk> ndern und die M<unk> ndern und die M<unk> ndern und die M<unk> ndern.
2025-05-29 19:19:18,233 - INFO - joeynmt.training - Example #2
2025-05-29 19:19:18,233 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:19:18,234 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:19:18,234 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'die', 'M@@', '<unk>', 'n@@', 'der@@', ',', 'die', 'die', 'die', 'M@@', '<unk>', 'n@@', 'der@@', 'n', 'und', 'die', 'M@@', '<unk>', 'n@@', 'der@@', 'n', 'und', 'die', 'M@@', '<unk>', 'n@@', 'der@@', 'n', 'und', 'die', 'M@@', '<unk>', 'n@@', 'der@@', 't', 'die', 'K@@', '<unk>', 'n@@', 'n@@', 'en,', 'die', 'die', 'die', 'die', 'M@@', '<unk>', 'n@@', 'der@@', 't', 'und', 'die', 'M@@', '<unk>', 'n@@', 'der@@', 'n', 'und', 'die', 'M@@', '<unk>', 'r@@', 'de', 'und', 'die', 'K@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:19:18,234 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:19:18,234 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:19:18,234 - INFO - joeynmt.training - 	Hypothesis: Und ich habe die M<unk> nder, die die die M<unk> ndern und die M<unk> ndern und die M<unk> ndern und die M<unk> ndert die K<unk> nnen, die die die die M<unk> ndert und die M<unk> ndern und die M<unk> rde und die K<unk> ndern.
2025-05-29 19:19:18,234 - INFO - joeynmt.training - Example #3
2025-05-29 19:19:18,234 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:19:18,234 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:19:18,234 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'ein', 'M@@', '<unk>', 'n@@', 'der@@', ',', 'dass', 'wir', 'die', 'M@@', '<unk>', 'n@@', 'der@@', 'n', 'und', 'die', 'M@@', '<unk>', 'n@@', 'der@@', 'n', 'und', 'die', 'M@@', '<unk>', 'n@@', 'der@@', 'n', 'und', 'die', 'M@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:19:18,234 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:19:18,234 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:19:18,234 - INFO - joeynmt.training - 	Hypothesis: Und ich habe ein M<unk> nder, dass wir die M<unk> ndern und die M<unk> ndern und die M<unk> ndern und die M<unk> ndern.
2025-05-29 19:19:18,234 - INFO - joeynmt.training - Example #4
2025-05-29 19:19:18,234 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:19:18,234 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:19:18,235 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'Ihnen', 'Ihnen', 'Ihnen', 'Ihnen', 'die', 'M@@', '<unk>', 'n@@', 'der@@', 'n', 'und', 'die', 'M@@', '<unk>', 'n@@', 'der@@', 'n', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'en,', 'die', 'die', 'die', 'die', 'M@@', '<unk>', 'n@@', 'der@@', 't', 'die', 'M@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:19:18,235 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:19:18,235 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:19:18,235 - INFO - joeynmt.training - 	Hypothesis: Und ich habe Ihnen Ihnen Ihnen Ihnen die M<unk> ndern und die M<unk> ndern und die M<unk> nnen, die die die die M<unk> ndert die M<unk> ndern.
2025-05-29 19:19:20,524 - INFO - joeynmt.training - Epoch   1, Step:     3100, Batch Loss:     2.998698, Batch Acc: 0.184400, Tokens per Sec:    29133, Lr: 0.000300
2025-05-29 19:19:22,380 - INFO - joeynmt.training - Epoch   1, Step:     3200, Batch Loss:     2.909329, Batch Acc: 0.186740, Tokens per Sec:    37634, Lr: 0.000300
2025-05-29 19:19:24,254 - INFO - joeynmt.training - Epoch   1, Step:     3300, Batch Loss:     2.722656, Batch Acc: 0.190536, Tokens per Sec:    36578, Lr: 0.000300
2025-05-29 19:19:26,279 - INFO - joeynmt.training - Epoch   1, Step:     3400, Batch Loss:     2.653104, Batch Acc: 0.192407, Tokens per Sec:    34994, Lr: 0.000300
2025-05-29 19:19:28,346 - INFO - joeynmt.training - Epoch   1, Step:     3500, Batch Loss:     2.692166, Batch Acc: 0.196133, Tokens per Sec:    34546, Lr: 0.000300
2025-05-29 19:19:28,346 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:19:28,346 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:19:42,122 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.75, ppl:  15.68, acc:   0.20, generation: 13.7665[sec], evaluation: 0.0000[sec]
2025-05-29 19:19:42,123 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:19:42,219 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/1000.ckpt
2025-05-29 19:19:42,224 - INFO - joeynmt.training - Example #0
2025-05-29 19:19:42,224 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:19:42,224 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:19:42,224 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'm@@', '<unk>', 'ber', 'die', 'F@@', '<unk>', 'h@@', 'ig@@', 'kei@@', 't,', 'die', 'die', 'die', 'die', 'K@@', '<unk>', 'n@@', 'n@@', 'en,', 'die', 'die', 'die', 'sie', 'in', 'der', 'F@@', '<unk>', 'r@@', 'z@@', 'e', 'und', 'die', 'F@@', '<unk>', 'r@@', 'de', 'und', 'die', 'K@@', '<unk>', 'n@@', 'n@@', 'te', 'die', 'F@@', '<unk>', 'r@@', 'k@@', 'te', 'in', 'der', 'F@@', '<unk>', 'n@@', 'n@@', 'ten', 'und', 'die', 'F@@', '<unk>', 'r@@', 'k@@', 'te', 'in', 'der', 'F@@', '<unk>', 'n@@', 'n@@', 'en,', 'die', 'die', 'die', 'die', 'sie', 'in', 'der', 'F@@', '<unk>', 'ber', 'die', 'F@@', '<unk>', 'h@@', 'ig@@', 'kei@@', 'ten', 'und', 'die', 'K@@', '<unk>', 'r@@', 'en', 'und', 'die', 'K@@', '<unk>', 'r@@', 't@@', 'te', 'der', 'F@@', '<unk>', 'ber', 'die', 'K@@', '<unk>', 'n@@', 'n@@', 'n@@']
2025-05-29 19:19:42,225 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:19:42,225 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:19:42,225 - INFO - joeynmt.training - 	Hypothesis: Und ich m<unk> ber die F<unk> higkeit, die die die die K<unk> nnen, die die die sie in der F<unk> rze und die F<unk> rde und die K<unk> nnte die F<unk> rkte in der F<unk> nnten und die F<unk> rkte in der F<unk> nnen, die die die die sie in der F<unk> ber die F<unk> higkeiten und die K<unk> ren und die K<unk> rtte der F<unk> ber die K<unk> nnn
2025-05-29 19:19:42,225 - INFO - joeynmt.training - Example #1
2025-05-29 19:19:42,225 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:19:42,225 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:19:42,225 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'm@@', '<unk>', 'ber', 'die', 'F@@', '<unk>', 'h@@', 'ig@@', 'kei@@', 't,', 'die', 'die', 'die', 'die', 'F@@', '<unk>', 'r@@', 'z@@', 'en', 'und', 'die', 'F@@', '<unk>', 'r@@', 'en', 'und', 'die', 'F@@', '<unk>', 'n@@', 'g@@', 'er', 'zu', 'er@@', 'rei@@', 'b@@', 'en,', 'die', 'die', 'sie', 'in', 'der', 'F@@', '<unk>', 'r@@', 'k@@', 'te', 'zu', 'ver@@', 'w@@', '<unk>', 'r@@', 'de', 'und', 'die', 'F@@', '<unk>', 'r@@', 'de', 'und', 'das', 'ist', 'das', 'in', 'der', 'F@@', '<unk>', 'h@@', 'ig@@', 'kei@@', 't,', 'die', 'die', 'die', 'die', 'F@@', '<unk>', 'ber', 'die', 'F@@', '<unk>', 'ber@@', 'fl@@', '<unk>', 'ber', 'die', 'K@@', '<unk>', 'r@@', 'z@@', 'er@@', 'ten', 'wir', 'die', 'K@@', '<unk>', 'r@@', 'te', 'der', 'F@@', '<unk>', 'ber', 'die', 'F@@', '<unk>', 'ber', 'die', 'K@@', '<unk>', 'n@@']
2025-05-29 19:19:42,225 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:19:42,225 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:19:42,225 - INFO - joeynmt.training - 	Hypothesis: Und ich m<unk> ber die F<unk> higkeit, die die die die F<unk> rzen und die F<unk> ren und die F<unk> nger zu erreiben, die die sie in der F<unk> rkte zu verw<unk> rde und die F<unk> rde und das ist das in der F<unk> higkeit, die die die die F<unk> ber die F<unk> berfl<unk> ber die K<unk> rzerten wir die K<unk> rte der F<unk> ber die F<unk> ber die K<unk> n
2025-05-29 19:19:42,225 - INFO - joeynmt.training - Example #2
2025-05-29 19:19:42,225 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:19:42,225 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:19:42,225 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'm@@', '<unk>', 'ber', 'die', 'F@@', '<unk>', 'h@@', 'ig@@', 'kei@@', 't,', 'die', 'die', 'die', 'die', 'F@@', '<unk>', 'r@@', 'z@@', 'en', 'und', 'die', 'F@@', '<unk>', 'r@@', 'en', 'und', 'die', 'F@@', '<unk>', 'r@@', 'z@@', 'e', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:19:42,225 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:19:42,226 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:19:42,226 - INFO - joeynmt.training - 	Hypothesis: Und ich m<unk> ber die F<unk> higkeit, die die die die F<unk> rzen und die F<unk> ren und die F<unk> rze zu ver<unk> ndern.
2025-05-29 19:19:42,226 - INFO - joeynmt.training - Example #3
2025-05-29 19:19:42,226 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:19:42,226 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:19:42,226 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'm@@', '<unk>', 'ber', 'die', 'F@@', '<unk>', 'h@@', 'ig@@', 'kei@@', 't,', 'die', 'die', 'die', 'F@@', '<unk>', 'r@@', 'k@@', 'te', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:19:42,226 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:19:42,226 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:19:42,226 - INFO - joeynmt.training - 	Hypothesis: Und ich m<unk> ber die F<unk> higkeit, die die die F<unk> rkte zu ver<unk> ndern.
2025-05-29 19:19:42,226 - INFO - joeynmt.training - Example #4
2025-05-29 19:19:42,226 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:19:42,226 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:19:42,226 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'm@@', '<unk>', 'ber', 'die', 'F@@', '<unk>', 'h@@', 'ig@@', 'kei@@', 't,', 'die', 'die', 'die', 'F@@', '<unk>', 'r@@', 'k@@', 'te', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:19:42,226 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:19:42,226 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:19:42,226 - INFO - joeynmt.training - 	Hypothesis: Und ich m<unk> ber die F<unk> higkeit, die die die F<unk> rkte zu ver<unk> ndern.
2025-05-29 19:19:44,477 - INFO - joeynmt.training - Epoch   1, Step:     3600, Batch Loss:     2.780586, Batch Acc: 0.196600, Tokens per Sec:    30503, Lr: 0.000300
2025-05-29 19:19:46,725 - INFO - joeynmt.training - Epoch   1, Step:     3700, Batch Loss:     2.622083, Batch Acc: 0.201563, Tokens per Sec:    30690, Lr: 0.000300
2025-05-29 19:19:49,783 - INFO - joeynmt.training - Epoch   1, Step:     3800, Batch Loss:     2.730426, Batch Acc: 0.202663, Tokens per Sec:    22868, Lr: 0.000300
2025-05-29 19:19:52,074 - INFO - joeynmt.training - Epoch   1, Step:     3900, Batch Loss:     2.766312, Batch Acc: 0.202985, Tokens per Sec:    29774, Lr: 0.000300
2025-05-29 19:19:54,278 - INFO - joeynmt.training - Epoch   1, Step:     4000, Batch Loss:     2.818806, Batch Acc: 0.203681, Tokens per Sec:    31815, Lr: 0.000300
2025-05-29 19:19:54,278 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:19:54,278 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:20:09,210 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.69, ppl:  14.79, acc:   0.21, generation: 14.9153[sec], evaluation: 0.0000[sec]
2025-05-29 19:20:09,210 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:20:09,308 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/1500.ckpt
2025-05-29 19:20:09,314 - INFO - joeynmt.training - Example #0
2025-05-29 19:20:09,314 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:20:09,314 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:20:09,314 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'Ihnen', 'Ihnen', 'Ihnen', 'ein', 'paar', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'ich', 'habe', 'ein', 'paar', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'ich', 'habe', 'ein', 'paar', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'ich', 'habe', 'ein', 'paar', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'K@@', '<unk>', 'n@@', 'n@@', 'te', 'ich', 'das', 'nicht', 'nur', 'ein', 'paar', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'K@@', '<unk>', 'r@@', 'z@@', 'te', 'der', 'K@@', '<unk>', 'n@@', 'n@@', 'te', 'und', 'ich', 'Ihnen', 'ein', 'paar', 'M@@', 'u@@', 'si@@', 'k', 'und', 'das', 'ist', 'das', 'nicht', 'nicht', 'nur', 'ein', 'paar', 'M@@', '<unk>', 'n@@', 'g@@', 'er', 'und', 'die', 'K@@', '<unk>', 'r@@', 'z@@', 'z@@', 'lich', 'f@@', '<unk>', 'r', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>']
2025-05-29 19:20:09,315 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:20:09,315 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:20:09,315 - INFO - joeynmt.training - 	Hypothesis: Und ich habe Ihnen Ihnen Ihnen ein paar M<unk> nner und ich habe ein paar M<unk> nner und ich habe ein paar M<unk> nner und ich habe ein paar M<unk> nner und die K<unk> nnte ich das nicht nur ein paar M<unk> nner und die K<unk> rzte der K<unk> nnte und ich Ihnen ein paar Musik und das ist das nicht nicht nur ein paar M<unk> nger und die K<unk> rzzlich f<unk> r die K<unk> rper und die K<unk>
2025-05-29 19:20:09,315 - INFO - joeynmt.training - Example #1
2025-05-29 19:20:09,315 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:20:09,315 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:20:09,315 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'ein', 'paar', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'ich', 'habe', 'ein', 'paar', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'ich', 'habe', 'ein', 'paar', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'das', 'ist', 'ein', 'paar', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'das', 'ist', 'ein', 'paar', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'das', 'ist', 'ein', 'paar', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'das', 'ist', 'ein', 'paar', 'M@@', 'et@@', 'ho@@', 'de', 'und', 'das', 'G@@', 'en@@', '<unk>', 'n@@', 'd@@', 'chen', 'und', 'das', 'ist', 'ein', 'paar', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'das', 'ist', 'das', 'F@@', '<unk>', 'hr@@', 'er', 'und', 'das', 'ist', 'das', 'nicht', 'nur', 'ein', 'paar', 'M@@', '<unk>', 'n@@', 'g@@', 'ro@@', '<unk>', 'e', 'und', 'das', 'ist', 'das', 'F@@', 'ol@@', 'er@@', 'l@@', '<unk>']
2025-05-29 19:20:09,315 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:20:09,315 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:20:09,315 - INFO - joeynmt.training - 	Hypothesis: Und ich habe ein paar M<unk> nner und ich habe ein paar M<unk> nner und ich habe ein paar M<unk> nner und das ist ein paar M<unk> nner und das ist ein paar M<unk> nner und das ist ein paar M<unk> nner und das ist ein paar Methode und das Gen<unk> ndchen und das ist ein paar M<unk> nner und das ist das F<unk> hrer und das ist das nicht nur ein paar M<unk> ngro<unk> e und das ist das Folerl<unk>
2025-05-29 19:20:09,315 - INFO - joeynmt.training - Example #2
2025-05-29 19:20:09,315 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:20:09,315 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:20:09,315 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'ein', 'paar', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'ich', 'habe', 'ein', 'paar', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'ich', 'habe', 'ein', 'paar', 'M@@', 'et@@', 'ho@@', 'de', 'und', 'ich', 'habe', 'ein', 'paar', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'das', 'ist', 'das', 'ein', 'paar', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'das', 'ist', 'ein', 'paar', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'das', 'ist', 'ein', 'paar', 'M@@', 'et@@', 'ho@@', 'de', 'und', 'das', 'G@@', 'en@@', '<unk>', 'n@@', 'der@@', 'n', 'und', 'das', 'ist', 'ein', 'paar', 'W@@', 'o@@', 'ch@@', 'er', 'zu', 'er@@', 'rei@@', 'b@@', 'en.', '</s>']
2025-05-29 19:20:09,316 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:20:09,316 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:20:09,316 - INFO - joeynmt.training - 	Hypothesis: Und ich habe ein paar M<unk> nner und ich habe ein paar M<unk> nner und ich habe ein paar Methode und ich habe ein paar M<unk> nner und das ist das ein paar M<unk> nner und das ist ein paar M<unk> nner und das ist ein paar Methode und das Gen<unk> ndern und das ist ein paar Wocher zu erreiben.
2025-05-29 19:20:09,316 - INFO - joeynmt.training - Example #3
2025-05-29 19:20:09,316 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:20:09,316 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:20:09,316 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'Ihnen', 'Ihnen', 'Ihnen', 'ein', 'paar', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'ich', 'habe', 'ein', 'paar', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'das', 'ist', 'ein', 'paar', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'das', 'ist', 'ein', 'paar', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'das', 'ist', 'ein', 'paar', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'das', 'ist', 'ein', 'paar', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'K@@', '<unk>', 'r@@', 'z@@', 'e', 'und', 'das', 'F@@', '<unk>', 'h@@', 'ig@@', 'kei@@', 'ten', 'zu', 'er@@', 'rei@@', 'b@@', 'en.', '</s>']
2025-05-29 19:20:09,316 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:20:09,316 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:20:09,316 - INFO - joeynmt.training - 	Hypothesis: Und ich habe Ihnen Ihnen Ihnen ein paar M<unk> nner und ich habe ein paar M<unk> nner und das ist ein paar M<unk> nner und das ist ein paar M<unk> nner und das ist ein paar M<unk> nner und das ist ein paar M<unk> nner und die K<unk> rze und das F<unk> higkeiten zu erreiben.
2025-05-29 19:20:09,316 - INFO - joeynmt.training - Example #4
2025-05-29 19:20:09,316 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:20:09,316 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:20:09,316 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'Ihnen', 'Ihnen', 'Ihnen', 'ein', 'paar', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'ich', 'habe', 'ein', 'paar', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'ich', 'habe', 'ich', 'ich', 'das', 'nicht', 'nicht', 'nur', 'ein', 'paar', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'das', 'ist', 'das', 'das', 'nicht', 'nur', 'ein', 'paar', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'das', 'ist', 'ein', 'paar', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'das', 'ist', 'ein', 'paar', 'M@@', 'et@@', 'ho@@', 'de', 'und', 'ich', 'habe', 'ein', 'paar', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'K@@', '<unk>', 'r@@', 'z@@', 'te', 'ich', 'das', 'F@@', '<unk>', 'hr@@', 'er', 'und', 'das', 'ist', 'ein', 'paar', 'M@@', '<unk>', 'n@@', 'der@@', 'es', 'zu', 'er@@', 'rei@@', 'b@@', 'en.', '</s>']
2025-05-29 19:20:09,317 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:20:09,317 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:20:09,317 - INFO - joeynmt.training - 	Hypothesis: Und ich habe Ihnen Ihnen Ihnen ein paar M<unk> nner und ich habe ein paar M<unk> nner und ich habe ich ich das nicht nicht nur ein paar M<unk> nner und das ist das das nicht nur ein paar M<unk> nner und das ist ein paar M<unk> nner und das ist ein paar Methode und ich habe ein paar M<unk> nner und die K<unk> rzte ich das F<unk> hrer und das ist ein paar M<unk> nderes zu erreiben.
2025-05-29 19:20:11,574 - INFO - joeynmt.training - Epoch   1, Step:     4100, Batch Loss:     2.643080, Batch Acc: 0.209320, Tokens per Sec:    28401, Lr: 0.000300
2025-05-29 19:20:13,702 - INFO - joeynmt.training - Epoch   1, Step:     4200, Batch Loss:     2.712423, Batch Acc: 0.210510, Tokens per Sec:    32727, Lr: 0.000300
2025-05-29 19:20:15,747 - INFO - joeynmt.training - Epoch   1, Step:     4300, Batch Loss:     2.705442, Batch Acc: 0.210423, Tokens per Sec:    35276, Lr: 0.000300
2025-05-29 19:20:17,689 - INFO - joeynmt.training - Epoch   1, Step:     4400, Batch Loss:     2.739578, Batch Acc: 0.212618, Tokens per Sec:    36457, Lr: 0.000300
2025-05-29 19:20:20,000 - INFO - joeynmt.training - Epoch   1, Step:     4500, Batch Loss:     2.707976, Batch Acc: 0.215800, Tokens per Sec:    30548, Lr: 0.000300
2025-05-29 19:20:20,000 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:20:20,001 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:20:35,020 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.65, ppl:  14.13, acc:   0.22, generation: 15.0064[sec], evaluation: 0.0000[sec]
2025-05-29 19:20:35,021 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:20:35,119 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/2000.ckpt
2025-05-29 19:20:35,126 - INFO - joeynmt.training - Example #0
2025-05-29 19:20:35,126 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:20:35,126 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:20:35,126 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'denk@@', 'e,', 'dass', 'wir', 'die', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 't,', 'die', 'die', 'die', 'K@@', '<unk>', 'r@@', 'per@@', 'f@@', 'ek@@', 'te', 'und', 'die', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', 'st@@', '<unk>', 'n@@', 'd@@', 'chen', 'und', 'die', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'und', 'der', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:20:35,126 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:20:35,126 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:20:35,126 - INFO - joeynmt.training - 	Hypothesis: Und ich denke, dass wir die M<unk> nner und die M<unk> nner und die M<unk> nner und die M<unk> nner und die M<unk> glichkeit, die die die K<unk> rperfekte und die M<unk> nner und die M<unk> nner und die M<unk> nner und die K<unk> rper zu verst<unk> ndchen und die M<unk> nner und die M<unk> nner und die M<unk> glichkeit und der K<unk> rper zu ver<unk> ndern.
2025-05-29 19:20:35,126 - INFO - joeynmt.training - Example #1
2025-05-29 19:20:35,126 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:20:35,126 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:20:35,126 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'denk@@', 'e,', 'dass', 'wir', 'die', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 't,', 'die', 'die', 'die', 'K@@', '<unk>', 'r@@', 'per@@', 'f@@', 'ek@@', 'te', 'und', 'die', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', 'st@@', '<unk>', 'n@@', 'd@@', 'chen', 'und', 'die', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ner', 'und', 'die', 'M@@', '<unk>', 'r@@', 'k@@', '<unk>', 'n@@', 'n@@']
2025-05-29 19:20:35,126 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:20:35,127 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:20:35,127 - INFO - joeynmt.training - 	Hypothesis: Und ich denke, dass wir die M<unk> nner und die M<unk> nner und die M<unk> nner und die M<unk> nner und die M<unk> glichkeit, die die die K<unk> rperfekte und die M<unk> nner und die M<unk> nner und die M<unk> nner und die K<unk> rper zu verst<unk> ndchen und die M<unk> nner und die M<unk> nner und die M<unk> glichkeiten und die M<unk> nnner und die M<unk> rk<unk> nn
2025-05-29 19:20:35,127 - INFO - joeynmt.training - Example #2
2025-05-29 19:20:35,127 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:20:35,127 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:20:35,127 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'denk@@', 'e,', 'dass', 'wir', 'die', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 't,', 'die', 'die', 'die', 'K@@', '<unk>', 'r@@', 'per@@', 'f@@', 'ek@@', 'te', 'und', 'die', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', 'st@@', '<unk>', 'n@@', 'd@@', 'chen', 'und', 'die', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'und', 'der', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:20:35,127 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:20:35,127 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:20:35,127 - INFO - joeynmt.training - 	Hypothesis: Und ich denke, dass wir die M<unk> nner und die M<unk> nner und die M<unk> nner und die M<unk> nner und die M<unk> glichkeit, die die die K<unk> rperfekte und die M<unk> nner und die M<unk> nner und die M<unk> nner und die K<unk> rper zu verst<unk> ndchen und die M<unk> nner und die M<unk> nner und die M<unk> glichkeit und der K<unk> rper zu ver<unk> ndern.
2025-05-29 19:20:35,127 - INFO - joeynmt.training - Example #3
2025-05-29 19:20:35,127 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:20:35,127 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:20:35,127 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'denk@@', 'e,', 'dass', 'wir', 'die', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'und', 'der', 'K@@', 'rank@@', 'hei@@', 'ten', 'und', 'die', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', 'st@@', '<unk>', 'n@@', 'd@@', 'chen', 'und', 'die', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'M@@', '<unk>', 'r@@', 'k@@', '<unk>', 'n@@', 'n@@', 'n@@', 'en.', '</s>']
2025-05-29 19:20:35,127 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:20:35,127 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:20:35,127 - INFO - joeynmt.training - 	Hypothesis: Und ich denke, dass wir die M<unk> nner und die M<unk> nner und die M<unk> nner und die M<unk> nner und die M<unk> nner und die M<unk> glichkeit und der Krankheiten und die M<unk> nner und die M<unk> nner und die M<unk> nner und die K<unk> rper zu verst<unk> ndchen und die M<unk> nner und die M<unk> rk<unk> nnnen.
2025-05-29 19:20:35,127 - INFO - joeynmt.training - Example #4
2025-05-29 19:20:35,127 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:20:35,128 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:20:35,128 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'denk@@', 'e,', 'dass', 'wir', 'die', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'von', 'der', 'K@@', 'rank@@', 'en@@', 'h@@', '<unk>', 'r@@', 'en', 'und', 'die', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'K@@', 'rank@@', 'en@@', 'h@@', '<unk>', 'r@@', 'en', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', 'st@@', '<unk>', 'n@@', 'd@@', 'chen', 'und', 'die', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ner', 'und', 'die', 'K@@', '<unk>', 'r@@', 'k@@', '<unk>', 'n@@']
2025-05-29 19:20:35,128 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:20:35,128 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:20:35,128 - INFO - joeynmt.training - 	Hypothesis: Und ich denke, dass wir die M<unk> nner und die M<unk> nner und die M<unk> nner und die M<unk> nner und die M<unk> nner und die M<unk> glichkeit von der Krankenh<unk> ren und die M<unk> nner und die Krankenh<unk> ren und die K<unk> rper zu verst<unk> ndchen und die M<unk> nner und die M<unk> nner und die M<unk> glichkeiten und die M<unk> nnner und die K<unk> rk<unk> n
2025-05-29 19:20:37,329 - INFO - joeynmt.training - Epoch   1, Step:     4600, Batch Loss:     2.643873, Batch Acc: 0.218515, Tokens per Sec:    31070, Lr: 0.000300
2025-05-29 19:20:39,592 - INFO - joeynmt.training - Epoch   1, Step:     4700, Batch Loss:     2.702773, Batch Acc: 0.221766, Tokens per Sec:    31039, Lr: 0.000300
2025-05-29 19:20:41,854 - INFO - joeynmt.training - Epoch   1, Step:     4800, Batch Loss:     2.622851, Batch Acc: 0.223049, Tokens per Sec:    31306, Lr: 0.000300
2025-05-29 19:20:43,987 - INFO - joeynmt.training - Epoch   1, Step:     4900, Batch Loss:     2.582315, Batch Acc: 0.224424, Tokens per Sec:    33882, Lr: 0.000300
2025-05-29 19:20:46,255 - INFO - joeynmt.training - Epoch   1, Step:     5000, Batch Loss:     2.989125, Batch Acc: 0.223687, Tokens per Sec:    31834, Lr: 0.000300
2025-05-29 19:20:46,256 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:20:46,256 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:21:02,516 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.61, ppl:  13.55, acc:   0.23, generation: 16.2465[sec], evaluation: 0.0000[sec]
2025-05-29 19:21:02,517 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:21:02,610 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/2500.ckpt
2025-05-29 19:21:02,615 - INFO - joeynmt.training - Example #0
2025-05-29 19:21:02,615 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:21:02,615 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:21:02,615 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'denk@@', 'e,', 'dass', 'es', 'nicht', 'nur', 'die', 'K@@', '<unk>', 'r@@', 'z@@', 'te', 'ich', 'mich', 'in', 'der', 'K@@', '<unk>', 'r@@', 'z@@', 'te', 'der', 'K@@', '<unk>', 'r@@', 'per@@', 'ten', 'und', 'die', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per@@', 'ten', 'und', 'die', 'K@@', '<unk>', 'r@@', 'z@@', 'te', 'der', 'K@@', '<unk>', 'r@@', 'per@@', 'per@@', 'f@@', 'ek@@', 'te', 'M@@', 'it@@', 'ge@@', 'f@@', '<unk>', 'h@@', 'l@@', 't', 'und', 'die', 'K@@', '<unk>', 'r@@', 'z@@', 'te', 'der', 'K@@', '<unk>', 'r@@', 'z@@', 'te', 'und', 'die', 'K@@', '<unk>', 'n@@', 'st@@', 'er', 'und', 'die', 'K@@', '<unk>', 'r@@', 'k@@', 'te', 'ich', 'in', 'der', 'K@@', '<unk>', 'n@@', 'st@@', 'er', 'zu', 'er@@', 'm@@', '<unk>', 'ss@@', 'en', 'und', 'die', 'K@@', '<unk>', 'n@@']
2025-05-29 19:21:02,615 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:21:02,615 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:21:02,615 - INFO - joeynmt.training - 	Hypothesis: Und ich denke, dass es nicht nur die K<unk> rzte ich mich in der K<unk> rzte der K<unk> rperten und die M<unk> nner und die K<unk> rperten und die K<unk> rzte der K<unk> rperperfekte Mitgef<unk> hlt und die K<unk> rzte der K<unk> rzte und die K<unk> nster und die K<unk> rkte ich in der K<unk> nster zu erm<unk> ssen und die K<unk> n
2025-05-29 19:21:02,615 - INFO - joeynmt.training - Example #1
2025-05-29 19:21:02,615 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:21:02,616 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:21:02,616 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'mich', 'mich', 'in', 'der', 'K@@', '<unk>', 'r@@', 'per', 'in', 'der', 'K@@', '<unk>', 'r@@', 'z@@', 'te', 'der', 'K@@', '<unk>', 'n@@', 'st@@', 'er', 'und', 'die', 'K@@', '<unk>', 'r@@', 'z@@', 'te', 'ich', 'mich', 'zu', 'er@@', 'stell@@', 'en,', 'dass', 'es', 'nicht', 'nur', 'ein', 'paar', 'Jahren', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:21:02,616 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:21:02,616 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:21:02,616 - INFO - joeynmt.training - 	Hypothesis: Und ich habe mich mich in der K<unk> rper in der K<unk> rzte der K<unk> nster und die K<unk> rzte ich mich zu erstellen, dass es nicht nur ein paar Jahren zu erreichen.
2025-05-29 19:21:02,616 - INFO - joeynmt.training - Example #2
2025-05-29 19:21:02,616 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:21:02,616 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:21:02,616 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'mich', 'mich', 'in', 'der', 'K@@', '<unk>', 'r@@', 'per', 'in', 'der', 'K@@', '<unk>', 'r@@', 'z@@', 'te', 'der', 'K@@', '<unk>', 'n@@', 'st@@', 'er', 'und', 'die', 'K@@', '<unk>', 'r@@', 'z@@', 'te', 'ich', 'mich', 'in', 'der', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per@@', 'per@@', 'ten', 'und', 'die', 'K@@', '<unk>', 'n@@', 'st@@', 'er', 'und', 'die', 'K@@', '<unk>', 'r@@', 'z@@', 'te', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per@@', 'ten', 'und', 'die', 'K@@', '<unk>', 'r@@', 'der@@', 'n', 'und', 'die', 'K@@', '<unk>', 'r@@', 'z@@', 'te', 'ich', 'mich', 'in', 'der', 'K@@', '<unk>', 'r@@', 'der@@', 'n', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per@@', 'per@@', 'per@@', 'per@@', 'per@@', 'im@@', 'ent', 'der', 'K@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:21:02,616 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:21:02,616 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:21:02,616 - INFO - joeynmt.training - 	Hypothesis: Und ich habe mich mich in der K<unk> rper in der K<unk> rzte der K<unk> nster und die K<unk> rzte ich mich in der K<unk> rper und die K<unk> rperperten und die K<unk> nster und die K<unk> rzte und die K<unk> rperten und die K<unk> rdern und die K<unk> rzte ich mich in der K<unk> rdern und die K<unk> rperperperperperiment der K<unk> ndern.
2025-05-29 19:21:02,616 - INFO - joeynmt.training - Example #3
2025-05-29 19:21:02,616 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:21:02,616 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:21:02,616 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'mich', 'in', 'der', 'K@@', '<unk>', 'r@@', 'per', 'in', 'der', 'K@@', '<unk>', 'r@@', 'z@@', 'te', 'der', 'K@@', '<unk>', 'r@@', 'z@@', 'te', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per@@', 'ten', 'und', 'die', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per@@', 'ten', 'und', 'die', 'K@@', '<unk>', 'r@@', 'z@@', 'te', 'und', 'die', 'K@@', '<unk>', 'r@@', 'der@@', 'n', 'und', 'die', 'K@@', '<unk>', 'r@@', 'z@@', 'te', 'und', 'die', 'K@@', '<unk>', 'r@@', 'der@@', 'n', 'und', 'die', 'K@@', '<unk>', 'r@@', 'z@@', 'te', 'und', 'die', 'K@@', '<unk>', 'n@@', 'st@@', 'er', 'und', 'die', 'K@@', '<unk>', 'r@@', 'k@@', 'te', 'ich', 'in', 'der', 'K@@', '<unk>', 'r@@', 'der@@', 'n', 'und', 'die', 'K@@', '<unk>', 'r@@', 'z@@', 'te', 'ich', 'in', 'der', 'K@@', '<unk>']
2025-05-29 19:21:02,616 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:21:02,616 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:21:02,616 - INFO - joeynmt.training - 	Hypothesis: Und ich habe mich in der K<unk> rper in der K<unk> rzte der K<unk> rzte und die K<unk> rperten und die M<unk> nner und die K<unk> rperten und die K<unk> rzte und die K<unk> rdern und die K<unk> rzte und die K<unk> rdern und die K<unk> rzte und die K<unk> nster und die K<unk> rkte ich in der K<unk> rdern und die K<unk> rzte ich in der K<unk>
2025-05-29 19:21:02,617 - INFO - joeynmt.training - Example #4
2025-05-29 19:21:02,617 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:21:02,617 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:21:02,617 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'denk@@', 'e,', 'dass', 'es', 'nicht', 'nur', 'die', 'K@@', '<unk>', 'r@@', 'z@@', 'te', 'ich', 'mich', 'in', 'der', 'K@@', '<unk>', 'r@@', 'z@@', 'te', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per@@', 'ten', 'und', 'die', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per@@', 'ten', 'und', 'die', 'K@@', '<unk>', 'r@@', 'der@@', 'n', 'und', 'die', 'K@@', '<unk>', 'r@@', 'z@@', 'te', 'der', 'K@@', '<unk>', 'r@@', 'z@@', 'te', 'und', 'die', 'K@@', '<unk>', 'r@@', 'z@@', 'te', 'der', 'K@@', '<unk>', 'r@@', 'per@@', 'per@@', 'per@@', 'per@@', 'iment@@', '.', '</s>']
2025-05-29 19:21:02,617 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:21:02,617 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:21:02,617 - INFO - joeynmt.training - 	Hypothesis: Und ich denke, dass es nicht nur die K<unk> rzte ich mich in der K<unk> rzte und die K<unk> rperten und die M<unk> nner und die K<unk> rperten und die K<unk> rdern und die K<unk> rzte der K<unk> rzte und die K<unk> rzte der K<unk> rperperperperiment.
2025-05-29 19:21:04,584 - INFO - joeynmt.training - Epoch   1, Step:     5100, Batch Loss:     2.569785, Batch Acc: 0.227250, Tokens per Sec:    34390, Lr: 0.000300
2025-05-29 19:21:06,465 - INFO - joeynmt.training - Epoch   1, Step:     5200, Batch Loss:     2.589182, Batch Acc: 0.226137, Tokens per Sec:    36843, Lr: 0.000300
2025-05-29 19:21:08,349 - INFO - joeynmt.training - Epoch   1, Step:     5300, Batch Loss:     2.613891, Batch Acc: 0.232472, Tokens per Sec:    38295, Lr: 0.000300
2025-05-29 19:21:09,190 - INFO - joeynmt.training - Epoch   1: total training loss 16211.12
2025-05-29 19:21:09,190 - INFO - joeynmt.training - EPOCH 2
2025-05-29 19:21:10,223 - INFO - joeynmt.training - Epoch   2, Step:     5400, Batch Loss:     2.598426, Batch Acc: 0.237436, Tokens per Sec:    39079, Lr: 0.000300
2025-05-29 19:21:12,045 - INFO - joeynmt.training - Epoch   2, Step:     5500, Batch Loss:     2.462383, Batch Acc: 0.234445, Tokens per Sec:    38461, Lr: 0.000300
2025-05-29 19:21:12,045 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:21:12,045 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:21:27,113 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.59, ppl:  13.29, acc:   0.23, generation: 15.0505[sec], evaluation: 0.0000[sec]
2025-05-29 19:21:27,114 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:21:27,207 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/3000.ckpt
2025-05-29 19:21:27,213 - INFO - joeynmt.training - Example #0
2025-05-29 19:21:27,213 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:21:27,213 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:21:27,213 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'bin', 'ein', 'paar', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'S@@', 'ache', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'und', 'die', 'S@@', 'ache', 'und', 'die', 'S@@', 'ache', 'und', 'die', 'S@@', 'ache', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'und', 'die', 'S@@', 'ache', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'und', 'die', 'S@@', 'ache', 'und', 'die', 'S@@', 'ache', 'und', 'die', 'S@@', 'ache', 'und', 'die', 'S@@', 'ache', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'und', 'die', 'S@@', 'pr@@', 'ache', 'und', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'und', 'die', 'S@@', 'pr@@', 'ache', 'und', 'und', 'die', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'S@@', 'pr@@', 'ache', 'und', 'und']
2025-05-29 19:21:27,214 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:21:27,214 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:21:27,214 - INFO - joeynmt.training - 	Hypothesis: Und ich bin ein paar M<unk> nner und die Sache und die M<unk> glichkeit und die Sache und die Sache und die Sache und die M<unk> glichkeit und die M<unk> glichkeit und die Sache und die M<unk> glichkeit und die M<unk> glichkeit und die Sache und die Sache und die Sache und die Sache und die M<unk> glichkeit und die Sprache und und die M<unk> glichkeit und die Sprache und und die M<unk> nner und die Sprache und und
2025-05-29 19:21:27,214 - INFO - joeynmt.training - Example #1
2025-05-29 19:21:27,214 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:21:27,214 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:21:27,214 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'bin', 'nicht', 'nur', 'die', 'S@@', 'ache', 'und', 'ich', 'denk@@', 'e,', 'dass', 'wir', 'uns', 'die', 'S@@', 'ache', 'und', 'die', 'S@@', 'ache', 'und', 'die', 'S@@', 'ache', 'und', 'die', 'S@@', 'ache', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'und', 'die', 'S@@', 'ache', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'und', 'die', 'F@@', '<unk>', 'h@@', 'ig@@', 'kei@@', 'ten', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:21:27,214 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:21:27,214 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:21:27,214 - INFO - joeynmt.training - 	Hypothesis: Und ich bin nicht nur die Sache und ich denke, dass wir uns die Sache und die Sache und die Sache und die Sache und die M<unk> glichkeit und die M<unk> glichkeit und die Sache und die M<unk> glichkeit und die M<unk> glichkeit und die F<unk> higkeiten zu erreichen.
2025-05-29 19:21:27,214 - INFO - joeynmt.training - Example #2
2025-05-29 19:21:27,214 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:21:27,215 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:21:27,215 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'denk@@', 'e,', 'dass', 'wir', 'die', 'S@@', 'ache', 'und', 'ich', 'denk@@', 'e,', 'dass', 'wir', 'uns', 'die', 'S@@', 'ache', 'und', 'die', 'S@@', 'ache', 'und', 'die', 'S@@', 'ache', 'und', 'die', 'S@@', 'ache', 'und', 'die', 'S@@', 'pr@@', 'ache', 'und', 'die', 'S@@', 'ache', 'und', 'die', 'S@@', 'ache', 'und', 'die', 'S@@', 'ache', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'und', 'die', 'S@@', 'ache', 'und', 'die', 'S@@', 'ache', 'und', 'die', 'S@@', 'pr@@', 'ache', 'und', 'und', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'und', 'die', 'S@@', 'pr@@', 'ache', 'und', 'und', 'die', 'F@@', '<unk>', 'h@@', 'ig@@', 'kei@@', 'ten', 'und', 'die', 'S@@', 'ache', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'und', 'die', 'S@@', '<unk>', 'n@@', 'der@@']
2025-05-29 19:21:27,215 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:21:27,215 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:21:27,215 - INFO - joeynmt.training - 	Hypothesis: Und ich denke, dass wir die Sache und ich denke, dass wir uns die Sache und die Sache und die Sache und die Sache und die Sprache und die Sache und die Sache und die Sache und die M<unk> glichkeit und die M<unk> glichkeit und die Sache und die Sache und die Sprache und und und die M<unk> glichkeit und die Sprache und und die F<unk> higkeiten und die Sache und die M<unk> glichkeiten und die S<unk> nder
2025-05-29 19:21:27,215 - INFO - joeynmt.training - Example #3
2025-05-29 19:21:27,215 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:21:27,215 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:21:27,215 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'bin', 'ein', 'paar', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 't,', 'die', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 't,', 'die', 'die', 'die', 'S@@', 'ache', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'und', 'die', 'F@@', '<unk>', 'h@@', 'ig@@', 'kei@@', 't,', 'die', 'die', 'F@@', '<unk>', 'h@@', 'ig@@', 'kei@@', 'ten', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:21:27,215 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:21:27,215 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:21:27,215 - INFO - joeynmt.training - 	Hypothesis: Und ich bin ein paar M<unk> nner und die M<unk> glichkeit, die die M<unk> glichkeit, die die die Sache und die M<unk> glichkeit und die F<unk> higkeit, die die F<unk> higkeiten zu erreichen.
2025-05-29 19:21:27,215 - INFO - joeynmt.training - Example #4
2025-05-29 19:21:27,215 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:21:27,215 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:21:27,215 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'denk@@', 'e,', 'dass', 'wir', 'die', 'S@@', 'ache', 'und', 'ich', 'denk@@', 'e,', 'dass', 'wir', 'uns', 'die', 'S@@', 'ache', 'und', 'die', 'S@@', 'ache', 'und', 'die', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'S@@', 'pr@@', 'ache', 'und', 'und', 'die', 'S@@', 'ache', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'und', 'die', 'S@@', 'ache', 'und', 'die', 'S@@', 'ache', 'und', 'die', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'S@@', 'pr@@', 'ache', 'und', 'und', 'die', 'S@@', '<unk>', 'n@@', 'de', 'und', 'die', 'S@@', 'ache', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'und', 'die', 'S@@', 'pr@@', 'ache', 'und', 'und', 'die', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'S@@', 'pr@@', 'ache', 'und', 'und']
2025-05-29 19:21:27,216 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:21:27,216 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:21:27,216 - INFO - joeynmt.training - 	Hypothesis: Und ich denke, dass wir die Sache und ich denke, dass wir uns die Sache und die Sache und die M<unk> nner und die Sprache und und die Sache und die M<unk> glichkeit und die M<unk> glichkeit und die M<unk> glichkeit und die Sache und die Sache und die M<unk> nner und die Sprache und und die S<unk> nde und die Sache und die M<unk> glichkeit und die Sprache und und die M<unk> nner und die Sprache und und
2025-05-29 19:21:30,285 - INFO - joeynmt.training - Epoch   2, Step:     5600, Batch Loss:     2.604553, Batch Acc: 0.237062, Tokens per Sec:    22030, Lr: 0.000300
2025-05-29 19:21:32,208 - INFO - joeynmt.training - Epoch   2, Step:     5700, Batch Loss:     2.528632, Batch Acc: 0.236090, Tokens per Sec:    36868, Lr: 0.000300
2025-05-29 19:21:34,112 - INFO - joeynmt.training - Epoch   2, Step:     5800, Batch Loss:     2.528902, Batch Acc: 0.236504, Tokens per Sec:    37331, Lr: 0.000300
2025-05-29 19:21:36,108 - INFO - joeynmt.training - Epoch   2, Step:     5900, Batch Loss:     2.562295, Batch Acc: 0.237342, Tokens per Sec:    34770, Lr: 0.000300
2025-05-29 19:21:38,021 - INFO - joeynmt.training - Epoch   2, Step:     6000, Batch Loss:     2.436916, Batch Acc: 0.241264, Tokens per Sec:    36632, Lr: 0.000300
2025-05-29 19:21:38,021 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:21:38,021 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:21:53,557 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.56, ppl:  12.91, acc:   0.24, generation: 15.5153[sec], evaluation: 0.0000[sec]
2025-05-29 19:21:53,557 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:21:53,648 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/3500.ckpt
2025-05-29 19:21:53,654 - INFO - joeynmt.training - Example #0
2025-05-29 19:21:53,654 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:21:53,654 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:21:53,654 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'ein', 'paar', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', 'st@@', '<unk>', 'n@@', 'd@@', 'lich', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', 'st@@', '<unk>', 'n@@', 'd@@', 'lich', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@']
2025-05-29 19:21:53,654 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:21:53,654 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:21:53,654 - INFO - joeynmt.training - 	Hypothesis: Und das ist ein paar M<unk> nner und die K<unk> rper und die K<unk> rper und die K<unk> rper und die K<unk> rper zu verst<unk> ndlich und die K<unk> rper und die K<unk> rper und die K<unk> rper zu verst<unk> ndlich und die K<unk> rper und die K<unk> rper und die K<unk> rper und die K<unk> rper und die K<unk> rper und die K<unk> rper und die K<unk> rper und die K<unk> r
2025-05-29 19:21:53,654 - INFO - joeynmt.training - Example #1
2025-05-29 19:21:53,654 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:21:53,655 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:21:53,655 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'mich', 'mich', 'nicht', 'nur', 'die', 'K@@', '<unk>', 'n@@', 'st@@', 'ler', 'und', 'die', 'K@@', '<unk>', 'r@@', 'k@@', 'er', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', 'st@@', '<unk>', 'n@@', 'd@@', 'lich', 'zu', 'ver@@', 'st@@', '<unk>', 'n@@', 'd@@', 'lich', 'zu', 'ver@@', 'st@@', '<unk>', 'n@@', 'd@@', 'ni@@', 's', 'zu', 'ver@@', 'st@@', '<unk>', 'n@@', 'd@@', 'et.', '</s>']
2025-05-29 19:21:53,655 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:21:53,655 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:21:53,655 - INFO - joeynmt.training - 	Hypothesis: Ich habe mich mich nicht nur die K<unk> nstler und die K<unk> rker und die K<unk> rper und die K<unk> rper und die K<unk> rper und die K<unk> rper und die K<unk> rper und die K<unk> rper zu verst<unk> ndlich zu verst<unk> ndlich zu verst<unk> ndnis zu verst<unk> ndet.
2025-05-29 19:21:53,655 - INFO - joeynmt.training - Example #2
2025-05-29 19:21:53,655 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:21:53,655 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:21:53,655 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'mich', 'mich', 'mit', 'der', 'K@@', '<unk>', 'n@@', 'st@@', 'ler', 'und', 'die', 'K@@', '<unk>', 'r@@', 'k@@', 'er', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', 'st@@', '<unk>', 'n@@', 'd@@', 'lich', 'zu', 'er@@', 'rei@@', 'chen,', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', 'st@@', '<unk>', 'n@@', 'd@@', 'lich', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:21:53,656 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:21:53,656 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:21:53,656 - INFO - joeynmt.training - 	Hypothesis: Ich habe mich mich mit der K<unk> nstler und die K<unk> rker und die K<unk> rper und die K<unk> rper und die K<unk> rper zu verst<unk> ndlich zu erreichen, und die K<unk> rper zu verst<unk> ndlich zu erreichen.
2025-05-29 19:21:53,656 - INFO - joeynmt.training - Example #3
2025-05-29 19:21:53,656 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:21:53,656 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:21:53,656 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'ein', 'paar', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', 'st@@', '<unk>', 'n@@', 'd@@', 'lich', 'zu', 'ver@@', 'st@@', '<unk>', 'n@@', 'd@@', 'lich', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', 'st@@', '<unk>', 'n@@', 'd@@', 'lich', 'zu', 'ver@@', 'st@@', '<unk>', 'n@@', 'd@@', 'lich', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', 'st@@', '<unk>', 'n@@', 'd@@', 'lich', 'zu', 'ver@@', 'st@@', '<unk>', 'n@@', 'd@@', 'et.', '</s>']
2025-05-29 19:21:53,656 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:21:53,656 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:21:53,656 - INFO - joeynmt.training - 	Hypothesis: Und das ist ein paar M<unk> nner und die K<unk> rper und die K<unk> rper und die K<unk> rper und die K<unk> rper zu verst<unk> ndlich zu verst<unk> ndlich und die K<unk> rper zu verst<unk> ndlich zu verst<unk> ndlich und die K<unk> rper zu verst<unk> ndlich zu verst<unk> ndet.
2025-05-29 19:21:53,656 - INFO - joeynmt.training - Example #4
2025-05-29 19:21:53,656 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:21:53,656 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:21:53,656 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'ein', 'paar', 'M@@', '<unk>', 'glich@@', 'kei@@', 't,', 'die', 'die', 'ich', 'in', 'der', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per@@', 's', 'zu', 'ver@@', 'st@@', '<unk>', 'n@@', 'd@@', 'et.', '</s>']
2025-05-29 19:21:53,657 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:21:53,657 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:21:53,657 - INFO - joeynmt.training - 	Hypothesis: Und das ist ein paar M<unk> glichkeit, die die ich in der K<unk> rper und die K<unk> rper und die K<unk> rper und die K<unk> rper und die K<unk> rper und die K<unk> rper und die K<unk> rper und die K<unk> rper und die K<unk> rper und die K<unk> rper und die K<unk> rpers zu verst<unk> ndet.
2025-05-29 19:21:55,878 - INFO - joeynmt.training - Epoch   2, Step:     6100, Batch Loss:     2.620360, Batch Acc: 0.239838, Tokens per Sec:    29727, Lr: 0.000300
2025-05-29 19:21:58,056 - INFO - joeynmt.training - Epoch   2, Step:     6200, Batch Loss:     2.520345, Batch Acc: 0.244379, Tokens per Sec:    32027, Lr: 0.000300
2025-05-29 19:22:00,414 - INFO - joeynmt.training - Epoch   2, Step:     6300, Batch Loss:     2.524541, Batch Acc: 0.244953, Tokens per Sec:    29480, Lr: 0.000300
2025-05-29 19:22:03,271 - INFO - joeynmt.training - Epoch   2, Step:     6400, Batch Loss:     2.459820, Batch Acc: 0.239814, Tokens per Sec:    24531, Lr: 0.000300
2025-05-29 19:22:05,307 - INFO - joeynmt.training - Epoch   2, Step:     6500, Batch Loss:     2.563037, Batch Acc: 0.243498, Tokens per Sec:    34402, Lr: 0.000300
2025-05-29 19:22:05,308 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:22:05,308 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:22:19,544 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.54, ppl:  12.65, acc:   0.25, generation: 14.2236[sec], evaluation: 0.0000[sec]
2025-05-29 19:22:19,544 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:22:19,630 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/4000.ckpt
2025-05-29 19:22:19,635 - INFO - joeynmt.training - Example #0
2025-05-29 19:22:19,636 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:22:19,636 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:22:19,636 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'denk@@', 'e,', 'dass', 'ich', 'die', 'M@@', '<unk>', 'r@@', 'k@@', 'e', 'von', 'Ihnen', 'ein', 'paar', 'M@@', '<unk>', 'r@@', 'k@@', 'er', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per@@', 'te', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:22:19,636 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:22:19,636 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:22:19,636 - INFO - joeynmt.training - 	Hypothesis: Und ich denke, dass ich die M<unk> rke von Ihnen ein paar M<unk> rker und die K<unk> rperte zu erreichen.
2025-05-29 19:22:19,636 - INFO - joeynmt.training - Example #1
2025-05-29 19:22:19,636 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:22:19,636 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:22:19,636 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'denk@@', 'e,', 'dass', 'ich', 'die', 'M@@', '<unk>', 'r@@', 'k@@', 'e', 'von', 'Ihnen', 'ein', 'paar', 'M@@', '<unk>', 'r@@', 'k@@', 'er', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per@@', 'te', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:22:19,636 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:22:19,636 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:22:19,636 - INFO - joeynmt.training - 	Hypothesis: Und ich denke, dass ich die M<unk> rke von Ihnen ein paar M<unk> rker und die K<unk> rperte zu erreichen.
2025-05-29 19:22:19,636 - INFO - joeynmt.training - Example #2
2025-05-29 19:22:19,636 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:22:19,636 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:22:19,636 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'denk@@', 'e', 'ich', 'Ihnen', 'sag@@', 'en,', 'dass', 'wir', 'die', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'M@@', '<unk>', 'r@@', 'k@@', 'te', 'in', 'der', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'die', 'wir', 'in', 'der', 'K@@', '<unk>', 'r@@', 'per@@', 's@@', '-@@', 'S@@', '<unk>', 'n@@', 'd@@', 'chen', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per@@', 'te', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:22:19,637 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:22:19,637 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:22:19,637 - INFO - joeynmt.training - 	Hypothesis: Und ich denke ich Ihnen sagen, dass wir die M<unk> nner und die M<unk> rkte in der K<unk> rper, die wir in der K<unk> rpers-S<unk> ndchen und die K<unk> rperte zu erreichen.
2025-05-29 19:22:19,637 - INFO - joeynmt.training - Example #3
2025-05-29 19:22:19,637 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:22:19,637 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:22:19,637 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'denk@@', 'e,', 'dass', 'wir', 'die', 'M@@', '<unk>', 'r@@', 'k@@', 'e', 'von', 'der', 'K@@', '<unk>', 'r@@', 'per@@', 's', 'und', 'die', 'K@@', '<unk>', 'n@@', 'st@@', 'ler', 'und', 'die', 'K@@', '<unk>', 'n@@', 'st@@', 'ler', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per@@', 's@@', '-@@', 'K@@', '<unk>', 'r@@', 'per@@', '.', '</s>']
2025-05-29 19:22:19,637 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:22:19,637 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:22:19,637 - INFO - joeynmt.training - 	Hypothesis: Und ich denke, dass wir die M<unk> rke von der K<unk> rpers und die K<unk> nstler und die K<unk> nstler und die K<unk> rpers-K<unk> rper.
2025-05-29 19:22:19,637 - INFO - joeynmt.training - Example #4
2025-05-29 19:22:19,637 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:22:19,637 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:22:19,637 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'denk@@', 'e', 'ich', 'Ihnen', 'sag@@', 'en,', 'dass', 'wir', 'die', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'M@@', '<unk>', 'r@@', 'k@@', 'te', 'in', 'der', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'die', 'wir', 'in', 'der', 'K@@', '<unk>', 'r@@', 'per@@', 's@@', 'k@@', '<unk>', 'n@@', 'n@@', 'en,', 'dass', 'sie', 'die', 'K@@', '<unk>', 'r@@', 'per@@', 'te', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:22:19,637 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:22:19,637 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:22:19,637 - INFO - joeynmt.training - 	Hypothesis: Und ich denke ich Ihnen sagen, dass wir die M<unk> nner und die M<unk> rkte in der K<unk> rper, die wir in der K<unk> rpersk<unk> nnen, dass sie die K<unk> rperte zu ver<unk> ndern.
2025-05-29 19:22:22,165 - INFO - joeynmt.training - Epoch   2, Step:     6600, Batch Loss:     2.502483, Batch Acc: 0.243853, Tokens per Sec:    27733, Lr: 0.000300
2025-05-29 19:22:24,642 - INFO - joeynmt.training - Epoch   2, Step:     6700, Batch Loss:     2.459121, Batch Acc: 0.243015, Tokens per Sec:    27974, Lr: 0.000300
2025-05-29 19:22:27,036 - INFO - joeynmt.training - Epoch   2, Step:     6800, Batch Loss:     2.490909, Batch Acc: 0.247597, Tokens per Sec:    29858, Lr: 0.000300
2025-05-29 19:22:29,496 - INFO - joeynmt.training - Epoch   2, Step:     6900, Batch Loss:     2.546580, Batch Acc: 0.246088, Tokens per Sec:    28192, Lr: 0.000300
2025-05-29 19:22:31,746 - INFO - joeynmt.training - Epoch   2, Step:     7000, Batch Loss:     2.419857, Batch Acc: 0.242925, Tokens per Sec:    31264, Lr: 0.000300
2025-05-29 19:22:31,746 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:22:31,746 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:22:46,272 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.52, ppl:  12.44, acc:   0.25, generation: 14.5162[sec], evaluation: 0.0000[sec]
2025-05-29 19:22:46,273 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:22:46,366 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/4500.ckpt
2025-05-29 19:22:46,372 - INFO - joeynmt.training - Example #0
2025-05-29 19:22:46,372 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:22:46,372 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:22:46,372 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'Ihnen', 'ein', 'paar', 'Jahren', 'in', 'der', 'K@@', '<unk>', 'r@@', 'per', 'und', 'ich', 'habe', 'einen', 'K@@', 'l@@', '<unk>', 'n@@', 'st@@', 'ler', 'zu', 'er@@', 'inn@@', 'ern@@', ',', 'dass', 'wir', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:22:46,372 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:22:46,372 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:22:46,372 - INFO - joeynmt.training - 	Hypothesis: Und ich habe Ihnen ein paar Jahren in der K<unk> rper und ich habe einen Kl<unk> nstler zu erinnern, dass wir die K<unk> rper zu erreichen.
2025-05-29 19:22:46,372 - INFO - joeynmt.training - Example #1
2025-05-29 19:22:46,373 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:22:46,373 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:22:46,373 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'Ihnen', 'ein', 'paar', 'Jahren', 'er@@', 'h@@', '<unk>', 'h@@', 'l@@', 'en', 'und', 'ich', 'habe', 'nicht', 'nur', 'ein', 'paar', 'Jahren', 'Jahren', 'in', 'der', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:22:46,373 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:22:46,373 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:22:46,373 - INFO - joeynmt.training - 	Hypothesis: Und ich habe Ihnen ein paar Jahren erh<unk> hlen und ich habe nicht nur ein paar Jahren Jahren in der K<unk> rper zu erreichen.
2025-05-29 19:22:46,373 - INFO - joeynmt.training - Example #2
2025-05-29 19:22:46,373 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:22:46,373 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:22:46,373 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'Ihnen', 'ein', 'paar', 'Jahren', 'er@@', 'h@@', '<unk>', 'h@@', 'l@@', 'en', 'und', 'ich', 'habe', 'ein', 'paar', 'Jahren', 'in', 'der', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:22:46,373 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:22:46,373 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:22:46,373 - INFO - joeynmt.training - 	Hypothesis: Und ich habe Ihnen ein paar Jahren erh<unk> hlen und ich habe ein paar Jahren in der K<unk> rper zu erreichen.
2025-05-29 19:22:46,373 - INFO - joeynmt.training - Example #3
2025-05-29 19:22:46,373 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:22:46,373 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:22:46,373 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'Ihnen', 'ein', 'paar', 'M@@', '<unk>', 'n@@', 'n@@', 'chen', 'und', 'die', 'K@@', '<unk>', 'n@@', 'st@@', 'l@@', 'er@@', 'nen', 'wir', 'die', 'K@@', '<unk>', 'n@@', 'st@@', 'l@@', 'er@@', 'nen', 'und', 'die', 'K@@', '<unk>', 'n@@', 'st@@', 'l@@', 'er@@', 'nen', 'wir', 'die', 'K@@', '<unk>', 'n@@', 'st@@', 'l@@', 'er@@', 'nen', 'und', 'die', 'K@@', '<unk>', 'n@@', 'st@@', 'l@@', 'er@@', 'nen', 'wir', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'n@@', 'st@@', 'l@@', 'er@@', 'nen', 'wir', 'die', 'K@@', '<unk>', 'n@@', 'st@@', 'l@@', 'er@@', 'nen', 'und', 'die', 'K@@', '<unk>', 'n@@', 'st@@', '.', '</s>']
2025-05-29 19:22:46,374 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:22:46,374 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:22:46,374 - INFO - joeynmt.training - 	Hypothesis: Und ich habe Ihnen ein paar M<unk> nnchen und die K<unk> nstlernen wir die K<unk> nstlernen und die K<unk> nstlernen wir die K<unk> nstlernen und die K<unk> nstlernen wir die K<unk> rper und die K<unk> nstlernen wir die K<unk> nstlernen und die K<unk> nst.
2025-05-29 19:22:46,374 - INFO - joeynmt.training - Example #4
2025-05-29 19:22:46,374 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:22:46,374 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:22:46,374 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'Ihnen', 'ein', 'paar', 'Jahren', 'in', 'der', 'K@@', '<unk>', 'n@@', 'st@@', 'l@@', 'er@@', 'nen', 'wir', 'die', 'K@@', '<unk>', 'n@@', 'st@@', 'l@@', 'er@@', 'nen', 'und', 'die', 'K@@', '<unk>', 'n@@', 'st@@', 'ler', 'zu', 'er@@', 'inn@@', 'ern@@', '.', '</s>']
2025-05-29 19:22:46,374 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:22:46,374 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:22:46,374 - INFO - joeynmt.training - 	Hypothesis: Und ich habe Ihnen ein paar Jahren in der K<unk> nstlernen wir die K<unk> nstlernen und die K<unk> nstler zu erinnern.
2025-05-29 19:22:48,623 - INFO - joeynmt.training - Epoch   2, Step:     7100, Batch Loss:     2.426031, Batch Acc: 0.246897, Tokens per Sec:    29575, Lr: 0.000300
2025-05-29 19:22:50,858 - INFO - joeynmt.training - Epoch   2, Step:     7200, Batch Loss:     2.544316, Batch Acc: 0.250825, Tokens per Sec:    32282, Lr: 0.000300
2025-05-29 19:22:53,115 - INFO - joeynmt.training - Epoch   2, Step:     7300, Batch Loss:     2.394442, Batch Acc: 0.249002, Tokens per Sec:    29875, Lr: 0.000300
2025-05-29 19:22:55,439 - INFO - joeynmt.training - Epoch   2, Step:     7400, Batch Loss:     2.562515, Batch Acc: 0.249902, Tokens per Sec:    30843, Lr: 0.000300
2025-05-29 19:22:57,613 - INFO - joeynmt.training - Epoch   2, Step:     7500, Batch Loss:     2.466202, Batch Acc: 0.249308, Tokens per Sec:    33398, Lr: 0.000300
2025-05-29 19:22:57,613 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:22:57,613 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:23:11,641 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.50, ppl:  12.16, acc:   0.25, generation: 14.0203[sec], evaluation: 0.0000[sec]
2025-05-29 19:23:11,641 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:23:11,728 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/5000.ckpt
2025-05-29 19:23:11,734 - INFO - joeynmt.training - Example #0
2025-05-29 19:23:11,734 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:23:11,734 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:23:11,734 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'denk@@', 'e,', 'dass', 'wir', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'M@@', '<unk>', 'glich@@', 'kei@@', 't,', 'die', 'wir', 'in', 'der', 'K@@', '<unk>', 'r@@', 'per@@', 's', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:23:11,734 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:23:11,734 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:23:11,734 - INFO - joeynmt.training - 	Hypothesis: Und ich denke, dass wir die M<unk> glichkeit der M<unk> glichkeit, die wir in der K<unk> rpers zu ver<unk> ndern.
2025-05-29 19:23:11,734 - INFO - joeynmt.training - Example #1
2025-05-29 19:23:11,734 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:23:11,734 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:23:11,734 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'denk@@', 'e,', 'dass', 'wir', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'M@@', '<unk>', 'glich@@', 'kei@@', 't,', 'die', 'ich', 'in', 'der', 'Welt', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:23:11,735 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:23:11,735 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:23:11,735 - INFO - joeynmt.training - 	Hypothesis: Und ich denke, dass wir die M<unk> glichkeit der M<unk> glichkeit, die ich in der Welt zu ver<unk> ndern.
2025-05-29 19:23:11,735 - INFO - joeynmt.training - Example #2
2025-05-29 19:23:11,735 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:23:11,735 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:23:11,735 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'denk@@', 'e,', 'dass', 'wir', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'M@@', '<unk>', 'glich@@', 'kei@@', 't,', 'die', 'ich', 'in', 'der', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:23:11,735 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:23:11,735 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:23:11,735 - INFO - joeynmt.training - 	Hypothesis: Und ich denke, dass wir die M<unk> glichkeit der M<unk> glichkeit, die ich in der K<unk> rper zu ver<unk> ndern.
2025-05-29 19:23:11,735 - INFO - joeynmt.training - Example #3
2025-05-29 19:23:11,735 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:23:11,735 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:23:11,735 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'denk@@', 'e,', 'dass', 'wir', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 't,', 'die', 'ich', 'in', 'der', 'Welt', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:23:11,735 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:23:11,736 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:23:11,736 - INFO - joeynmt.training - 	Hypothesis: Und ich denke, dass wir die M<unk> glichkeit, die ich in der Welt zu ver<unk> ndern.
2025-05-29 19:23:11,736 - INFO - joeynmt.training - Example #4
2025-05-29 19:23:11,736 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:23:11,736 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:23:11,736 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'denk@@', 'e,', 'dass', 'wir', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 't,', 'die', 'wir', 'in', 'der', 'Welt', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:23:11,736 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:23:11,736 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:23:11,736 - INFO - joeynmt.training - 	Hypothesis: Und ich denke, dass wir die M<unk> glichkeit, die wir in der Welt zu ver<unk> ndern.
2025-05-29 19:23:14,078 - INFO - joeynmt.training - Epoch   2, Step:     7600, Batch Loss:     2.553495, Batch Acc: 0.249578, Tokens per Sec:    29429, Lr: 0.000300
2025-05-29 19:23:16,382 - INFO - joeynmt.training - Epoch   2, Step:     7700, Batch Loss:     2.395199, Batch Acc: 0.247816, Tokens per Sec:    30864, Lr: 0.000300
2025-05-29 19:23:18,515 - INFO - joeynmt.training - Epoch   2, Step:     7800, Batch Loss:     2.430250, Batch Acc: 0.255744, Tokens per Sec:    32891, Lr: 0.000300
2025-05-29 19:23:20,614 - INFO - joeynmt.training - Epoch   2, Step:     7900, Batch Loss:     2.493195, Batch Acc: 0.255389, Tokens per Sec:    32582, Lr: 0.000300
2025-05-29 19:23:22,863 - INFO - joeynmt.training - Epoch   2, Step:     8000, Batch Loss:     2.528237, Batch Acc: 0.253119, Tokens per Sec:    31133, Lr: 0.000300
2025-05-29 19:23:22,863 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:23:22,863 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:23:32,407 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.49, ppl:  12.03, acc:   0.25, generation: 9.5366[sec], evaluation: 0.0000[sec]
2025-05-29 19:23:32,407 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:23:32,506 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/5500.ckpt
2025-05-29 19:23:32,513 - INFO - joeynmt.training - Example #0
2025-05-29 19:23:32,513 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:23:32,513 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:23:32,513 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'ein', 'paar', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'S@@', 'pr@@', 'ache', 'und', 'die', 'S@@', 'pr@@', 'ache', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:23:32,513 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:23:32,513 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:23:32,513 - INFO - joeynmt.training - 	Hypothesis: Und das ist ein paar M<unk> nner und die Sprache und die Sprache zu erreichen.
2025-05-29 19:23:32,513 - INFO - joeynmt.training - Example #1
2025-05-29 19:23:32,513 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:23:32,514 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:23:32,514 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'ein', 'paar', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'S@@', 'k@@', 'ul@@', 'tu@@', 'r', 'der', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'und', 'ich', 'habe', 'es', 'nicht', 'nur', 'ein', 'paar', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:23:32,514 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:23:32,514 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:23:32,514 - INFO - joeynmt.training - 	Hypothesis: Und das ist ein paar M<unk> nner und die Skultur der K<unk> rper, und ich habe es nicht nur ein paar M<unk> glichkeiten zu erreichen.
2025-05-29 19:23:32,514 - INFO - joeynmt.training - Example #2
2025-05-29 19:23:32,514 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:23:32,514 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:23:32,514 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'ein', 'paar', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'S@@', 'pr@@', 'ache', 'und', 'die', 'S@@', 'pr@@', 'ache', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:23:32,514 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:23:32,514 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:23:32,514 - INFO - joeynmt.training - 	Hypothesis: Und das ist ein paar M<unk> nner und die Sprache und die Sprache zu erreichen.
2025-05-29 19:23:32,514 - INFO - joeynmt.training - Example #3
2025-05-29 19:23:32,514 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:23:32,515 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:23:32,515 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'ein', 'paar', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'S@@', 'k@@', 'el@@', 'b@@', 'st@@', '<unk>', 'n@@', 'di@@', 'g', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:23:32,515 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:23:32,515 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:23:32,515 - INFO - joeynmt.training - 	Hypothesis: Und das ist ein paar M<unk> nner und die Skelbst<unk> ndig zu erreichen.
2025-05-29 19:23:32,515 - INFO - joeynmt.training - Example #4
2025-05-29 19:23:32,515 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:23:32,515 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:23:32,515 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'ein', 'paar', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'S@@', 'pr@@', 'ache', 'und', 'die', 'S@@', 'pr@@', 'ache', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:23:32,515 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:23:32,515 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:23:32,515 - INFO - joeynmt.training - 	Hypothesis: Und das ist ein paar M<unk> nner und die Sprache und die Sprache zu erreichen.
2025-05-29 19:23:34,767 - INFO - joeynmt.training - Epoch   2, Step:     8100, Batch Loss:     2.454135, Batch Acc: 0.253139, Tokens per Sec:    28860, Lr: 0.000300
2025-05-29 19:23:36,979 - INFO - joeynmt.training - Epoch   2, Step:     8200, Batch Loss:     2.508203, Batch Acc: 0.254120, Tokens per Sec:    30973, Lr: 0.000300
2025-05-29 19:23:39,013 - INFO - joeynmt.training - Epoch   2, Step:     8300, Batch Loss:     2.480378, Batch Acc: 0.256374, Tokens per Sec:    35992, Lr: 0.000300
2025-05-29 19:23:42,322 - INFO - joeynmt.training - Epoch   2, Step:     8400, Batch Loss:     2.462232, Batch Acc: 0.254192, Tokens per Sec:    21274, Lr: 0.000300
2025-05-29 19:23:44,588 - INFO - joeynmt.training - Epoch   2, Step:     8500, Batch Loss:     2.517372, Batch Acc: 0.255215, Tokens per Sec:    30829, Lr: 0.000300
2025-05-29 19:23:44,588 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:23:44,588 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:23:59,559 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.48, ppl:  11.91, acc:   0.26, generation: 14.9606[sec], evaluation: 0.0000[sec]
2025-05-29 19:23:59,560 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:23:59,655 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/6000.ckpt
2025-05-29 19:23:59,662 - INFO - joeynmt.training - Example #0
2025-05-29 19:23:59,662 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:23:59,662 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:23:59,662 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'eine', 'M@@', 'en@@', 'ge', 'M@@', 'en@@', 'ge', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per@@', 'n@@', 'en.', '</s>']
2025-05-29 19:23:59,662 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:23:59,662 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:23:59,662 - INFO - joeynmt.training - 	Hypothesis: Und das ist eine Menge Menge und die M<unk> glichkeit und die M<unk> glichkeit und die K<unk> rper und die K<unk> rpernen.
2025-05-29 19:23:59,662 - INFO - joeynmt.training - Example #1
2025-05-29 19:23:59,662 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:23:59,662 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:23:59,662 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'die', 'K@@', '<unk>', 'r@@', 'per', 'ist', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per@@', 'n@@', 'en.', '</s>']
2025-05-29 19:23:59,663 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:23:59,663 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:23:59,663 - INFO - joeynmt.training - 	Hypothesis: Ich habe die K<unk> rper ist die K<unk> rper und die M<unk> glichkeit und die M<unk> glichkeit und die K<unk> rper und die M<unk> glichkeit und die M<unk> glichkeit und die K<unk> rpernen.
2025-05-29 19:23:59,663 - INFO - joeynmt.training - Example #2
2025-05-29 19:23:59,663 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:23:59,663 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:23:59,663 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'eine', 'M@@', 'en@@', 'ge', 'M@@', 'en@@', 'ge', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'und', 'die', 'M@@', '<unk>', 'd@@', 'chen', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per@@', '.', '</s>']
2025-05-29 19:23:59,663 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:23:59,663 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:23:59,663 - INFO - joeynmt.training - 	Hypothesis: Und das ist eine Menge Menge und die M<unk> glichkeit und die M<unk> dchen und die K<unk> rper.
2025-05-29 19:23:59,663 - INFO - joeynmt.training - Example #3
2025-05-29 19:23:59,663 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:23:59,663 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:23:59,663 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'ein', 'paar', 'Jahren', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'er,', 'die', 'wir', 'in', 'der', 'Welt', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:23:59,663 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:23:59,663 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:23:59,663 - INFO - joeynmt.training - 	Hypothesis: Ich habe ein paar Jahren die M<unk> glichkeit und die M<unk> glichkeit und die M<unk> glichkeit und die K<unk> rper und die M<unk> glichkeit und die K<unk> rper und die K<unk> rper und die M<unk> glichkeit und die M<unk> glichkeit und die M<unk> glichkeit und die M<unk> glichkeit und die K<unk> rper und die K<unk> rper und die M<unk> nner, die wir in der Welt zu erreichen.
2025-05-29 19:23:59,663 - INFO - joeynmt.training - Example #4
2025-05-29 19:23:59,664 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:23:59,664 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:23:59,664 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'eine', 'M@@', 'en@@', 'ge', 'M@@', 'en@@', 'ge', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per@@', 'n@@', 'en.', '</s>']
2025-05-29 19:23:59,664 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:23:59,664 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:23:59,664 - INFO - joeynmt.training - 	Hypothesis: Und das ist eine Menge Menge und die M<unk> glichkeit und die M<unk> glichkeit und die K<unk> rpernen.
2025-05-29 19:24:02,040 - INFO - joeynmt.training - Epoch   2, Step:     8600, Batch Loss:     2.452527, Batch Acc: 0.255656, Tokens per Sec:    29984, Lr: 0.000300
2025-05-29 19:24:04,334 - INFO - joeynmt.training - Epoch   2, Step:     8700, Batch Loss:     2.483931, Batch Acc: 0.257593, Tokens per Sec:    29430, Lr: 0.000300
2025-05-29 19:24:06,486 - INFO - joeynmt.training - Epoch   2, Step:     8800, Batch Loss:     2.495872, Batch Acc: 0.258812, Tokens per Sec:    33913, Lr: 0.000300
2025-05-29 19:24:08,375 - INFO - joeynmt.training - Epoch   2, Step:     8900, Batch Loss:     2.411790, Batch Acc: 0.260579, Tokens per Sec:    37600, Lr: 0.000300
2025-05-29 19:24:10,554 - INFO - joeynmt.training - Epoch   2, Step:     9000, Batch Loss:     2.447410, Batch Acc: 0.263160, Tokens per Sec:    32627, Lr: 0.000300
2025-05-29 19:24:10,555 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:24:10,555 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:24:26,781 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.46, ppl:  11.66, acc:   0.26, generation: 16.2133[sec], evaluation: 0.0000[sec]
2025-05-29 19:24:26,782 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:24:26,866 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/6500.ckpt
2025-05-29 19:24:26,872 - INFO - joeynmt.training - Example #0
2025-05-29 19:24:26,873 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:24:26,873 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:24:26,873 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'einen', 'M@@', 'om@@', 'ent', 'der', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'S@@', 'ache', 'und', 'die', 'S@@', 'ache', 'und', 'die', 'S@@', 'ache', 'und', 'die', 'S@@', 'ache', 'und', 'die', 'S@@', 'ache', 'und', 'und', 'die', 'S@@', 'ei@@', 'te', 'und', 'die', 'S@@', 'ei@@', 'te', 'und', 'die', 'S@@', 'ache', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:24:26,873 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:24:26,873 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:24:26,873 - INFO - joeynmt.training - 	Hypothesis: Und ich habe einen Moment der M<unk> nner und die Sache und die Sache und die Sache und die Sache und die Sache und und die Seite und die Seite und die Sache und die M<unk> glichkeiten zu erreichen.
2025-05-29 19:24:26,873 - INFO - joeynmt.training - Example #1
2025-05-29 19:24:26,873 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:24:26,873 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:24:26,873 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'nicht', 'nur', 'eine', 'M@@', 'en@@', 'ge', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'S@@', 'ache', 'und', 'die', 'S@@', 'ache', 'und', 'die', 'S@@', 'ache', 'und', 'die', 'S@@', 'ei@@', 'te', 'und', 'die', 'S@@', 'ei@@', 'te', 'und', 'die', 'S@@', 'ei@@', 'te', 'und', 'die', 'S@@', 'ei@@', 'te', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:24:26,873 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:24:26,873 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:24:26,873 - INFO - joeynmt.training - 	Hypothesis: Und ich habe nicht nur eine Menge M<unk> nner und die M<unk> nner und die Sache und die Sache und die Sache und die Seite und die Seite und die Seite und die Seite und die M<unk> glichkeiten zu erreichen.
2025-05-29 19:24:26,873 - INFO - joeynmt.training - Example #2
2025-05-29 19:24:26,874 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:24:26,874 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:24:26,874 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'das', 'nicht', 'nur', 'eine', 'M@@', 'en@@', 'ge', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'k@@', 'eit@@', 'en,', 'die', 'wir', 'in', 'den', 'letz@@', 'ten', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'S@@', 'ache', 'und', 'die', 'S@@', 'ei@@', 'te', 'und', 'die', 'S@@', 'ache', 'und', 'die', 'S@@', 'ei@@', 'te', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'zu', 'er@@', 'rei@@', 'chen', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'k@@', 'eit@@', 'en,', 'die', 'wir', 'uns', 'in', 'der', 'H@@', '<unk>', 'h@@', 'e', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:24:26,874 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:24:26,874 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:24:26,874 - INFO - joeynmt.training - 	Hypothesis: Und ich habe das nicht nur eine Menge M<unk> nner und die M<unk> glichkeiten, die wir in den letzten M<unk> nner und die Sache und die Seite und die Sache und die Seite und die M<unk> glichkeiten zu erreichen und die M<unk> glichkeiten, die wir uns in der H<unk> he zu ver<unk> ndern.
2025-05-29 19:24:26,874 - INFO - joeynmt.training - Example #3
2025-05-29 19:24:26,874 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:24:26,874 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:24:26,874 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'das', 'nicht', 'nur', 'ein', 'paar', 'M@@', 'at@@', 'h@@', 'em@@', 'ati@@', 'k', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'k@@', 'eit@@', 'en.', '</s>']
2025-05-29 19:24:26,874 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:24:26,874 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:24:26,874 - INFO - joeynmt.training - 	Hypothesis: Und ich habe das nicht nur ein paar Mathematik und die M<unk> glichkeiten.
2025-05-29 19:24:26,874 - INFO - joeynmt.training - Example #4
2025-05-29 19:24:26,874 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:24:26,875 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:24:26,875 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'das', 'nicht', 'nur', 'eine', 'M@@', 'en@@', 'ge', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'k@@', 'eit@@', 'en,', 'die', 'wir', 'in', 'den', 'letz@@', 'ten', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'S@@', 'ei@@', 'te', 'und', 'die', 'S@@', 'ei@@', 'te', 'und', 'die', 'S@@', 'ek@@', 'un@@', 'de', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:24:26,875 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:24:26,875 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:24:26,875 - INFO - joeynmt.training - 	Hypothesis: Und ich habe das nicht nur eine Menge M<unk> nner und die M<unk> glichkeiten, die wir in den letzten M<unk> nner und die Seite und die Seite und die Sekunde und die M<unk> glichkeiten zu erreichen.
2025-05-29 19:24:29,096 - INFO - joeynmt.training - Epoch   2, Step:     9100, Batch Loss:     2.455979, Batch Acc: 0.258413, Tokens per Sec:    30557, Lr: 0.000300
2025-05-29 19:24:31,470 - INFO - joeynmt.training - Epoch   2, Step:     9200, Batch Loss:     2.567125, Batch Acc: 0.262236, Tokens per Sec:    30237, Lr: 0.000300
2025-05-29 19:24:33,796 - INFO - joeynmt.training - Epoch   2, Step:     9300, Batch Loss:     2.390579, Batch Acc: 0.259757, Tokens per Sec:    29861, Lr: 0.000300
2025-05-29 19:24:36,001 - INFO - joeynmt.training - Epoch   2, Step:     9400, Batch Loss:     2.426279, Batch Acc: 0.264370, Tokens per Sec:    33209, Lr: 0.000300
2025-05-29 19:24:38,220 - INFO - joeynmt.training - Epoch   2, Step:     9500, Batch Loss:     2.512640, Batch Acc: 0.264057, Tokens per Sec:    30906, Lr: 0.000300
2025-05-29 19:24:38,220 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:24:38,221 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:24:54,064 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.45, ppl:  11.54, acc:   0.26, generation: 15.8305[sec], evaluation: 0.0000[sec]
2025-05-29 19:24:54,064 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:24:54,143 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/7000.ckpt
2025-05-29 19:24:54,148 - INFO - joeynmt.training - Example #0
2025-05-29 19:24:54,148 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:24:54,148 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:24:54,148 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'Ihnen', 'ein', 'paar', 'Jahren', 'er@@', 'h@@', '<unk>', 'r@@', 'en', 'wir', 'uns', 'er@@', 'm@@', '<unk>', 'glich@@', 'en,', 'dass', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'zu', 'ver@@', 'w@@', 'andel@@', 'n.', '</s>']
2025-05-29 19:24:54,149 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:24:54,149 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:24:54,149 - INFO - joeynmt.training - 	Hypothesis: Und ich habe Ihnen ein paar Jahren erh<unk> ren wir uns erm<unk> glichen, dass die M<unk> glichkeit der M<unk> glichkeiten zu verwandeln.
2025-05-29 19:24:54,149 - INFO - joeynmt.training - Example #1
2025-05-29 19:24:54,149 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:24:54,149 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:24:54,149 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'Ihnen', 'ein', 'paar', 'Jahren', 'nicht', 'nur', 'ein', 'paar', 'Jahren', 'in', 'der', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'zu', 'ver@@', 'w@@', 'andel@@', 'n.', '</s>']
2025-05-29 19:24:54,149 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:24:54,149 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:24:54,149 - INFO - joeynmt.training - 	Hypothesis: Und ich habe Ihnen ein paar Jahren nicht nur ein paar Jahren in der M<unk> glichkeiten zu verwandeln.
2025-05-29 19:24:54,149 - INFO - joeynmt.training - Example #2
2025-05-29 19:24:54,149 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:24:54,149 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:24:54,149 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'Ihnen', 'ein', 'paar', 'Jahren', 'er@@', 'm@@', '<unk>', 'gli@@', 'chen', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'zu', 'ver@@', 'w@@', 'andel@@', 'n.', '</s>']
2025-05-29 19:24:54,149 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:24:54,149 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:24:54,149 - INFO - joeynmt.training - 	Hypothesis: Und ich habe Ihnen ein paar Jahren erm<unk> glichen M<unk> nner und die M<unk> glichkeiten zu verwandeln.
2025-05-29 19:24:54,149 - INFO - joeynmt.training - Example #3
2025-05-29 19:24:54,149 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:24:54,149 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:24:54,150 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'Ihnen', 'ein', 'paar', 'Jahren', 'in', 'der', 'K@@', '<unk>', 'n@@', 'st@@', 'ler', 'und', 'die', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'und', 'die', 'K@@', '<unk>', 'n@@', 'st@@', 'l@@', 'er@@', 'nen', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'zu', 'ver@@', 'w@@', 'andel@@', 'n.', '</s>']
2025-05-29 19:24:54,150 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:24:54,150 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:24:54,150 - INFO - joeynmt.training - 	Hypothesis: Und ich habe Ihnen ein paar Jahren in der K<unk> nstler und die M<unk> nner und die M<unk> glichkeiten und die M<unk> glichkeit und die M<unk> glichkeiten und die K<unk> nstlernen und die M<unk> glichkeit und die M<unk> glichkeit und die M<unk> glichkeit und die M<unk> glichkeiten zu verwandeln.
2025-05-29 19:24:54,150 - INFO - joeynmt.training - Example #4
2025-05-29 19:24:54,150 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:24:54,150 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:24:54,150 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'Ihnen', 'ein', 'paar', 'Jahren', 'er@@', 'h@@', '<unk>', 'r@@', 'en', 'wir', 'uns', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'zu', 'ver@@', 'w@@', 'andel@@', 'n.', '</s>']
2025-05-29 19:24:54,150 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:24:54,150 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:24:54,150 - INFO - joeynmt.training - 	Hypothesis: Und ich habe Ihnen ein paar Jahren erh<unk> ren wir uns die M<unk> glichkeiten zu verwandeln.
2025-05-29 19:24:56,555 - INFO - joeynmt.training - Epoch   2, Step:     9600, Batch Loss:     2.352524, Batch Acc: 0.262527, Tokens per Sec:    28820, Lr: 0.000300
2025-05-29 19:24:58,907 - INFO - joeynmt.training - Epoch   2, Step:     9700, Batch Loss:     2.565550, Batch Acc: 0.259939, Tokens per Sec:    30049, Lr: 0.000300
2025-05-29 19:25:01,192 - INFO - joeynmt.training - Epoch   2, Step:     9800, Batch Loss:     2.260638, Batch Acc: 0.264614, Tokens per Sec:    31339, Lr: 0.000300
2025-05-29 19:25:03,492 - INFO - joeynmt.training - Epoch   2, Step:     9900, Batch Loss:     2.570722, Batch Acc: 0.264635, Tokens per Sec:    29544, Lr: 0.000300
2025-05-29 19:25:05,744 - INFO - joeynmt.training - Epoch   2, Step:    10000, Batch Loss:     2.448531, Batch Acc: 0.267520, Tokens per Sec:    31057, Lr: 0.000300
2025-05-29 19:25:05,745 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:25:05,745 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:25:20,705 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.43, ppl:  11.41, acc:   0.27, generation: 14.9460[sec], evaluation: 0.0000[sec]
2025-05-29 19:25:20,705 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:25:20,796 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/7500.ckpt
2025-05-29 19:25:20,803 - INFO - joeynmt.training - Example #0
2025-05-29 19:25:20,803 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:25:20,803 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:25:20,803 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'Ihnen', 'ein', 'paar', 'Jahren', 'k@@', '<unk>', 'n@@', 'n@@', 'te', 'ich', 'mich', 'in', 'der', 'Welt', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n,', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'von', 'der', 'Welt', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n,', 'die', 'wir', 'in', 'der', 'Welt', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:25:20,803 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:25:20,803 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:25:20,804 - INFO - joeynmt.training - 	Hypothesis: Und ich habe Ihnen ein paar Jahren k<unk> nnte ich mich in der Welt zu ver<unk> ndern, und die M<unk> glichkeiten von der Welt zu ver<unk> ndern, die wir in der Welt zu ver<unk> ndern.
2025-05-29 19:25:20,804 - INFO - joeynmt.training - Example #1
2025-05-29 19:25:20,804 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:25:20,804 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:25:20,804 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'Ihnen', 'ein', 'paar', 'Jahren', 'k@@', '<unk>', 'n@@', 'n@@', 'te', 'ich', 'mich', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n,', 'die', 'wir', 'in', 'der', 'Welt', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n,', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n,', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'von', 'der', 'Welt', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n,', 'und', 'die', 'T@@', '<unk>', 'tig@@', 'keit', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n,', 'und', 'die', 'T@@', 'i@@', 'ere', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'zu', 'ver@@', 'k@@', '<unk>', 'n@@', 'n@@', 'en.', '</s>']
2025-05-29 19:25:20,804 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:25:20,804 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:25:20,804 - INFO - joeynmt.training - 	Hypothesis: Und ich habe Ihnen ein paar Jahren k<unk> nnte ich mich zu ver<unk> ndern, die wir in der Welt zu ver<unk> ndern, und die M<unk> glichkeiten zu ver<unk> ndern, und die K<unk> rper, die M<unk> glichkeit und die M<unk> glichkeiten von der Welt zu ver<unk> ndern, und die T<unk> tigkeit zu ver<unk> ndern, und die Tiere und die M<unk> glichkeiten zu verk<unk> nnen.
2025-05-29 19:25:20,804 - INFO - joeynmt.training - Example #2
2025-05-29 19:25:20,804 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:25:20,804 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:25:20,804 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'Ihnen', 'ein', 'paar', 'Jahren', 'k@@', '<unk>', 'n@@', 'n@@', 'te', 'ich', 'mich', 'in', 'der', 'Welt', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n,', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n,', 'und', 'die', 'T@@', 'i@@', 'ere', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:25:20,804 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:25:20,805 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:25:20,805 - INFO - joeynmt.training - 	Hypothesis: Und ich habe Ihnen ein paar Jahren k<unk> nnte ich mich in der Welt zu ver<unk> ndern, und die K<unk> rper zu ver<unk> ndern, und die Tiere und die K<unk> rper zu ver<unk> ndern.
2025-05-29 19:25:20,805 - INFO - joeynmt.training - Example #3
2025-05-29 19:25:20,805 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:25:20,805 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:25:20,805 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'Ihnen', 'ein', 'paar', 'Jahren', 'k@@', '<unk>', 'n@@', 'n@@', 'te', 'ich', 'mich', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n,', 'die', 'wir', 'in', 'der', 'Welt', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n,', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n,', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per@@', '.', '</s>']
2025-05-29 19:25:20,805 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:25:20,805 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:25:20,805 - INFO - joeynmt.training - 	Hypothesis: Und ich habe Ihnen ein paar Jahren k<unk> nnte ich mich zu ver<unk> ndern, die wir in der Welt zu ver<unk> ndern, und die M<unk> glichkeiten zu ver<unk> ndern, und die K<unk> rper.
2025-05-29 19:25:20,805 - INFO - joeynmt.training - Example #4
2025-05-29 19:25:20,805 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:25:20,805 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:25:20,805 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'Ihnen', 'ein', 'paar', 'Jahren', 'k@@', '<unk>', 'n@@', 'n@@', 'te', 'ich', 'mich', 'in', 'der', 'Welt', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n,', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n,', 'und', 'die', 'T@@', 'i@@', 'ere', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'und', 'sie', 'k@@', '<unk>', 'n@@', 'n@@', 'ten', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'von', 'der', 'Welt', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:25:20,805 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:25:20,806 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:25:20,806 - INFO - joeynmt.training - 	Hypothesis: Und ich habe Ihnen ein paar Jahren k<unk> nnte ich mich in der Welt zu ver<unk> ndern, und die K<unk> rper zu ver<unk> ndern, und die Tiere und die K<unk> rper zu verwenden, und sie k<unk> nnten die M<unk> glichkeiten von der Welt zu ver<unk> ndern.
2025-05-29 19:25:23,209 - INFO - joeynmt.training - Epoch   2, Step:    10100, Batch Loss:     2.493490, Batch Acc: 0.259111, Tokens per Sec:    27806, Lr: 0.000300
2025-05-29 19:25:25,516 - INFO - joeynmt.training - Epoch   2, Step:    10200, Batch Loss:     2.385672, Batch Acc: 0.263135, Tokens per Sec:    30009, Lr: 0.000300
2025-05-29 19:25:27,526 - INFO - joeynmt.training - Epoch   2, Step:    10300, Batch Loss:     2.348676, Batch Acc: 0.265473, Tokens per Sec:    35626, Lr: 0.000300
2025-05-29 19:25:29,493 - INFO - joeynmt.training - Epoch   2, Step:    10400, Batch Loss:     2.421293, Batch Acc: 0.263130, Tokens per Sec:    36642, Lr: 0.000300
2025-05-29 19:25:31,493 - INFO - joeynmt.training - Epoch   2, Step:    10500, Batch Loss:     2.347587, Batch Acc: 0.266643, Tokens per Sec:    35654, Lr: 0.000300
2025-05-29 19:25:31,494 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:25:31,494 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:25:36,129 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.43, ppl:  11.31, acc:   0.27, generation: 4.6289[sec], evaluation: 0.0000[sec]
2025-05-29 19:25:36,130 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:25:36,230 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/8000.ckpt
2025-05-29 19:25:36,237 - INFO - joeynmt.training - Example #0
2025-05-29 19:25:36,237 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:25:36,237 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:25:36,237 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'ein', 'paar', 'Jahren', 'er@@', 'h@@', '<unk>', 'h@@', 'n@@', 'lich@@', 'er', 'M@@', 'et@@', 'er', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:25:36,237 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:25:36,237 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:25:36,237 - INFO - joeynmt.training - 	Hypothesis: Ich habe ein paar Jahren erh<unk> hnlicher Meter und die M<unk> glichkeit der K<unk> rper zu erreichen.
2025-05-29 19:25:36,237 - INFO - joeynmt.training - Example #1
2025-05-29 19:25:36,237 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:25:36,237 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:25:36,237 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'ein', 'paar', 'Jahren', 'nicht', 'mehr', 'als', 'die', 'K@@', '<unk>', 'r@@', 'per@@', '.', '</s>']
2025-05-29 19:25:36,238 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:25:36,238 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:25:36,238 - INFO - joeynmt.training - 	Hypothesis: Ich habe ein paar Jahren nicht mehr als die K<unk> rper.
2025-05-29 19:25:36,238 - INFO - joeynmt.training - Example #2
2025-05-29 19:25:36,238 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:25:36,238 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:25:36,238 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'ein', 'paar', 'Jahren', 'er@@', 'h@@', '<unk>', 'h@@', 'n@@', 'lich@@', 'er', 'M@@', 'et@@', 'er', 'und', 'die', 'M@@', '<unk>', 'd@@', 'chen', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per@@', '.', '</s>']
2025-05-29 19:25:36,238 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:25:36,238 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:25:36,238 - INFO - joeynmt.training - 	Hypothesis: Ich habe ein paar Jahren erh<unk> hnlicher Meter und die M<unk> dchen und die K<unk> rper.
2025-05-29 19:25:36,238 - INFO - joeynmt.training - Example #3
2025-05-29 19:25:36,238 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:25:36,238 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:25:36,238 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'es', 'nicht', 'nur', 'ein', 'paar', 'M@@', 'et@@', 'er', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:25:36,238 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:25:36,238 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:25:36,239 - INFO - joeynmt.training - 	Hypothesis: Ich habe es nicht nur ein paar Meter und die K<unk> rper und die K<unk> rper zu erreichen.
2025-05-29 19:25:36,239 - INFO - joeynmt.training - Example #4
2025-05-29 19:25:36,239 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:25:36,239 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:25:36,239 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'ein', 'paar', 'Jahren', 'er@@', 'h@@', '<unk>', 'h@@', 'n@@', 'lich@@', 'er', 'M@@', 'et@@', 'er', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:25:36,239 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:25:36,239 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:25:36,239 - INFO - joeynmt.training - 	Hypothesis: Ich habe ein paar Jahren erh<unk> hnlicher Meter und die M<unk> glichkeit der K<unk> rper zu erreichen.
2025-05-29 19:25:38,498 - INFO - joeynmt.training - Epoch   2, Step:    10600, Batch Loss:     2.465824, Batch Acc: 0.264239, Tokens per Sec:    30079, Lr: 0.000300
2025-05-29 19:25:40,493 - INFO - joeynmt.training - Epoch   2: total training loss 13300.14
2025-05-29 19:25:40,493 - INFO - joeynmt.training - EPOCH 3
2025-05-29 19:25:40,759 - INFO - joeynmt.training - Epoch   3, Step:    10700, Batch Loss:     2.415281, Batch Acc: 0.277131, Tokens per Sec:    28536, Lr: 0.000300
2025-05-29 19:25:42,843 - INFO - joeynmt.training - Epoch   3, Step:    10800, Batch Loss:     2.436738, Batch Acc: 0.272762, Tokens per Sec:    34753, Lr: 0.000300
2025-05-29 19:25:44,826 - INFO - joeynmt.training - Epoch   3, Step:    10900, Batch Loss:     2.446354, Batch Acc: 0.272661, Tokens per Sec:    35356, Lr: 0.000300
2025-05-29 19:25:46,787 - INFO - joeynmt.training - Epoch   3, Step:    11000, Batch Loss:     2.385762, Batch Acc: 0.272122, Tokens per Sec:    35933, Lr: 0.000300
2025-05-29 19:25:46,787 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:25:46,788 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:26:03,508 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.42, ppl:  11.24, acc:   0.27, generation: 16.7014[sec], evaluation: 0.0000[sec]
2025-05-29 19:26:03,508 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:26:03,597 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/8500.ckpt
2025-05-29 19:26:03,603 - INFO - joeynmt.training - Example #0
2025-05-29 19:26:03,604 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:26:03,604 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:26:03,604 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ern']
2025-05-29 19:26:03,604 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:26:03,604 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:26:03,604 - INFO - joeynmt.training - 	Hypothesis: Ich habe ein paar Minuten und die M<unk> nnern und die M<unk> nnern und die M<unk> nnern und die M<unk> nnern und die M<unk> nnern und die M<unk> nnern und die M<unk> nnern und die M<unk> nnern und die M<unk> glichkeit und die M<unk> nnern und die M<unk> nnern und die M<unk> nnern und die M<unk> nnern und die M<unk> nnern und die M<unk> nnern
2025-05-29 19:26:03,604 - INFO - joeynmt.training - Example #1
2025-05-29 19:26:03,604 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:26:03,604 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:26:03,604 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'nicht', 'nur', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@']
2025-05-29 19:26:03,605 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:26:03,605 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:26:03,605 - INFO - joeynmt.training - 	Hypothesis: Und ich habe nicht nur die M<unk> nnern und die M<unk> nnern und die M<unk> nnern und die M<unk> nnern und die M<unk> nnern und die M<unk> nnern und die M<unk> nnern und die M<unk> nnern und die M<unk> nnern und die M<unk> nnern und die M<unk> nnern und die M<unk> nnern und die M<unk> nnern und die M<unk> nnern und die M<unk> nnern und die M
2025-05-29 19:26:03,605 - INFO - joeynmt.training - Example #2
2025-05-29 19:26:03,605 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:26:03,605 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:26:03,605 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'es', 'nicht', 'nur', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'chen', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die']
2025-05-29 19:26:03,605 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:26:03,605 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:26:03,605 - INFO - joeynmt.training - 	Hypothesis: Und ich habe es nicht nur ein paar Minuten und die M<unk> nnern und die M<unk> nnern und die M<unk> nnern und die M<unk> nnern und die M<unk> nnern und die M<unk> nnern und die M<unk> nnern und die M<unk> nnchen und die M<unk> nnern und die M<unk> nnern und die M<unk> nnern und die M<unk> nnern und die M<unk> nnern und die M<unk> nnern und die
2025-05-29 19:26:03,605 - INFO - joeynmt.training - Example #3
2025-05-29 19:26:03,605 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:26:03,605 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:26:03,605 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'das', 'nicht', 'nur', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'und', 'die', 'M@@', '<unk>', 'n@@']
2025-05-29 19:26:03,606 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:26:03,606 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:26:03,606 - INFO - joeynmt.training - 	Hypothesis: Ich habe das nicht nur die M<unk> nnern und die M<unk> nnern und die M<unk> nnern und die M<unk> nnern und die M<unk> glichkeit und die M<unk> nnern und die M<unk> nnern und die M<unk> nnern und die M<unk> nnern und die M<unk> nnern und die M<unk> nnern und die M<unk> nnern und die M<unk> nnern und die M<unk> nnern und die M<unk> glichkeit und die M<unk> n
2025-05-29 19:26:03,606 - INFO - joeynmt.training - Example #4
2025-05-29 19:26:03,606 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:26:03,606 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:26:03,606 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'und', 'ich', 'habe', 'eine', 'M@@', 'en@@', 'ge', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und']
2025-05-29 19:26:03,606 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:26:03,606 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:26:03,606 - INFO - joeynmt.training - 	Hypothesis: Und ich habe ein paar Minuten und ich habe eine Menge M<unk> nnern und die M<unk> nnern und die M<unk> nnern und die M<unk> nnern und die M<unk> nnern und die M<unk> nnern und die M<unk> nnern und die M<unk> glichkeit und die M<unk> nnern und die M<unk> nnern und die M<unk> nnern und die M<unk> nnern und die M<unk> nnern und die M<unk> nnern und
2025-05-29 19:26:05,852 - INFO - joeynmt.training - Epoch   3, Step:    11100, Batch Loss:     2.433247, Batch Acc: 0.272973, Tokens per Sec:    29955, Lr: 0.000300
2025-05-29 19:26:08,196 - INFO - joeynmt.training - Epoch   3, Step:    11200, Batch Loss:     2.410945, Batch Acc: 0.272812, Tokens per Sec:    30092, Lr: 0.000300
2025-05-29 19:26:10,607 - INFO - joeynmt.training - Epoch   3, Step:    11300, Batch Loss:     2.547062, Batch Acc: 0.273572, Tokens per Sec:    29613, Lr: 0.000300
2025-05-29 19:26:12,972 - INFO - joeynmt.training - Epoch   3, Step:    11400, Batch Loss:     2.408062, Batch Acc: 0.276481, Tokens per Sec:    29675, Lr: 0.000300
2025-05-29 19:26:15,410 - INFO - joeynmt.training - Epoch   3, Step:    11500, Batch Loss:     2.253997, Batch Acc: 0.271462, Tokens per Sec:    28331, Lr: 0.000300
2025-05-29 19:26:15,411 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:26:15,411 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:26:31,604 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.41, ppl:  11.12, acc:   0.27, generation: 16.1817[sec], evaluation: 0.0000[sec]
2025-05-29 19:26:31,604 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:26:31,686 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/9000.ckpt
2025-05-29 19:26:31,691 - INFO - joeynmt.training - Example #0
2025-05-29 19:26:31,692 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:26:31,692 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:26:31,692 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'ein', 'paar', 'Jahren', 'er@@', 'h@@', '<unk>', 'h@@', 'n@@', 'liche', 'M@@', '<unk>', 'glich@@', 'kei@@', 't,', 'die', 'wir', 'in', 'den', 'letz@@', 'ten', 'St@@', '<unk>', 'ck', 'und', 'die', 'S@@', 'ei@@', 'te', 'der', 'S@@', 'ei@@', 'te', 'und', 'die', 'S@@', 'ei@@', 'te', 'und', 'die', 'S@@', 'ei@@', 'te', 'und', 'die', 'S@@', 'ei@@', 'te', 'der', 'M@@', '<unk>', 'glich@@', 'keit', 'und', 'die', 'S@@', 'ei@@', 'te', 'der', 'S@@', 'ei@@', 'te', 'und', 'die', 'S@@', 'ei@@', 'te', 'der', 'S@@', 'ei@@', 'te', 'und', 'die', 'S@@', 'ei@@', 'te', 'der', 'M@@', '<unk>', 'glich@@', 'keit', 'und', 'die', 'S@@', 'tra@@', '<unk>', 'en', 'und', 'die', 'S@@', 'ei@@', 'te', 'der', 'S@@', 'pr@@', 'ache', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:26:31,692 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:26:31,692 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:26:31,692 - INFO - joeynmt.training - 	Hypothesis: Und ich habe ein paar Jahren erh<unk> hnliche M<unk> glichkeit, die wir in den letzten St<unk> ck und die Seite der Seite und die Seite und die Seite und die Seite der M<unk> glichkeit und die Seite der Seite und die Seite der Seite und die Seite der M<unk> glichkeit und die Stra<unk> en und die Seite der Sprache zu erreichen.
2025-05-29 19:26:31,692 - INFO - joeynmt.training - Example #1
2025-05-29 19:26:31,692 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:26:31,692 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:26:31,692 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'und', 'ich', 'habe', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'und', 'die', 'S@@', 'tra@@', '<unk>', 'en', 'und', 'die', 'S@@', 'tra@@', '<unk>', 'en', 'und', 'die', 'S@@', 'tra@@', '<unk>', 'en', 'und', 'die', 'S@@', 'tra@@', '<unk>', 'en', 'und', 'die', 'S@@', 'tra@@', '<unk>', 'en', 'und', 'die', 'S@@', 'ei@@', 'te', 'und', 'die', 'S@@', 'ach@@', 'e,', 'die', 'wir', 'in', 'den', 'letz@@', 'ten', 'St@@', '<unk>', 'ck', 'und', 'die', 'S@@', 'tra@@', '<unk>', 'en', 'und', 'die', 'S@@', 'tra@@', '<unk>', 'e', 'zu', 'ver@@', 'w@@', 'andel@@', 'n.', '</s>']
2025-05-29 19:26:31,692 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:26:31,692 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:26:31,692 - INFO - joeynmt.training - 	Hypothesis: Und ich habe ein paar Minuten und ich habe ein paar Minuten und die Stra<unk> en und die Stra<unk> en und die Stra<unk> en und die Stra<unk> en und die Stra<unk> en und die Seite und die Sache, die wir in den letzten St<unk> ck und die Stra<unk> en und die Stra<unk> e zu verwandeln.
2025-05-29 19:26:31,692 - INFO - joeynmt.training - Example #2
2025-05-29 19:26:31,693 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:26:31,693 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:26:31,693 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'und', 'ich', 'habe', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'und', 'die', 'S@@', 'ei@@', 'te', 'der', 'S@@', 'ei@@', 'te', 'und', 'die', 'S@@', 'ache', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:26:31,693 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:26:31,693 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:26:31,693 - INFO - joeynmt.training - 	Hypothesis: Und ich habe ein paar Minuten und ich habe ein paar Minuten und die Seite der Seite und die Sache zu erreichen.
2025-05-29 19:26:31,693 - INFO - joeynmt.training - Example #3
2025-05-29 19:26:31,693 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:26:31,693 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:26:31,693 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'und', 'die', 'S@@', 'ei@@', 'te', 'der', 'S@@', 'ei@@', 'te', 'und', 'die', 'S@@', 'ei@@', 'te', 'und', 'die', 'S@@', 'ache', 'zu', 'er@@', 'rei@@', 'chen,', 'und', 'die', 'S@@', 'tra@@', '<unk>', 'en', 'und', 'die', 'S@@', 'tra@@', '<unk>', 'en', 'und', 'die', 'S@@', 'ei@@', 'te', 'und', 'die', 'S@@', 'ei@@', 'te', 'und', 'die', 'S@@', 'ei@@', 'te', 'und', 'die', 'S@@', 'ei@@', 'te', 'und', 'die', 'S@@', 'ei@@', 'te', 'der', 'S@@', 'ei@@', 'te', 'und', 'die', 'S@@', 'ei@@', 'te', 'der', 'M@@', '<unk>', 'glich@@', 'keit', 'und', 'die', 'S@@', 'ache', 'zu', 'ver@@', 'w@@', 'andel@@', 'n.', '</s>']
2025-05-29 19:26:31,693 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:26:31,693 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:26:31,693 - INFO - joeynmt.training - 	Hypothesis: Und ich habe ein paar Minuten und die Seite der Seite und die Seite und die Sache zu erreichen, und die Stra<unk> en und die Stra<unk> en und die Seite und die Seite und die Seite und die Seite und die Seite der Seite und die Seite der M<unk> glichkeit und die Sache zu verwandeln.
2025-05-29 19:26:31,693 - INFO - joeynmt.training - Example #4
2025-05-29 19:26:31,693 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:26:31,693 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:26:31,693 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'ein', 'paar', 'Jahren', 'er@@', 'h@@', '<unk>', 'h@@', 'n@@', 'liche', 'M@@', '<unk>', 'glich@@', 'kei@@', 't,', 'die', 'wir', 'in', 'der', 'Welt', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:26:31,693 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:26:31,693 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:26:31,693 - INFO - joeynmt.training - 	Hypothesis: Und ich habe ein paar Jahren erh<unk> hnliche M<unk> glichkeit, die wir in der Welt zu ver<unk> ndern.
2025-05-29 19:26:34,020 - INFO - joeynmt.training - Epoch   3, Step:    11600, Batch Loss:     2.313944, Batch Acc: 0.274781, Tokens per Sec:    29468, Lr: 0.000300
2025-05-29 19:26:36,353 - INFO - joeynmt.training - Epoch   3, Step:    11700, Batch Loss:     2.412574, Batch Acc: 0.274076, Tokens per Sec:    30621, Lr: 0.000300
2025-05-29 19:26:38,653 - INFO - joeynmt.training - Epoch   3, Step:    11800, Batch Loss:     2.402070, Batch Acc: 0.276228, Tokens per Sec:    30362, Lr: 0.000300
2025-05-29 19:26:41,032 - INFO - joeynmt.training - Epoch   3, Step:    11900, Batch Loss:     2.358101, Batch Acc: 0.273172, Tokens per Sec:    29495, Lr: 0.000300
2025-05-29 19:26:43,400 - INFO - joeynmt.training - Epoch   3, Step:    12000, Batch Loss:     2.355179, Batch Acc: 0.275829, Tokens per Sec:    29455, Lr: 0.000300
2025-05-29 19:26:43,401 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:26:43,401 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:27:00,433 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.40, ppl:  11.03, acc:   0.28, generation: 17.0168[sec], evaluation: 0.0000[sec]
2025-05-29 19:27:00,433 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:27:00,518 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/9500.ckpt
2025-05-29 19:27:00,524 - INFO - joeynmt.training - Example #0
2025-05-29 19:27:00,524 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:27:00,524 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:27:00,524 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'eine', 'M@@', '<unk>', 'd@@', 'chen', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'er,', 'die', 'wir', 'in', 'der', 'H@@', '<unk>', 'n@@', 'de', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'er@@', 'kl@@', '<unk>', 'r@@', 'en,', 'die', 'wir', 'in', 'den', 'U@@', 'S@@', 'A', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'er@@', 'rei@@', 'chen,', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'zu', 'er@@', 'kl@@', '<unk>', 'r@@', 'en,', 'die', 'wir', 'in', 'den', 'H@@', '<unk>', 'r@@', 'en', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'die', 'die', 'S@@', 'pr@@', 'ache', 'zu', 'er@@', 'inn@@', 'ern@@', ',', 'die', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'er@@', 'rei@@', 'chen,', 'die', '<unk>', 'ber@@', 'w@@', 'ach@@', 'ung', 'der', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die']
2025-05-29 19:27:00,524 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:27:00,524 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:27:00,525 - INFO - joeynmt.training - 	Hypothesis: Und das ist eine M<unk> dchen und die M<unk> nner, die wir in der H<unk> nde und die K<unk> rper zu erkl<unk> ren, die wir in den USA und die K<unk> rper zu erreichen, die M<unk> glichkeiten zu erkl<unk> ren, die wir in den H<unk> ren und die K<unk> rper, die die Sprache zu erinnern, die die K<unk> rper zu erreichen, die <unk> berwachung der K<unk> rper und die
2025-05-29 19:27:00,525 - INFO - joeynmt.training - Example #1
2025-05-29 19:27:00,525 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:27:00,525 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:27:00,525 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'nicht', 'nur', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'er@@', 'kl@@', '<unk>', 'r@@', 'en,', 'die', 'wir', 'nicht', 'nur', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'er@@', 'rei@@', 'chen,', 'die', 'K@@', '<unk>', 'r@@', 'per@@', 'ung', 'der', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'er@@', 'kl@@', '<unk>', 'r@@', 'en,', 'die', 'wir', 'nicht', 'nur', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'er@@', 'rei@@', 'chen,', 'die', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'die', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'er@@', 'kl@@', '<unk>', 'r@@', 'en,', 'die', 'wir', 'in', 'der', 'Welt', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:27:00,525 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:27:00,525 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:27:00,525 - INFO - joeynmt.training - 	Hypothesis: Und das ist nicht nur ein paar Minuten und die K<unk> rper und die K<unk> rper zu erkl<unk> ren, die wir nicht nur die K<unk> rper zu erreichen, die K<unk> rperung der K<unk> rper zu erkl<unk> ren, die wir nicht nur die K<unk> rper zu erreichen, die K<unk> rper, die die K<unk> rper zu erkl<unk> ren, die wir in der Welt zu erreichen.
2025-05-29 19:27:00,525 - INFO - joeynmt.training - Example #2
2025-05-29 19:27:00,525 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:27:00,525 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:27:00,525 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'eine', 'M@@', '<unk>', 'd@@', 'chen', 'der', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'M@@', '<unk>', 'd@@', 'chen', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'er@@', 'rei@@', 'chen,', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'er@@', 'rei@@', 'chen,', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'er@@', 'rei@@', 'chen,', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'er@@', 'kl@@', '<unk>', 'r@@', 'en,', 'die', 'wir', 'in', 'der', 'H@@', '<unk>', 'l@@', 'f@@', 'te', 'der', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'er@@', 'rei@@', 'chen,', 'die', '<unk>', 'ber@@', 'w@@', 'ach@@', 'ung', 'der', 'M@@', '<unk>', 'd@@', 'chen', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per@@', 'ung', 'der', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'er@@', 'rei@@', 'chen,', 'die', '<unk>', 'ber@@', 'w@@', 'ach@@', 'ung', 'der', 'K@@', '<unk>']
2025-05-29 19:27:00,525 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:27:00,525 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:27:00,525 - INFO - joeynmt.training - 	Hypothesis: Und das ist eine M<unk> dchen der K<unk> rper und die M<unk> dchen und die K<unk> rper zu erreichen, die K<unk> rper zu erreichen, die K<unk> rper zu erreichen, die K<unk> rper zu erkl<unk> ren, die wir in der H<unk> lfte der K<unk> rper zu erreichen, die <unk> berwachung der M<unk> dchen und die K<unk> rperung der K<unk> rper zu erreichen, die <unk> berwachung der K<unk>
2025-05-29 19:27:00,525 - INFO - joeynmt.training - Example #3
2025-05-29 19:27:00,525 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:27:00,525 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:27:00,525 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'eine', 'M@@', '<unk>', 'd@@', 'chen', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'M@@', '<unk>', 'd@@', 'chen', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'er@@', 'kl@@', '<unk>', 'r@@', 'en,', 'die', 'wir', 'in', 'der', 'Welt', 'zu', 'er@@', 'rei@@', 'chen,', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'er@@', 'rei@@', 'chen,', 'die', 'K@@', '<unk>', 'r@@', 'per@@', 'ung', 'der', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'er@@', 'kl@@', '<unk>', 'r@@', 'en,', 'die', 'wir', 'in', 'der', 'Welt', 'zu', 'er@@', 'rei@@', 'chen,', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'er@@', 'rei@@', 'chen,', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:27:00,526 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:27:00,526 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:27:00,526 - INFO - joeynmt.training - 	Hypothesis: Und das ist eine M<unk> dchen und die K<unk> rper und die M<unk> dchen und die K<unk> rper zu erkl<unk> ren, die wir in der Welt zu erreichen, die K<unk> rper zu erreichen, die K<unk> rperung der K<unk> rper zu erkl<unk> ren, die wir in der Welt zu erreichen, die K<unk> rper zu erreichen, die K<unk> rper zu ver<unk> ndern.
2025-05-29 19:27:00,526 - INFO - joeynmt.training - Example #4
2025-05-29 19:27:00,526 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:27:00,526 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:27:00,526 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'eine', 'M@@', '<unk>', 'd@@', 'chen', 'der', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'M@@', '<unk>', 'd@@', 'chen', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'er@@', 'kl@@', '<unk>', 'r@@', 'en,', 'die', 'wir', 'in', 'der', 'Welt', 'zu', 'er@@', 'rei@@', 'chen,', 'die', 'K@@', '<unk>', 'r@@', 'per@@', 'ung', 'der', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'er@@', 'kl@@', '<unk>', 'r@@', 'en,', 'die', 'wir', 'uns', 'in', 'der', 'H@@', '<unk>', 'h@@', 'e', 'zu', 'er@@', 'inn@@', 'en,', 'die', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'er@@', 'kl@@', '<unk>', 'r@@', 'en,', 'die', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'er@@', 'kl@@', '<unk>', 'r@@']
2025-05-29 19:27:00,526 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:27:00,526 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:27:00,526 - INFO - joeynmt.training - 	Hypothesis: Und das ist eine M<unk> dchen der K<unk> rper und die M<unk> dchen und die K<unk> rper, die K<unk> rper zu erkl<unk> ren, die wir in der Welt zu erreichen, die K<unk> rperung der K<unk> rper, die K<unk> rper zu erkl<unk> ren, die wir uns in der H<unk> he zu erinnen, die die M<unk> nnern und die K<unk> rper zu erkl<unk> ren, die die K<unk> rper zu erkl<unk> r
2025-05-29 19:27:02,980 - INFO - joeynmt.training - Epoch   3, Step:    12100, Batch Loss:     2.441521, Batch Acc: 0.277608, Tokens per Sec:    28152, Lr: 0.000300
2025-05-29 19:27:05,237 - INFO - joeynmt.training - Epoch   3, Step:    12200, Batch Loss:     2.367010, Batch Acc: 0.275715, Tokens per Sec:    31851, Lr: 0.000300
2025-05-29 19:27:07,462 - INFO - joeynmt.training - Epoch   3, Step:    12300, Batch Loss:     2.401071, Batch Acc: 0.277192, Tokens per Sec:    31657, Lr: 0.000300
2025-05-29 19:27:09,665 - INFO - joeynmt.training - Epoch   3, Step:    12400, Batch Loss:     2.205437, Batch Acc: 0.272035, Tokens per Sec:    32117, Lr: 0.000300
2025-05-29 19:27:11,895 - INFO - joeynmt.training - Epoch   3, Step:    12500, Batch Loss:     2.356200, Batch Acc: 0.277625, Tokens per Sec:    31924, Lr: 0.000300
2025-05-29 19:27:11,895 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:27:11,895 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:27:24,860 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.40, ppl:  10.98, acc:   0.28, generation: 12.9548[sec], evaluation: 0.0000[sec]
2025-05-29 19:27:24,860 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:27:24,938 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/10000.ckpt
2025-05-29 19:27:24,944 - INFO - joeynmt.training - Example #0
2025-05-29 19:27:24,944 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:27:24,944 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:27:24,944 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'es', 'in', 'der', 'L@@', 'age', 'in', 'der', 'L@@', 'age', 'in', 'der', 'L@@', 'age', 'in', 'der', 'L@@', 'age', 'in', 'der', 'L@@', 'age', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:27:24,944 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:27:24,944 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:27:24,944 - INFO - joeynmt.training - 	Hypothesis: Ich habe es in der Lage in der Lage in der Lage in der Lage in der Lage zu ver<unk> ndern.
2025-05-29 19:27:24,944 - INFO - joeynmt.training - Example #1
2025-05-29 19:27:24,945 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:27:24,945 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:27:24,945 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'Ihnen', 'ein', 'paar', 'Jahre', 'al@@', 'es', 'in', 'der', 'L@@', 'age', 'in', 'der', 'L@@', 'age', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:27:24,945 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:27:24,945 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:27:24,945 - INFO - joeynmt.training - 	Hypothesis: Und ich habe Ihnen ein paar Jahre ales in der Lage in der Lage zu erreichen.
2025-05-29 19:27:24,945 - INFO - joeynmt.training - Example #2
2025-05-29 19:27:24,945 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:27:24,945 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:27:24,945 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'Ihnen', 'ein', 'paar', 'Jahre', 'al@@', 'es', 'in', 'der', 'L@@', 'age', 'zu', 'er@@', 'h@@', '<unk>', 'h@@', 'n@@', 'lich@@', 'er', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'zu', 'er@@', 'w@@', '<unk>', 'h@@', 'n@@', 'en.', '</s>']
2025-05-29 19:27:24,945 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:27:24,945 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:27:24,946 - INFO - joeynmt.training - 	Hypothesis: Und ich habe Ihnen ein paar Jahre ales in der Lage zu erh<unk> hnlicher M<unk> nner und die M<unk> nner und die M<unk> glichkeit zu erw<unk> hnen.
2025-05-29 19:27:24,946 - INFO - joeynmt.training - Example #3
2025-05-29 19:27:24,946 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:27:24,946 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:27:24,946 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'S@@', 'ache', 'zu', 'er@@', 'rei@@', 'chen,', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per@@', 'f@@', 'ek@@', 't', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:27:24,946 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:27:24,946 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:27:24,946 - INFO - joeynmt.training - 	Hypothesis: Ich habe die M<unk> glichkeit und die M<unk> nnern und die M<unk> nnern und die M<unk> nner und die M<unk> nner und die Sache zu erreichen, und die K<unk> rperfekt und die M<unk> glichkeit zu ver<unk> ndern.
2025-05-29 19:27:24,946 - INFO - joeynmt.training - Example #4
2025-05-29 19:27:24,946 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:27:24,946 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:27:24,946 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'Ihnen', 'ein', 'paar', 'Jahre', 'al@@', 'es', 'in', 'der', 'L@@', 'age', 'zu', 'er@@', 'h@@', '<unk>', 'h@@', 'n@@', 'lich@@', 'er', 'M@@', '<unk>', 'd@@', 'chen', 'und', 'die', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'zu', 'er@@', 'w@@', '<unk>', 'h@@', 'n@@', 'en,', 'aber', 'es', 'ist', 'nicht', 'so', 'viel', 'mehr', 'als', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'zu', 'er@@', 'w@@', '<unk>', 'h@@', 'n@@', 'lich@@', 'er', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'zu', 'er@@', 'w@@', '<unk>', 'h@@', 'n@@', 'en,', 'die', 'wir', 'in', 'der', 'L@@', 'age', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:27:24,946 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:27:24,946 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:27:24,946 - INFO - joeynmt.training - 	Hypothesis: Und ich habe Ihnen ein paar Jahre ales in der Lage zu erh<unk> hnlicher M<unk> dchen und die M<unk> nner und die M<unk> glichkeit zu erw<unk> hnen, aber es ist nicht so viel mehr als die M<unk> glichkeit zu erw<unk> hnlicher M<unk> nner und die M<unk> nner und die M<unk> glichkeit zu erw<unk> hnen, die wir in der Lage zu ver<unk> ndern.
2025-05-29 19:27:27,247 - INFO - joeynmt.training - Epoch   3, Step:    12600, Batch Loss:     2.306761, Batch Acc: 0.279283, Tokens per Sec:    30105, Lr: 0.000300
2025-05-29 19:27:29,471 - INFO - joeynmt.training - Epoch   3, Step:    12700, Batch Loss:     2.444009, Batch Acc: 0.274835, Tokens per Sec:    32241, Lr: 0.000300
2025-05-29 19:27:31,744 - INFO - joeynmt.training - Epoch   3, Step:    12800, Batch Loss:     2.448069, Batch Acc: 0.277295, Tokens per Sec:    30614, Lr: 0.000300
2025-05-29 19:27:35,041 - INFO - joeynmt.training - Epoch   3, Step:    12900, Batch Loss:     2.461116, Batch Acc: 0.276182, Tokens per Sec:    21252, Lr: 0.000300
2025-05-29 19:27:37,427 - INFO - joeynmt.training - Epoch   3, Step:    13000, Batch Loss:     2.361279, Batch Acc: 0.275516, Tokens per Sec:    29580, Lr: 0.000300
2025-05-29 19:27:37,427 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:27:37,427 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:27:52,648 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.39, ppl:  10.87, acc:   0.28, generation: 15.2076[sec], evaluation: 0.0000[sec]
2025-05-29 19:27:52,648 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:27:52,734 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/10500.ckpt
2025-05-29 19:27:52,740 - INFO - joeynmt.training - Example #0
2025-05-29 19:27:52,740 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:27:52,740 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:27:52,740 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'bin', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'und', 'ich', 'bin', 'ein', 'paar', 'M@@', '<unk>', 'glich@@', 'k@@', 'eit@@', 'en,', 'die', 'ich', 'in', 'den', 'letz@@', 'ten', '1@@', '0@@', '0@@', 'ern', 'und', '1@@', '00', 'Milli@@', 'onen', 'D@@', 'oll@@', 'ar', 'f@@', '<unk>', 'r', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'die', 'sie', 'in', 'den', 'letz@@', 'ten', '1@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', ',', 'und', 'der', 'K@@', '<unk>', 'r@@']
2025-05-29 19:27:52,740 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:27:52,740 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:27:52,740 - INFO - joeynmt.training - 	Hypothesis: Und ich bin ein paar Minuten und ich bin ein paar M<unk> glichkeiten, die ich in den letzten 100ern und 100 Millionen Dollar f<unk> r die M<unk> glichkeit und die M<unk> glichkeit zu ver<unk> ndern und die M<unk> glichkeit und die M<unk> glichkeit und die M<unk> glichkeiten und die M<unk> glichkeit zu verwenden, die sie in den letzten 100000000000, und der K<unk> r
2025-05-29 19:27:52,740 - INFO - joeynmt.training - Example #1
2025-05-29 19:27:52,740 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:27:52,740 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:27:52,740 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'm@@', '<unk>', 'chte', 'Ihnen', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'des', 'K@@', 'ri@@', 'eg@@', 'es', 'in', 'den', 'letz@@', 'ten', 'M@@', '<unk>', 'glich@@', 'k@@', 'eit@@', 'en,', 'die', 'wir', 'in', 'den', 'letz@@', 'ten', 'St@@', '<unk>', 'd@@', 'te', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:27:52,740 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:27:52,741 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:27:52,741 - INFO - joeynmt.training - 	Hypothesis: Und ich m<unk> chte Ihnen ein paar Minuten und die M<unk> glichkeit des Krieges in den letzten M<unk> glichkeiten, die wir in den letzten St<unk> dte und die M<unk> glichkeit zu ver<unk> ndern.
2025-05-29 19:27:52,741 - INFO - joeynmt.training - Example #2
2025-05-29 19:27:52,741 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:27:52,741 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:27:52,741 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'm@@', '<unk>', 'chte', 'Ihnen', 'ein', 'paar', 'M@@', '<unk>', 'glich@@', 'k@@', 'eit@@', 'en,', 'die', 'wir', 'in', 'den', 'letz@@', 'ten', 'M@@', '<unk>', 'glich@@', 'k@@', 'eit@@', 'en,', 'die', 'wir', 'in', 'den', 'letz@@', 'ten', 'St@@', '<unk>', 'd@@', 'te', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'zu', 'er@@', 'kl@@', '<unk>', 'r@@', 'en,', 'die', 'wir', 'in', 'den', 'letz@@', 'ten', 'St@@', '<unk>', 'd@@', 'te', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:27:52,741 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:27:52,741 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:27:52,741 - INFO - joeynmt.training - 	Hypothesis: Und ich m<unk> chte Ihnen ein paar M<unk> glichkeiten, die wir in den letzten M<unk> glichkeiten, die wir in den letzten St<unk> dte und die M<unk> glichkeit zu erkl<unk> ren, die wir in den letzten St<unk> dte und die M<unk> glichkeit und die M<unk> glichkeit zu ver<unk> ndern und die M<unk> glichkeiten und die M<unk> glichkeit zu ver<unk> ndern und die M<unk> glichkeit zu ver<unk> ndern.
2025-05-29 19:27:52,741 - INFO - joeynmt.training - Example #3
2025-05-29 19:27:52,741 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:27:52,741 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:27:52,741 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'bin', 'ein', 'paar', 'M@@', '<unk>', 'glich@@', 'k@@', 'eit@@', 'en,', 'die', 'wir', 'in', 'den', 'U@@', 'S@@', 'A', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:27:52,741 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:27:52,741 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:27:52,741 - INFO - joeynmt.training - 	Hypothesis: Und ich bin ein paar M<unk> glichkeiten, die wir in den USA und die M<unk> glichkeit und die M<unk> glichkeit und die M<unk> glichkeit zu ver<unk> ndern.
2025-05-29 19:27:52,741 - INFO - joeynmt.training - Example #4
2025-05-29 19:27:52,742 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:27:52,742 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:27:52,742 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'bin', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'und', 'ich', 'bin', 'ein', 'paar', 'M@@', '<unk>', 'glich@@', 'k@@', 'eit@@', 'en,', 'die', 'ich', 'in', 'den', 'letz@@', 'ten', '1@@', '0@@', '0@@', 'ern', 'und', 'M@@', '<unk>', 'd@@', 'chen', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'die', 'sie', 'in', 'den', 'letz@@', 'ten', '1@@', '0@@', 'ern', 'und', 'M@@', '<unk>', 'glich@@', 'k@@', 'eit@@', 'en,', 'die', 'sie', 'in', 'den', 'letz@@', 'ten', 'K@@', '<unk>', 'r@@', 'per@@', '.', '</s>']
2025-05-29 19:27:52,742 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:27:52,742 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:27:52,742 - INFO - joeynmt.training - 	Hypothesis: Und ich bin ein paar Minuten und ich bin ein paar M<unk> glichkeiten, die ich in den letzten 100ern und M<unk> dchen und die M<unk> glichkeiten und die M<unk> glichkeit zu verwenden, die sie in den letzten 10ern und M<unk> glichkeiten, die sie in den letzten K<unk> rper.
2025-05-29 19:27:55,051 - INFO - joeynmt.training - Epoch   3, Step:    13100, Batch Loss:     2.372451, Batch Acc: 0.277364, Tokens per Sec:    30905, Lr: 0.000300
2025-05-29 19:27:57,458 - INFO - joeynmt.training - Epoch   3, Step:    13200, Batch Loss:     2.390408, Batch Acc: 0.278988, Tokens per Sec:    29882, Lr: 0.000300
2025-05-29 19:27:59,808 - INFO - joeynmt.training - Epoch   3, Step:    13300, Batch Loss:     2.620719, Batch Acc: 0.277108, Tokens per Sec:    29257, Lr: 0.000300
2025-05-29 19:28:02,275 - INFO - joeynmt.training - Epoch   3, Step:    13400, Batch Loss:     2.412556, Batch Acc: 0.274679, Tokens per Sec:    27806, Lr: 0.000300
2025-05-29 19:28:04,538 - INFO - joeynmt.training - Epoch   3, Step:    13500, Batch Loss:     2.316013, Batch Acc: 0.275934, Tokens per Sec:    32621, Lr: 0.000300
2025-05-29 19:28:04,539 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:28:04,539 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:28:17,249 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.38, ppl:  10.78, acc:   0.28, generation: 12.7025[sec], evaluation: 0.0000[sec]
2025-05-29 19:28:17,249 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:28:17,343 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/11000.ckpt
2025-05-29 19:28:17,348 - INFO - joeynmt.training - Example #0
2025-05-29 19:28:17,349 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:28:17,349 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:28:17,349 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'Ihnen', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'und', 'ich', 'habe', 'mich', 'nicht', 'nur', 'in', 'der', 'Welt', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:28:17,349 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:28:17,349 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:28:17,349 - INFO - joeynmt.training - 	Hypothesis: Und ich habe Ihnen ein paar Minuten und ich habe mich nicht nur in der Welt zu ver<unk> ndern.
2025-05-29 19:28:17,349 - INFO - joeynmt.training - Example #1
2025-05-29 19:28:17,349 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:28:17,349 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:28:17,349 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'nicht', 'nur', 'in', 'der', 'Welt', 'ist', 'ein', 'sehr', 'gut@@', 'er', 'K@@', '<unk>', 'r@@', 'per@@', '.', '</s>']
2025-05-29 19:28:17,349 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:28:17,349 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:28:17,349 - INFO - joeynmt.training - 	Hypothesis: Und ich habe nicht nur in der Welt ist ein sehr guter K<unk> rper.
2025-05-29 19:28:17,349 - INFO - joeynmt.training - Example #2
2025-05-29 19:28:17,350 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:28:17,350 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:28:17,350 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'und', 'ich', 'habe', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per@@', '.', '</s>']
2025-05-29 19:28:17,350 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:28:17,350 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:28:17,350 - INFO - joeynmt.training - 	Hypothesis: Und ich habe ein paar Minuten und ich habe ein paar Minuten und die K<unk> rper.
2025-05-29 19:28:17,350 - INFO - joeynmt.training - Example #3
2025-05-29 19:28:17,350 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:28:17,350 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:28:17,350 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'mich', 'sehr', 'sch@@', 'wi@@', 'er@@', 'ig@@', '.', '</s>']
2025-05-29 19:28:17,350 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:28:17,350 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:28:17,350 - INFO - joeynmt.training - 	Hypothesis: Und ich habe mich sehr schwierig.
2025-05-29 19:28:17,350 - INFO - joeynmt.training - Example #4
2025-05-29 19:28:17,351 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:28:17,351 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:28:17,351 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'Ihnen', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'und', 'ich', 'habe', 'mich', 'f@@', '<unk>', 'r', 'die', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'die', 'wir', 'in', 'der', 'K@@', '<unk>', 'r@@', 'per@@', '.', '</s>']
2025-05-29 19:28:17,351 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:28:17,351 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:28:17,351 - INFO - joeynmt.training - 	Hypothesis: Und ich habe Ihnen ein paar Minuten und ich habe mich f<unk> r die K<unk> rper, die wir in der K<unk> rper.
2025-05-29 19:28:19,699 - INFO - joeynmt.training - Epoch   3, Step:    13600, Batch Loss:     2.516124, Batch Acc: 0.277699, Tokens per Sec:    28848, Lr: 0.000300
2025-05-29 19:28:22,017 - INFO - joeynmt.training - Epoch   3, Step:    13700, Batch Loss:     2.394131, Batch Acc: 0.280763, Tokens per Sec:    30594, Lr: 0.000300
2025-05-29 19:28:24,289 - INFO - joeynmt.training - Epoch   3, Step:    13800, Batch Loss:     2.403488, Batch Acc: 0.279866, Tokens per Sec:    30831, Lr: 0.000300
2025-05-29 19:28:26,558 - INFO - joeynmt.training - Epoch   3, Step:    13900, Batch Loss:     2.526174, Batch Acc: 0.281513, Tokens per Sec:    31618, Lr: 0.000300
2025-05-29 19:28:28,773 - INFO - joeynmt.training - Epoch   3, Step:    14000, Batch Loss:     2.325357, Batch Acc: 0.281094, Tokens per Sec:    32111, Lr: 0.000300
2025-05-29 19:28:28,773 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:28:28,773 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:28:41,966 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.37, ppl:  10.72, acc:   0.29, generation: 13.1848[sec], evaluation: 0.0000[sec]
2025-05-29 19:28:41,966 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:28:42,056 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/11500.ckpt
2025-05-29 19:28:42,061 - INFO - joeynmt.training - Example #0
2025-05-29 19:28:42,062 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:28:42,062 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:28:42,062 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'es', 'in', 'den', 'letz@@', 'ten', '1@@', '00', 'Milli@@', 'onen', 'D@@', 'oll@@', 'ar', 'f@@', '<unk>', 'r', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'zu', '<unk>', 'ber@@', 'w@@', 'ach@@', 'ung', 'der', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:28:42,062 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:28:42,062 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:28:42,062 - INFO - joeynmt.training - 	Hypothesis: Und ich habe es in den letzten 100 Millionen Dollar f<unk> r die M<unk> glichkeiten zu <unk> berwachung der M<unk> nnern und die M<unk> glichkeit der K<unk> rper und die M<unk> glichkeit der M<unk> glichkeiten zu erreichen.
2025-05-29 19:28:42,062 - INFO - joeynmt.training - Example #1
2025-05-29 19:28:42,062 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:28:42,062 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:28:42,062 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'nicht', 'nur', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 't,', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'zu', 'mach@@', 'en.', '</s>']
2025-05-29 19:28:42,062 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:28:42,062 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:28:42,062 - INFO - joeynmt.training - 	Hypothesis: Und das ist nicht nur ein paar Minuten und die M<unk> glichkeit, die M<unk> glichkeiten zu machen.
2025-05-29 19:28:42,063 - INFO - joeynmt.training - Example #2
2025-05-29 19:28:42,063 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:28:42,063 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:28:42,063 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'das', 'M@@', 'e@@', 'er@@', 'es@@', 'k@@', 'op@@', 'f', 'in', 'der', 'L@@', 'age', 'in', 'der', 'Welt', 'zu', 'mach@@', 'en.', '</s>']
2025-05-29 19:28:42,063 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:28:42,063 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:28:42,063 - INFO - joeynmt.training - 	Hypothesis: Und das ist das Meereskopf in der Lage in der Welt zu machen.
2025-05-29 19:28:42,063 - INFO - joeynmt.training - Example #3
2025-05-29 19:28:42,063 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:28:42,063 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:28:42,063 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'eine', 'M@@', 'en@@', 'ge', 'M@@', '<unk>', 'n@@', 'n@@', 'er,', 'die', 'wir', 'in', 'der', 'Welt', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'die', 'wir', 'in', 'den', 'letz@@', 'ten', 'St@@', '<unk>', 'ck', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:28:42,063 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:28:42,063 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:28:42,063 - INFO - joeynmt.training - 	Hypothesis: Und das ist eine Menge M<unk> nner, die wir in der Welt und die M<unk> glichkeiten und die K<unk> rper und die M<unk> glichkeit und die M<unk> glichkeit und die K<unk> rper, die wir in den letzten St<unk> ck und die M<unk> glichkeiten zu erreichen.
2025-05-29 19:28:42,063 - INFO - joeynmt.training - Example #4
2025-05-29 19:28:42,063 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:28:42,063 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:28:42,063 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'eine', 'M@@', 'en@@', 'ge', 'M@@', '<unk>', 'n@@', 'n@@', 'er,', 'die', 'sich', 'in', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'zu', 'mach@@', 'en.', '</s>']
2025-05-29 19:28:42,064 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:28:42,064 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:28:42,064 - INFO - joeynmt.training - 	Hypothesis: Und das ist eine Menge M<unk> nner, die sich in die M<unk> glichkeiten zu machen.
2025-05-29 19:28:44,432 - INFO - joeynmt.training - Epoch   3, Step:    14100, Batch Loss:     2.358220, Batch Acc: 0.280182, Tokens per Sec:    29180, Lr: 0.000300
2025-05-29 19:28:46,744 - INFO - joeynmt.training - Epoch   3, Step:    14200, Batch Loss:     2.357936, Batch Acc: 0.282123, Tokens per Sec:    29734, Lr: 0.000300
2025-05-29 19:28:48,742 - INFO - joeynmt.training - Epoch   3, Step:    14300, Batch Loss:     2.353609, Batch Acc: 0.278317, Tokens per Sec:    35262, Lr: 0.000300
2025-05-29 19:28:50,734 - INFO - joeynmt.training - Epoch   3, Step:    14400, Batch Loss:     2.292674, Batch Acc: 0.280882, Tokens per Sec:    35815, Lr: 0.000300
2025-05-29 19:28:53,039 - INFO - joeynmt.training - Epoch   3, Step:    14500, Batch Loss:     2.360363, Batch Acc: 0.281631, Tokens per Sec:    30985, Lr: 0.000300
2025-05-29 19:28:53,039 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:28:53,039 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:29:05,541 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.36, ppl:  10.64, acc:   0.29, generation: 12.4899[sec], evaluation: 0.0000[sec]
2025-05-29 19:29:05,541 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:29:05,630 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/12000.ckpt
2025-05-29 19:29:05,636 - INFO - joeynmt.training - Example #0
2025-05-29 19:29:05,636 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:29:05,636 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:29:05,636 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'm@@', '<unk>', 'chte', 'Ihnen', 'ein', 'paar', 'Bei@@', 'spiel@@', 'e', 'von', 'der', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'um', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'um', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'um', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'um', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:29:05,636 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:29:05,636 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:29:05,636 - INFO - joeynmt.training - 	Hypothesis: Und ich m<unk> chte Ihnen ein paar Beispiele von der K<unk> rper und die K<unk> rper zu verwenden, um die K<unk> rper zu verwenden, um die K<unk> rper zu verwenden, um die K<unk> rper zu verwenden, um die K<unk> rper zu ver<unk> ndern.
2025-05-29 19:29:05,636 - INFO - joeynmt.training - Example #1
2025-05-29 19:29:05,636 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:29:05,636 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:29:05,636 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'm@@', '<unk>', 'chte', 'Ihnen', 'ein', 'paar', 'Jahre', 'al@@', 't', 'und', 'ich', 'sag@@', 'te,', '"@@', 'Ich', 'bin', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'e', 'in', 'der', 'L@@', 'age', 'der', 'S@@', 'pr@@', 'ache', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'die', 'wir', 'nicht', 'nur', 'in', 'der', 'L@@', 'age', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'die', 'wir', 'nicht', 'nur', 'in', 'der', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', 'w@@', 'end@@', 'en.', '</s>']
2025-05-29 19:29:05,636 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:29:05,637 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:29:05,637 - INFO - joeynmt.training - 	Hypothesis: Und ich m<unk> chte Ihnen ein paar Jahre alt und ich sagte, "Ich bin ein paar Minute in der Lage der Sprache zu verwenden, die wir nicht nur in der Lage zu verwenden, die wir nicht nur in der K<unk> rper zu verwenden.
2025-05-29 19:29:05,637 - INFO - joeynmt.training - Example #2
2025-05-29 19:29:05,637 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:29:05,637 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:29:05,637 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'ein', 'g@@', 'ro@@', '<unk>', 'es', 'Pro@@', 'bl@@', 'em', 'ist', 'ein', 'sehr', 'sch@@', 'wi@@', 'er@@', 'ig@@', 'es', 'M@@', 'al', 'in', 'der', 'L@@', 'age', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'die', 'wir', 'in', 'der', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'die', 'wir', 'in', 'der', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'die', 'wir', 'uns', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'die', 'wir', 'uns', 'in', 'den', 'U@@', 'S@@', 'A', 'und', 'der', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:29:05,637 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:29:05,637 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:29:05,637 - INFO - joeynmt.training - 	Hypothesis: Und das ist ein gro<unk> es Problem ist ein sehr schwieriges Mal in der Lage zu verwenden, die wir in der K<unk> rper und die K<unk> rper und die K<unk> rper zu verwenden, die wir in der K<unk> rper zu verwenden, die wir uns zu verwenden, die wir uns in den USA und der K<unk> rper zu ver<unk> ndern.
2025-05-29 19:29:05,637 - INFO - joeynmt.training - Example #3
2025-05-29 19:29:05,637 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:29:05,637 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:29:05,637 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'eine', 'M@@', 'en@@', 'ge', 'von', 'der', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'die', 'wir', 'uns', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'die', 'wir', 'uns', 'in', 'der', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'die', 'wir', 'in', 'der', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:29:05,637 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:29:05,637 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:29:05,637 - INFO - joeynmt.training - 	Hypothesis: Und das ist eine Menge von der K<unk> rper und die K<unk> rper und die K<unk> rper zu verwenden, die wir uns zu verwenden, die wir uns in der K<unk> rper und die K<unk> rper zu verwenden, die wir in der K<unk> rper zu ver<unk> ndern.
2025-05-29 19:29:05,637 - INFO - joeynmt.training - Example #4
2025-05-29 19:29:05,637 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:29:05,638 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:29:05,638 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'm@@', '<unk>', 'chte', 'Ihnen', 'ein', 'paar', 'Jahre', 'al@@', 't', 'und', 'ich', 'habe', 'mich', 'ge@@', 'fun@@', 'den,', 'aber', 'es', 'ist', 'ein', 'sehr', 'sch@@', 'wi@@', 'er@@', 'ig@@', 'es', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'zu', 'ver@@', 'w@@', 'end@@', 'en.', '</s>']
2025-05-29 19:29:05,638 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:29:05,638 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:29:05,638 - INFO - joeynmt.training - 	Hypothesis: Und ich m<unk> chte Ihnen ein paar Jahre alt und ich habe mich gefunden, aber es ist ein sehr schwieriges M<unk> glichkeiten zu verwenden.
2025-05-29 19:29:07,849 - INFO - joeynmt.training - Epoch   3, Step:    14600, Batch Loss:     2.442640, Batch Acc: 0.282189, Tokens per Sec:    30353, Lr: 0.000300
2025-05-29 19:29:10,105 - INFO - joeynmt.training - Epoch   3, Step:    14700, Batch Loss:     2.321082, Batch Acc: 0.280789, Tokens per Sec:    30553, Lr: 0.000300
2025-05-29 19:29:13,494 - INFO - joeynmt.training - Epoch   3, Step:    14800, Batch Loss:     2.343119, Batch Acc: 0.278799, Tokens per Sec:    21181, Lr: 0.000300
2025-05-29 19:29:15,891 - INFO - joeynmt.training - Epoch   3, Step:    14900, Batch Loss:     2.415384, Batch Acc: 0.285437, Tokens per Sec:    29231, Lr: 0.000300
2025-05-29 19:29:18,070 - INFO - joeynmt.training - Epoch   3, Step:    15000, Batch Loss:     2.347862, Batch Acc: 0.284090, Tokens per Sec:    31902, Lr: 0.000300
2025-05-29 19:29:18,070 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:29:18,070 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:29:25,955 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.36, ppl:  10.58, acc:   0.29, generation: 7.8778[sec], evaluation: 0.0000[sec]
2025-05-29 19:29:25,956 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:29:26,046 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/12500.ckpt
2025-05-29 19:29:26,052 - INFO - joeynmt.training - Example #0
2025-05-29 19:29:26,052 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:29:26,052 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:29:26,052 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'm@@', '<unk>', 'chte', 'Ihnen', 'ein', 'paar', 'Jahren', 'war', 'ich', 'ein', 'paar', 'M@@', '<unk>', 'glich@@', 'kei@@', 't,', 'dass', 'es', 'nicht', 'nur', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'und', 'die', 'S@@', 'tra@@', '<unk>', 'e', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:29:26,053 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:29:26,053 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:29:26,053 - INFO - joeynmt.training - 	Hypothesis: Und ich m<unk> chte Ihnen ein paar Jahren war ich ein paar M<unk> glichkeit, dass es nicht nur ein paar Minuten und die Stra<unk> e zu ver<unk> ndern.
2025-05-29 19:29:26,053 - INFO - joeynmt.training - Example #1
2025-05-29 19:29:26,053 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:29:26,053 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:29:26,053 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'ein', 'M@@', '<unk>', 'd@@', 'chen', 'und', 'das', 'ist', 'ein', 'M@@', '<unk>', 'd@@', 'chen', 'und', 'die', 'S@@', 'tra@@', '<unk>', 'e', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:29:26,053 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:29:26,053 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:29:26,053 - INFO - joeynmt.training - 	Hypothesis: Und das ist ein M<unk> dchen und das ist ein M<unk> dchen und die Stra<unk> e zu ver<unk> ndern.
2025-05-29 19:29:26,053 - INFO - joeynmt.training - Example #2
2025-05-29 19:29:26,053 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:29:26,053 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:29:26,053 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'ein', 'M@@', 'ann', 'in', 'der', 'L@@', 'age', 'der', 'von', 'der', 'M@@', '<unk>', 'glich@@', 'keit', 'und', 'die', 'S@@', 'tra@@', '<unk>', 'e', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:29:26,054 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:29:26,054 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:29:26,054 - INFO - joeynmt.training - 	Hypothesis: Und das ist ein Mann in der Lage der von der M<unk> glichkeit und die Stra<unk> e zu ver<unk> ndern.
2025-05-29 19:29:26,054 - INFO - joeynmt.training - Example #3
2025-05-29 19:29:26,054 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:29:26,054 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:29:26,054 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'ein', 'M@@', '<unk>', 'd@@', 'chen', 'und', 'die', 'S@@', 'tra@@', '<unk>', 'e', 'und', 'die', 'S@@', 'tra@@', '<unk>', 'e', 'und', 'die', 'S@@', 'tra@@', '<unk>', 'e', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:29:26,054 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:29:26,054 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:29:26,054 - INFO - joeynmt.training - 	Hypothesis: Und das ist ein M<unk> dchen und die Stra<unk> e und die Stra<unk> e und die Stra<unk> e zu ver<unk> ndern.
2025-05-29 19:29:26,054 - INFO - joeynmt.training - Example #4
2025-05-29 19:29:26,054 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:29:26,054 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:29:26,054 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'ein', 'M@@', '<unk>', 'd@@', 'chen', 'und', 'ich', 'sag@@', 'te', 'mi@@', 'r,', 'dass', 'ich', 'das', 'nicht', 'nur', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'und', 'die', 'S@@', 'tra@@', '<unk>', 'e', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:29:26,055 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:29:26,055 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:29:26,055 - INFO - joeynmt.training - 	Hypothesis: Und das ist ein M<unk> dchen und ich sagte mir, dass ich das nicht nur ein paar Minuten und die Stra<unk> e zu ver<unk> ndern.
2025-05-29 19:29:28,417 - INFO - joeynmt.training - Epoch   3, Step:    15100, Batch Loss:     2.440125, Batch Acc: 0.282969, Tokens per Sec:    28109, Lr: 0.000300
2025-05-29 19:29:30,795 - INFO - joeynmt.training - Epoch   3, Step:    15200, Batch Loss:     2.389760, Batch Acc: 0.280246, Tokens per Sec:    29254, Lr: 0.000300
2025-05-29 19:29:33,141 - INFO - joeynmt.training - Epoch   3, Step:    15300, Batch Loss:     2.289513, Batch Acc: 0.282251, Tokens per Sec:    29811, Lr: 0.000300
2025-05-29 19:29:35,464 - INFO - joeynmt.training - Epoch   3, Step:    15400, Batch Loss:     2.334094, Batch Acc: 0.284608, Tokens per Sec:    30802, Lr: 0.000300
2025-05-29 19:29:37,617 - INFO - joeynmt.training - Epoch   3, Step:    15500, Batch Loss:     2.221089, Batch Acc: 0.286217, Tokens per Sec:    33105, Lr: 0.000300
2025-05-29 19:29:37,617 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:29:37,617 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:29:46,068 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.36, ppl:  10.54, acc:   0.29, generation: 8.4446[sec], evaluation: 0.0000[sec]
2025-05-29 19:29:46,068 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:29:46,151 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/13000.ckpt
2025-05-29 19:29:46,158 - INFO - joeynmt.training - Example #0
2025-05-29 19:29:46,158 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:29:46,158 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:29:46,158 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'mir', 'nicht', 'nur', 'in', 'der', 'H@@', '<unk>', 'h@@', 'e', 'und', 'ich', 'habe', 'mich', 'nicht', 'nur', 'in', 'der', 'L@@', 'age', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:29:46,158 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:29:46,158 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:29:46,158 - INFO - joeynmt.training - 	Hypothesis: Und ich habe mir nicht nur in der H<unk> he und ich habe mich nicht nur in der Lage zu erreichen.
2025-05-29 19:29:46,159 - INFO - joeynmt.training - Example #1
2025-05-29 19:29:46,159 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:29:46,159 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:29:46,159 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'eine', 'M@@', 'en@@', 'ge', 'S@@', 'ache', 'ist', 'nicht', 'der', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:29:46,159 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:29:46,159 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:29:46,159 - INFO - joeynmt.training - 	Hypothesis: Und das ist eine Menge Sache ist nicht der K<unk> rper zu ver<unk> ndern.
2025-05-29 19:29:46,159 - INFO - joeynmt.training - Example #2
2025-05-29 19:29:46,159 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:29:46,159 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:29:46,159 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'eine', 'M@@', 'ut@@', 'ter', 'und', 'ich', 'habe', 'ein', 'paar', 'Jahre', 'al@@', 't', 'und', 'ich', 'habe', 'ein', 'paar', 'Jahre', 'al@@', 'ter', 'und', 'ich', 'habe', 'es', 'nicht', 'nur', 'ein', 'paar', 'Jahre', 'al@@', 't', 'und', 'die', 'S@@', 'ach@@', 'e,', 'die', 'wir', 'uns', 'in', 'der', 'H@@', '<unk>', 'h@@', 'e', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:29:46,159 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:29:46,159 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:29:46,159 - INFO - joeynmt.training - 	Hypothesis: Und das ist eine Mutter und ich habe ein paar Jahre alt und ich habe ein paar Jahre alter und ich habe es nicht nur ein paar Jahre alt und die Sache, die wir uns in der H<unk> he zu erreichen.
2025-05-29 19:29:46,159 - INFO - joeynmt.training - Example #3
2025-05-29 19:29:46,159 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:29:46,159 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:29:46,160 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'eine', 'M@@', 'en@@', 'ge', 'S@@', 'ache', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:29:46,160 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:29:46,160 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:29:46,160 - INFO - joeynmt.training - 	Hypothesis: Und das ist eine Menge Sache und die K<unk> rper und die K<unk> rper und die K<unk> rper und die K<unk> rper zu ver<unk> ndern.
2025-05-29 19:29:46,160 - INFO - joeynmt.training - Example #4
2025-05-29 19:29:46,160 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:29:46,160 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:29:46,160 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'mir', 'nicht', 'nur', 'in', 'der', 'H@@', '<unk>', 'h@@', 'e', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:29:46,160 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:29:46,160 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:29:46,160 - INFO - joeynmt.training - 	Hypothesis: Und ich habe mir nicht nur in der H<unk> he zu erreichen.
2025-05-29 19:29:48,499 - INFO - joeynmt.training - Epoch   3, Step:    15600, Batch Loss:     2.276264, Batch Acc: 0.281084, Tokens per Sec:    29011, Lr: 0.000300
2025-05-29 19:29:50,731 - INFO - joeynmt.training - Epoch   3, Step:    15700, Batch Loss:     2.293959, Batch Acc: 0.285672, Tokens per Sec:    30642, Lr: 0.000300
2025-05-29 19:29:52,976 - INFO - joeynmt.training - Epoch   3, Step:    15800, Batch Loss:     2.388751, Batch Acc: 0.286809, Tokens per Sec:    30237, Lr: 0.000300
2025-05-29 19:29:55,588 - INFO - joeynmt.training - Epoch   3, Step:    15900, Batch Loss:     2.294806, Batch Acc: 0.284385, Tokens per Sec:    26950, Lr: 0.000300
2025-05-29 19:29:58,021 - INFO - joeynmt.training - Epoch   3, Step:    16000, Batch Loss:     2.417643, Batch Acc: 0.284690, Tokens per Sec:    28545, Lr: 0.000300
2025-05-29 19:29:58,022 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:29:58,022 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:30:10,232 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.35, ppl:  10.52, acc:   0.29, generation: 12.2011[sec], evaluation: 0.0000[sec]
2025-05-29 19:30:10,232 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:30:10,310 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/13500.ckpt
2025-05-29 19:30:10,316 - INFO - joeynmt.training - Example #0
2025-05-29 19:30:10,317 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:30:10,317 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:30:10,317 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'mich', 'in', 'den', 'letz@@', 'ten', '1@@', '5', 'M@@', 'in@@', 'ut@@', 'en', 'und', 'ich', 'habe', 'mich', 'nicht', 'nur', 'in', 'den', 'letz@@', 'ten', '1@@', '5', 'M@@', 'in@@', 'ut@@', 'en', 'und', 'die', 'B@@', '<unk>', 'r@@', 'ger@@', '<unk>', 't', 'und', 'dann', 'in', 'den', 'letz@@', 'ten', '1@@', '0@@', '0@@', 'ern', 'und', '1@@', '5', 'Milli@@', 'onen', 'D@@', 'oll@@', 'ar', 'zu', 'er@@', 'schaff@@', 'en,', 'um', 'die', 'wir', 'in', 'der', 'Welt', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:30:10,317 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:30:10,317 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:30:10,317 - INFO - joeynmt.training - 	Hypothesis: Und ich habe mich in den letzten 15 Minuten und ich habe mich nicht nur in den letzten 15 Minuten und die B<unk> rger<unk> t und dann in den letzten 100ern und 15 Millionen Dollar zu erschaffen, um die wir in der Welt zu erreichen.
2025-05-29 19:30:10,317 - INFO - joeynmt.training - Example #1
2025-05-29 19:30:10,317 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:30:10,317 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:30:10,317 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'und', 'ich', 'sag@@', 'te,', '"@@', 'Ich', 'bin', 'ein', 'M@@', '<unk>', 'glich@@', 'k@@', 'eit@@', '"', 'und', '"@@', 'N@@', 'ein@@', '"', 'und', '"@@', 'N@@', 'ein@@', '"', 'und', '"@@', 'N@@', 'ein@@', '"', 'und', '"@@', 'N@@', 'ein@@', '"', 'und', '"@@', 'N@@', 'ein@@', '"', 'und', '"@@', 'N@@', 'ein@@', '"', 'und', '"@@', 'N@@', 'ein@@', '"', 'und', '"@@', 'N@@', 'ein@@', '"', 'und', '"@@', '"@@', 'N@@', 'ein@@', '"', 'und', '"@@', 'N@@', 'ein@@', '"', 'und', '"@@', 'M@@', 'i@@', 't', 'das', 'B@@', 'o@@', 'den', 'und', 'der', 'T@@', 'at', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'k@@', 'eit@@', '."', '</s>']
2025-05-29 19:30:10,317 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:30:10,317 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:30:10,318 - INFO - joeynmt.training - 	Hypothesis: Und ich habe ein paar Minuten und ich sagte, "Ich bin ein M<unk> glichkeit" und "Nein" und "Nein" und "Nein" und "Nein" und "Nein" und "Nein" und "Nein" und "Nein" und ""Nein" und "Nein" und "Mit das Boden und der Tat und die M<unk> glichkeit."
2025-05-29 19:30:10,318 - INFO - joeynmt.training - Example #2
2025-05-29 19:30:10,318 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:30:10,318 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:30:10,318 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'und', 'ich', 'sag@@', 'te,', '"@@', 'Ich', 'bin', 'ein', 'M@@', '<unk>', 'n@@', 'n@@', 'er,', 'dass', 'wir', 'die', 'F@@', '<unk>', 'h@@', 'ig@@', 'keit', 'der', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'er@@', 'schaff@@', 'en,', 'und', 'das', 'ist', 'ein', 'M@@', '<unk>', 'glich@@', 'kei@@', 't.', '</s>']
2025-05-29 19:30:10,318 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:30:10,318 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:30:10,318 - INFO - joeynmt.training - 	Hypothesis: Und ich habe ein paar Minuten und ich sagte, "Ich bin ein M<unk> nner, dass wir die F<unk> higkeit der K<unk> rper zu erschaffen, und das ist ein M<unk> glichkeit.
2025-05-29 19:30:10,318 - INFO - joeynmt.training - Example #3
2025-05-29 19:30:10,318 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:30:10,318 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:30:10,318 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'und', 'ich', 'habe', 'eine', 'M@@', 'en@@', 'ge', 'S@@', 'el@@', 'b@@', 'st@@', '<unk>', 'r@@', 'k@@', 'e', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'zu', 'er@@', 'schaff@@', 'en,', 'und', 'das', 'ist', 'ein', 'M@@', 'ann', 'und', 'der', 'T@@', 'at', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'zu', 'er@@', 'schaff@@', 'en,', 'die', 'wir', 'uns', 'in', 'der', 'Welt', 'zu', 'er@@', 'schaff@@', 'en,', 'und', 'das', 'ist', 'ein', 'M@@', '<unk>', 'n@@', 'n@@', 'er,', 'dass', 'wir', 'uns', 'die', 'W@@', '<unk>', 'r@@', 'ter@@', 'n', 'und', 'das', 'ist', 'ein', 'M@@', '<unk>', 'glich@@', 'kei@@', 't.', '</s>']
2025-05-29 19:30:10,318 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:30:10,318 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:30:10,318 - INFO - joeynmt.training - 	Hypothesis: Und ich habe ein paar Minuten und ich habe eine Menge Selbst<unk> rke und die M<unk> glichkeiten zu erschaffen, und das ist ein Mann und der Tat und die M<unk> glichkeiten zu erschaffen, die wir uns in der Welt zu erschaffen, und das ist ein M<unk> nner, dass wir uns die W<unk> rtern und das ist ein M<unk> glichkeit.
2025-05-29 19:30:10,318 - INFO - joeynmt.training - Example #4
2025-05-29 19:30:10,319 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:30:10,319 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:30:10,319 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'und', 'ich', 'habe', 'eine', 'M@@', 'en@@', 'ge', 'S@@', 'pr@@', 'ache', 'zu', 'er@@', 'schaff@@', 'en,', 'die', 'ich', 'in', 'der', 'Welt', 'zu', 'er@@', 'schaff@@', 'en,', 'die', 'ich', 'in', 'der', 'Welt', 'zu', 'er@@', 'schaff@@', 'en,', 'die', 'ich', 'in', 'der', 'L@@', 'u@@', 'ft', 'zu', 'er@@', 'schaff@@', 'en,', 'die', 'ich', 'in', 'der', 'Welt', 'zu', 'er@@', 'schaff@@', 'en,', 'die', 'sich', 'in', 'der', 'Welt', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:30:10,319 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:30:10,319 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:30:10,319 - INFO - joeynmt.training - 	Hypothesis: Und ich habe ein paar Minuten und ich habe eine Menge Sprache zu erschaffen, die ich in der Welt zu erschaffen, die ich in der Welt zu erschaffen, die ich in der Luft zu erschaffen, die ich in der Welt zu erschaffen, die sich in der Welt zu erreichen.
2025-05-29 19:30:11,112 - INFO - joeynmt.training - Epoch   3: total training loss 12685.99
2025-05-29 19:30:11,113 - INFO - joeynmt.training - EPOCH 4
2025-05-29 19:30:12,694 - INFO - joeynmt.training - Epoch   4, Step:    16100, Batch Loss:     2.296791, Batch Acc: 0.288885, Tokens per Sec:    29927, Lr: 0.000300
2025-05-29 19:30:14,979 - INFO - joeynmt.training - Epoch   4, Step:    16200, Batch Loss:     2.312437, Batch Acc: 0.289359, Tokens per Sec:    31666, Lr: 0.000300
2025-05-29 19:30:17,156 - INFO - joeynmt.training - Epoch   4, Step:    16300, Batch Loss:     2.399806, Batch Acc: 0.288890, Tokens per Sec:    31371, Lr: 0.000300
2025-05-29 19:30:20,279 - INFO - joeynmt.training - Epoch   4, Step:    16400, Batch Loss:     2.366874, Batch Acc: 0.290024, Tokens per Sec:    23597, Lr: 0.000300
2025-05-29 19:30:22,638 - INFO - joeynmt.training - Epoch   4, Step:    16500, Batch Loss:     2.316525, Batch Acc: 0.291674, Tokens per Sec:    29547, Lr: 0.000300
2025-05-29 19:30:22,638 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:30:22,639 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:30:28,641 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.35, ppl:  10.46, acc:   0.29, generation: 5.9951[sec], evaluation: 0.0000[sec]
2025-05-29 19:30:28,641 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:30:28,737 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/14000.ckpt
2025-05-29 19:30:28,743 - INFO - joeynmt.training - Example #0
2025-05-29 19:30:28,743 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:30:28,743 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:30:28,743 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'bin', 'nicht', 'nur', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:30:28,743 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:30:28,743 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:30:28,743 - INFO - joeynmt.training - 	Hypothesis: Und ich bin nicht nur ein paar Minuten und die K<unk> rper und die K<unk> rper zu ver<unk> ndern.
2025-05-29 19:30:28,743 - INFO - joeynmt.training - Example #1
2025-05-29 19:30:28,743 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:30:28,743 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:30:28,743 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:30:28,744 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:30:28,744 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:30:28,744 - INFO - joeynmt.training - 	Hypothesis: Und das ist ein paar Minuten und die K<unk> rper und die K<unk> rper und die K<unk> rper zu ver<unk> ndern.
2025-05-29 19:30:28,744 - INFO - joeynmt.training - Example #2
2025-05-29 19:30:28,744 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:30:28,744 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:30:28,744 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:30:28,744 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:30:28,744 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:30:28,744 - INFO - joeynmt.training - 	Hypothesis: Und das ist ein paar Minuten und die K<unk> rper und die K<unk> rper zu ver<unk> ndern.
2025-05-29 19:30:28,744 - INFO - joeynmt.training - Example #3
2025-05-29 19:30:28,744 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:30:28,744 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:30:28,744 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:30:28,744 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:30:28,744 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:30:28,744 - INFO - joeynmt.training - 	Hypothesis: Und das ist ein paar Minuten und die K<unk> rper und die K<unk> rper und die K<unk> rper und die K<unk> rper zu ver<unk> ndern.
2025-05-29 19:30:28,744 - INFO - joeynmt.training - Example #4
2025-05-29 19:30:28,744 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:30:28,744 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:30:28,745 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'und', 'ich', 'bin', 'ein', 'paar', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:30:28,745 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:30:28,745 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:30:28,745 - INFO - joeynmt.training - 	Hypothesis: Und das ist ein paar Minuten und ich bin ein paar M<unk> nnern und die K<unk> rper zu ver<unk> ndern.
2025-05-29 19:30:30,961 - INFO - joeynmt.training - Epoch   4, Step:    16600, Batch Loss:     2.280330, Batch Acc: 0.290079, Tokens per Sec:    30799, Lr: 0.000300
2025-05-29 19:30:33,282 - INFO - joeynmt.training - Epoch   4, Step:    16700, Batch Loss:     2.465474, Batch Acc: 0.287051, Tokens per Sec:    30411, Lr: 0.000300
2025-05-29 19:30:35,627 - INFO - joeynmt.training - Epoch   4, Step:    16800, Batch Loss:     2.311054, Batch Acc: 0.290210, Tokens per Sec:    29899, Lr: 0.000300
2025-05-29 19:30:37,896 - INFO - joeynmt.training - Epoch   4, Step:    16900, Batch Loss:     2.398854, Batch Acc: 0.288348, Tokens per Sec:    30936, Lr: 0.000300
2025-05-29 19:30:40,108 - INFO - joeynmt.training - Epoch   4, Step:    17000, Batch Loss:     2.424603, Batch Acc: 0.289826, Tokens per Sec:    32602, Lr: 0.000300
2025-05-29 19:30:40,108 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:30:40,109 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:30:54,533 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.34, ppl:  10.37, acc:   0.29, generation: 14.4145[sec], evaluation: 0.0000[sec]
2025-05-29 19:30:54,533 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:30:54,615 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/14500.ckpt
2025-05-29 19:30:54,621 - INFO - joeynmt.training - Example #0
2025-05-29 19:30:54,621 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:30:54,621 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:30:54,621 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'eine', 'M@@', 'en@@', 'ge', 'S@@', 'ach@@', 'e,', 'die', 'ich', 'in', 'der', 'N@@', '<unk>', 'h@@', 'e', 'von', 'der', 'S@@', 'tra@@', '<unk>', 'e', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:30:54,621 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:30:54,621 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:30:54,621 - INFO - joeynmt.training - 	Hypothesis: Und ich habe eine Menge Sache, die ich in der N<unk> he von der Stra<unk> e zu ver<unk> ndern.
2025-05-29 19:30:54,621 - INFO - joeynmt.training - Example #1
2025-05-29 19:30:54,622 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:30:54,622 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:30:54,622 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'eine', 'M@@', 'en@@', 'ge', 'S@@', 'ach@@', 'e,', 'die', 'ich', 'in', 'der', 'L@@', 'age', 'in', 'der', 'Welt', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:30:54,622 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:30:54,622 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:30:54,622 - INFO - joeynmt.training - 	Hypothesis: Und ich habe eine Menge Sache, die ich in der Lage in der Welt zu ver<unk> ndern.
2025-05-29 19:30:54,622 - INFO - joeynmt.training - Example #2
2025-05-29 19:30:54,622 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:30:54,622 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:30:54,622 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'eine', 'M@@', 'en@@', 'ge', 'S@@', 'ach@@', 'e,', 'die', 'ich', 'in', 'der', 'N@@', '<unk>', 'h@@', 'e', 'von', 'einem', 'K@@', 'op@@', 'f', 'in', 'der', 'L@@', 'age', 'in', 'der', 'Welt', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:30:54,622 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:30:54,622 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:30:54,622 - INFO - joeynmt.training - 	Hypothesis: Und ich habe eine Menge Sache, die ich in der N<unk> he von einem Kopf in der Lage in der Welt zu ver<unk> ndern.
2025-05-29 19:30:54,622 - INFO - joeynmt.training - Example #3
2025-05-29 19:30:54,622 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:30:54,622 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:30:54,622 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'eine', 'M@@', 'en@@', 'ge', 'M@@', 'en@@', 'ge', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'die', 'die', 'K@@', '<unk>', 'r@@', 'per@@', 's', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per@@', 's', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per@@', 's', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per@@', 's', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per@@', 's', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per@@', 's', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'die', 'die', 'K@@', '<unk>', 'r@@', 'per@@', 's', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'die', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'K@@', '<unk>', 'r@@', 'per@@', 'n', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per@@', 'ation', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:30:54,623 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:30:54,623 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:30:54,623 - INFO - joeynmt.training - 	Hypothesis: Und ich habe eine Menge Menge und die K<unk> rper, die die K<unk> rpers und die K<unk> rpers und die K<unk> rpers und die K<unk> rpers und die K<unk> rpers und die K<unk> rpers und die K<unk> rper, die die K<unk> rpers und die K<unk> rper, die die M<unk> glichkeit der K<unk> rpern und die K<unk> rperation zu ver<unk> ndern.
2025-05-29 19:30:54,623 - INFO - joeynmt.training - Example #4
2025-05-29 19:30:54,623 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:30:54,623 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:30:54,623 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'eine', 'M@@', 'en@@', 'ge', 'S@@', 'pr@@', 'ache', 'in', 'der', 'Welt', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:30:54,623 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:30:54,623 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:30:54,623 - INFO - joeynmt.training - 	Hypothesis: Und ich habe eine Menge Sprache in der Welt zu ver<unk> ndern.
2025-05-29 19:30:56,819 - INFO - joeynmt.training - Epoch   4, Step:    17100, Batch Loss:     2.171016, Batch Acc: 0.288054, Tokens per Sec:    30299, Lr: 0.000300
2025-05-29 19:30:59,045 - INFO - joeynmt.training - Epoch   4, Step:    17200, Batch Loss:     2.468323, Batch Acc: 0.288802, Tokens per Sec:    30592, Lr: 0.000300
2025-05-29 19:31:01,270 - INFO - joeynmt.training - Epoch   4, Step:    17300, Batch Loss:     2.368317, Batch Acc: 0.290772, Tokens per Sec:    31460, Lr: 0.000300
2025-05-29 19:31:03,647 - INFO - joeynmt.training - Epoch   4, Step:    17400, Batch Loss:     2.241987, Batch Acc: 0.290296, Tokens per Sec:    29398, Lr: 0.000300
2025-05-29 19:31:05,972 - INFO - joeynmt.training - Epoch   4, Step:    17500, Batch Loss:     2.276853, Batch Acc: 0.287712, Tokens per Sec:    29849, Lr: 0.000300
2025-05-29 19:31:05,972 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:31:05,972 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:31:11,600 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.34, ppl:  10.37, acc:   0.29, generation: 5.6205[sec], evaluation: 0.0000[sec]
2025-05-29 19:31:11,600 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:31:11,686 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/15000.ckpt
2025-05-29 19:31:11,692 - INFO - joeynmt.training - Example #0
2025-05-29 19:31:11,692 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:31:11,692 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:31:11,692 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'Ihnen', 'ein', 'paar', 'Bei@@', 'spiel@@', 'e', 'von', 'der', 'T@@', 'at', 'in', 'der', 'Welt', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:31:11,692 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:31:11,692 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:31:11,692 - INFO - joeynmt.training - 	Hypothesis: Und ich habe Ihnen ein paar Beispiele von der Tat in der Welt zu erreichen.
2025-05-29 19:31:11,692 - INFO - joeynmt.training - Example #1
2025-05-29 19:31:11,692 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:31:11,692 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:31:11,692 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'ein', 'paar', 'T@@', 'ag@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'en,', 'wie', 'ich', 'das', 'nicht', 'nur', 'ein', 'paar', 'T@@', 'age', 'in', 'der', 'Welt', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:31:11,693 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:31:11,693 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:31:11,693 - INFO - joeynmt.training - 	Hypothesis: Und ich habe ein paar Tage, die ich Ihnen zeigen, wie ich das nicht nur ein paar Tage in der Welt zu ver<unk> ndern.
2025-05-29 19:31:11,693 - INFO - joeynmt.training - Example #2
2025-05-29 19:31:11,693 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:31:11,693 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:31:11,693 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'sag@@', 'te,', '"@@', 'Ich', 'bin', 'ein', 'paar', 'T@@', 'age', 'ist', 'ein', 'sehr', 'sch@@', '<unk>', 'n@@', 'e', 'M@@', '<unk>', 'd@@', 'chen', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:31:11,693 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:31:11,693 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:31:11,693 - INFO - joeynmt.training - 	Hypothesis: Und ich sagte, "Ich bin ein paar Tage ist ein sehr sch<unk> ne M<unk> dchen zu erreichen.
2025-05-29 19:31:11,693 - INFO - joeynmt.training - Example #3
2025-05-29 19:31:11,693 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:31:11,693 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:31:11,693 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'Ihnen', 'ein', 'paar', 'Bei@@', 'spiel@@', 'e', 'von', 'der', 'T@@', 'y@@', 'p@@', 'en', 'und', 'die', 'K@@', 'ra@@', 'ft', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:31:11,693 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:31:11,693 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:31:11,693 - INFO - joeynmt.training - 	Hypothesis: Und ich habe Ihnen ein paar Beispiele von der Typen und die Kraft und die K<unk> rper zu ver<unk> ndern.
2025-05-29 19:31:11,693 - INFO - joeynmt.training - Example #4
2025-05-29 19:31:11,694 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:31:11,694 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:31:11,694 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'sag@@', 'te', 'mi@@', 'r,', '"@@', 'Ich', 'bin', 'ein', 'paar', 'T@@', 'age', 'ich', 'in', 'der', 'Welt', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:31:11,694 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:31:11,694 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:31:11,694 - INFO - joeynmt.training - 	Hypothesis: Und ich sagte mir, "Ich bin ein paar Tage ich in der Welt zu erreichen.
2025-05-29 19:31:14,054 - INFO - joeynmt.training - Epoch   4, Step:    17600, Batch Loss:     2.321118, Batch Acc: 0.290210, Tokens per Sec:    28717, Lr: 0.000300
2025-05-29 19:31:16,131 - INFO - joeynmt.training - Epoch   4, Step:    17700, Batch Loss:     2.220540, Batch Acc: 0.292353, Tokens per Sec:    34428, Lr: 0.000300
2025-05-29 19:31:18,135 - INFO - joeynmt.training - Epoch   4, Step:    17800, Batch Loss:     2.315293, Batch Acc: 0.292707, Tokens per Sec:    35381, Lr: 0.000300
2025-05-29 19:31:20,117 - INFO - joeynmt.training - Epoch   4, Step:    17900, Batch Loss:     2.242255, Batch Acc: 0.292974, Tokens per Sec:    35575, Lr: 0.000300
2025-05-29 19:31:22,023 - INFO - joeynmt.training - Epoch   4, Step:    18000, Batch Loss:     2.346682, Batch Acc: 0.287355, Tokens per Sec:    36687, Lr: 0.000300
2025-05-29 19:31:22,023 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:31:22,024 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:31:36,363 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.33, ppl:  10.30, acc:   0.30, generation: 14.3303[sec], evaluation: 0.0000[sec]
2025-05-29 19:31:36,363 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:31:36,456 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/15500.ckpt
2025-05-29 19:31:36,463 - INFO - joeynmt.training - Example #0
2025-05-29 19:31:36,463 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:31:36,463 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:31:36,463 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'Ihnen', 'ein', 'paar', 'Bei@@', 'spiel@@', 'e', 'von', 'einem', 'T@@', 'ag', 'in', 'den', 'letz@@', 'ten', '1@@', '0@@', '0@@', '0@@', '0@@', 'ern', 'und', '1@@', '0@@', '0@@', '0@@', '0@@', '0@@', '.', '</s>']
2025-05-29 19:31:36,463 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:31:36,463 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:31:36,463 - INFO - joeynmt.training - 	Hypothesis: Und ich habe Ihnen ein paar Beispiele von einem Tag in den letzten 10000ern und 100000.
2025-05-29 19:31:36,463 - INFO - joeynmt.training - Example #1
2025-05-29 19:31:36,463 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:31:36,464 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:31:36,464 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'nicht', 'der', 'T@@', 'at', 'ist', 'ein', 'K@@', '<unk>', 'r@@', 'per@@', '.', '</s>']
2025-05-29 19:31:36,464 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:31:36,464 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:31:36,464 - INFO - joeynmt.training - 	Hypothesis: Und das ist nicht der Tat ist ein K<unk> rper.
2025-05-29 19:31:36,464 - INFO - joeynmt.training - Example #2
2025-05-29 19:31:36,464 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:31:36,464 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:31:36,464 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'ein', 'M@@', 'ann', 'ist', 'ein', 'sehr', 'sch@@', '<unk>', 'tz@@', 'lich@@', 'es', 'Pro@@', 'bl@@', 'em', 'ist,', 'dass', 'wir', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:31:36,464 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:31:36,464 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:31:36,464 - INFO - joeynmt.training - 	Hypothesis: Und das ist ein Mann ist ein sehr sch<unk> tzliches Problem ist, dass wir die M<unk> glichkeit der K<unk> rper zu ver<unk> ndern.
2025-05-29 19:31:36,464 - INFO - joeynmt.training - Example #3
2025-05-29 19:31:36,464 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:31:36,465 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:31:36,465 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'ein', 'M@@', 'ann', 'ist', 'das', 'nicht', 'so', 'viel', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:31:36,465 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:31:36,465 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:31:36,465 - INFO - joeynmt.training - 	Hypothesis: Und das ist ein Mann ist das nicht so viel zu ver<unk> ndern.
2025-05-29 19:31:36,465 - INFO - joeynmt.training - Example #4
2025-05-29 19:31:36,465 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:31:36,465 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:31:36,465 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'Ihnen', 'ein', 'paar', 'Bei@@', 'spiel@@', 'e', 'von', 'einem', 'T@@', 'ag', 'in', 'den', 'letz@@', 'ten', '1@@', '5', 'Jahren', 'in', 'der', 'Welt', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:31:36,465 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:31:36,465 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:31:36,465 - INFO - joeynmt.training - 	Hypothesis: Und ich habe Ihnen ein paar Beispiele von einem Tag in den letzten 15 Jahren in der Welt zu ver<unk> ndern.
2025-05-29 19:31:38,886 - INFO - joeynmt.training - Epoch   4, Step:    18100, Batch Loss:     2.318897, Batch Acc: 0.289613, Tokens per Sec:    27760, Lr: 0.000300
2025-05-29 19:31:41,168 - INFO - joeynmt.training - Epoch   4, Step:    18200, Batch Loss:     2.407396, Batch Acc: 0.290574, Tokens per Sec:    29771, Lr: 0.000300
2025-05-29 19:31:43,613 - INFO - joeynmt.training - Epoch   4, Step:    18300, Batch Loss:     2.286033, Batch Acc: 0.289060, Tokens per Sec:    29104, Lr: 0.000300
2025-05-29 19:31:45,746 - INFO - joeynmt.training - Epoch   4, Step:    18400, Batch Loss:     2.316275, Batch Acc: 0.292761, Tokens per Sec:    32816, Lr: 0.000300
2025-05-29 19:31:47,911 - INFO - joeynmt.training - Epoch   4, Step:    18500, Batch Loss:     2.272801, Batch Acc: 0.294153, Tokens per Sec:    32885, Lr: 0.000300
2025-05-29 19:31:47,911 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:31:47,911 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:32:02,647 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.33, ppl:  10.27, acc:   0.29, generation: 14.7236[sec], evaluation: 0.0000[sec]
2025-05-29 19:32:02,647 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:32:02,732 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/16000.ckpt
2025-05-29 19:32:02,738 - INFO - joeynmt.training - Example #0
2025-05-29 19:32:02,739 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:32:02,739 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:32:02,739 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'Ihnen', 'ein', 'paar', 'Bei@@', 'spiel@@', 'e', 'von', '1@@', '0@@', '0@@', '.000', 'D@@', 'oll@@', 'ar', 'f@@', '<unk>', 'r', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:32:02,739 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:32:02,739 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:32:02,739 - INFO - joeynmt.training - 	Hypothesis: Und ich habe Ihnen ein paar Beispiele von 100.000 Dollar f<unk> r die M<unk> glichkeiten zu erreichen.
2025-05-29 19:32:02,739 - INFO - joeynmt.training - Example #1
2025-05-29 19:32:02,739 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:32:02,739 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:32:02,739 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'ein', 'M@@', '<unk>', 'd@@', 'chen', 'ist', 'nicht', 'nur', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 't,', 'die', 'wir', 'nicht', 'er@@', 'war@@', 't@@', 'et', 'haben,', 'und', 'wir', 'haben', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 't,', 'die', 'wir', 'nicht', 'er@@', 'war@@', 't@@', 'et', 'haben,', 'und', 'wir', 'haben', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 't,', 'die', 'wir', 'nicht', 'er@@', 'war@@', 't@@', 'et', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 't,', 'die', 'wir', 'nicht', 'er@@', 'war@@', 't@@', 'et', 'haben,', 'und', 'die', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 't,', 'die', 'wir', 'nicht', 'nur', 'ein', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 't,', 'die', 'wir']
2025-05-29 19:32:02,739 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:32:02,739 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:32:02,739 - INFO - joeynmt.training - 	Hypothesis: Und das ist ein M<unk> dchen ist nicht nur ein paar Minuten und die M<unk> glichkeit, die wir nicht erwartet haben, und wir haben die M<unk> glichkeit, die wir nicht erwartet haben, und wir haben die M<unk> glichkeit, die wir nicht erwartet und die M<unk> glichkeit, die wir nicht erwartet haben, und die M<unk> nner und die M<unk> glichkeit, die wir nicht nur ein M<unk> nnern und die M<unk> glichkeit, die wir
2025-05-29 19:32:02,739 - INFO - joeynmt.training - Example #2
2025-05-29 19:32:02,740 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:32:02,740 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:32:02,740 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'ein', 'M@@', '<unk>', 'd@@', 'chen', 'ist', 'ein', 'M@@', '<unk>', 'd@@', 'chen', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 't,', 'die', 'wir', 'in', 'der', 'L@@', 'age', 'in', 'der', 'L@@', 'age', 'in', 'der', 'L@@', 'age', 'in', 'der', 'L@@', 'age', 'in', 'der', 'L@@', 'age', 'in', 'der', 'L@@', 'age', 'in', 'der', 'L@@', 'age', 'in', 'der', 'L@@', 'age', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:32:02,740 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:32:02,740 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:32:02,740 - INFO - joeynmt.training - 	Hypothesis: Und das ist ein M<unk> dchen ist ein M<unk> dchen und die M<unk> glichkeit, die wir in der Lage in der Lage in der Lage in der Lage in der Lage in der Lage in der Lage in der Lage zu ver<unk> ndern und die M<unk> glichkeiten zu ver<unk> ndern.
2025-05-29 19:32:02,740 - INFO - joeynmt.training - Example #3
2025-05-29 19:32:02,740 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:32:02,740 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:32:02,740 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'ein', 'M@@', '<unk>', 'd@@', 'chen', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 't,', 'die', 'wir', 'in', 'der', 'L@@', 'age', 'in', 'der', 'L@@', 'age', 'zu', 'er@@', 'for@@', 'sch@@', 'en.', '</s>']
2025-05-29 19:32:02,740 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:32:02,740 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:32:02,740 - INFO - joeynmt.training - 	Hypothesis: Und das ist ein M<unk> dchen und die M<unk> glichkeit, die wir in der Lage in der Lage zu erforschen.
2025-05-29 19:32:02,740 - INFO - joeynmt.training - Example #4
2025-05-29 19:32:02,740 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:32:02,740 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:32:02,740 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'ein', 'M@@', '<unk>', 'd@@', 'chen', 'ist', 'ein', 'M@@', '<unk>', 'd@@', 'chen', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 't,', 'die', 'wir', 'in', 'der', 'L@@', 'age', 'zu', 'er@@', 'for@@', 'sch@@', 'en.', '</s>']
2025-05-29 19:32:02,740 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:32:02,741 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:32:02,741 - INFO - joeynmt.training - 	Hypothesis: Und das ist ein M<unk> dchen ist ein M<unk> dchen und die M<unk> glichkeit, die wir in der Lage zu erforschen.
2025-05-29 19:32:05,173 - INFO - joeynmt.training - Epoch   4, Step:    18600, Batch Loss:     2.348016, Batch Acc: 0.294087, Tokens per Sec:    28288, Lr: 0.000300
2025-05-29 19:32:07,629 - INFO - joeynmt.training - Epoch   4, Step:    18700, Batch Loss:     2.210435, Batch Acc: 0.292925, Tokens per Sec:    28481, Lr: 0.000300
2025-05-29 19:32:09,932 - INFO - joeynmt.training - Epoch   4, Step:    18800, Batch Loss:     2.313437, Batch Acc: 0.296629, Tokens per Sec:    30604, Lr: 0.000300
2025-05-29 19:32:12,154 - INFO - joeynmt.training - Epoch   4, Step:    18900, Batch Loss:     2.304074, Batch Acc: 0.291532, Tokens per Sec:    31319, Lr: 0.000300
2025-05-29 19:32:14,475 - INFO - joeynmt.training - Epoch   4, Step:    19000, Batch Loss:     2.449560, Batch Acc: 0.287664, Tokens per Sec:    30197, Lr: 0.000300
2025-05-29 19:32:14,475 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:32:14,475 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:32:26,453 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.32, ppl:  10.20, acc:   0.30, generation: 11.9645[sec], evaluation: 0.0000[sec]
2025-05-29 19:32:26,453 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:32:26,540 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/16500.ckpt
2025-05-29 19:32:26,548 - INFO - joeynmt.training - Example #0
2025-05-29 19:32:26,548 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:32:26,548 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:32:26,548 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'und', 'ich', 'habe', 'eine', 'M@@', 'en@@', 'ge', 'S@@', 'ei@@', 'te', 'in', 'der', 'L@@', 'age', 'in', 'der', 'L@@', 'age', 'in', 'den', 'U@@', 'S@@', 'A', 'und', 'die', 'S@@', 'tra@@', '<unk>', 'e', 'zu', '<unk>', 'ber@@', 'w@@', 'ach@@', 'ung', 'und', 'die', 'S@@', 'tra@@', '<unk>', 'e', 'zu', '<unk>', 'ber@@', 'w@@', 'ach@@', 'ung', 'und', 'die', 'S@@', 'tra@@', '<unk>', 'e', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:32:26,548 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:32:26,548 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:32:26,548 - INFO - joeynmt.training - 	Hypothesis: Und ich habe ein paar Minuten und ich habe eine Menge Seite in der Lage in der Lage in den USA und die Stra<unk> e zu <unk> berwachung und die Stra<unk> e zu <unk> berwachung und die Stra<unk> e zu erreichen.
2025-05-29 19:32:26,548 - INFO - joeynmt.training - Example #1
2025-05-29 19:32:26,549 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:32:26,549 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:32:26,549 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'eine', 'Art', 'Art', 'von', 'S@@', 'ach@@', 'en,', 'die', 'ich', 'nicht', 'nur', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'und', 'die', 'S@@', 'tra@@', '<unk>', 'e', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'und', 'ich', 'war', 'nicht', 'nur', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'und', 'die', 'S@@', 'tra@@', '<unk>', 'e', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'die', 'wir', 'nicht', 'nur', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'und', 'die', 'S@@', 'tra@@', '<unk>', 'e', 'zu', 'ver@@', 'w@@', 'end@@', 'en.', '</s>']
2025-05-29 19:32:26,549 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:32:26,549 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:32:26,549 - INFO - joeynmt.training - 	Hypothesis: Und ich habe eine Art Art von Sachen, die ich nicht nur ein paar Minuten und die Stra<unk> e zu verwenden, und ich war nicht nur ein paar Minuten und die Stra<unk> e zu verwenden, die wir nicht nur ein paar Minuten und die Stra<unk> e zu verwenden.
2025-05-29 19:32:26,549 - INFO - joeynmt.training - Example #2
2025-05-29 19:32:26,549 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:32:26,549 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:32:26,549 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'eine', 'M@@', 'en@@', 'ge', 'S@@', 'ei@@', 'te', 'in', 'der', 'L@@', 'age', 'in', 'der', 'L@@', 'age', 'in', 'der', 'L@@', 'age', 'in', 'der', 'L@@', 'age', 'in', 'der', 'L@@', 'age', 'in', 'der', 'L@@', 'age', 'in', 'der', 'L@@', 'age', 'in', 'der', 'L@@', 'age', 'in', 'der', 'L@@', 'age', 'in', 'der', 'L@@', 'age', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:32:26,549 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:32:26,549 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:32:26,549 - INFO - joeynmt.training - 	Hypothesis: Und ich habe eine Menge Seite in der Lage in der Lage in der Lage in der Lage in der Lage in der Lage in der Lage in der Lage in der Lage in der Lage zu ver<unk> ndern.
2025-05-29 19:32:26,549 - INFO - joeynmt.training - Example #3
2025-05-29 19:32:26,549 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:32:26,549 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:32:26,550 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'm@@', '<unk>', 'chte', 'Ihnen', 'ein', 'paar', 'Bei@@', 'spiel@@', 'e', 'von', 'einem', 'K@@', 'op@@', 'f', 'in', 'der', 'L@@', 'age', 'in', 'der', 'L@@', 'age', 'in', 'der', 'L@@', 'age', 'zu', 'er@@', 'for@@', 'sch@@', 'en.', '</s>']
2025-05-29 19:32:26,550 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:32:26,550 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:32:26,550 - INFO - joeynmt.training - 	Hypothesis: Und ich m<unk> chte Ihnen ein paar Beispiele von einem Kopf in der Lage in der Lage in der Lage zu erforschen.
2025-05-29 19:32:26,550 - INFO - joeynmt.training - Example #4
2025-05-29 19:32:26,550 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:32:26,550 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:32:26,550 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'eine', 'S@@', 'ache', 'ist,', 'dass', 'ich', 'in', 'der', 'L@@', 'age', 'in', 'den', 'U@@', 'S@@', 'A', 'und', 'die', 'S@@', 'tra@@', '<unk>', 'e', 'zu', 'ver@@', 'w@@', 'end@@', 'en.', '</s>']
2025-05-29 19:32:26,550 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:32:26,550 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:32:26,550 - INFO - joeynmt.training - 	Hypothesis: Und ich habe eine Sache ist, dass ich in der Lage in den USA und die Stra<unk> e zu verwenden.
2025-05-29 19:32:28,794 - INFO - joeynmt.training - Epoch   4, Step:    19100, Batch Loss:     2.257068, Batch Acc: 0.291519, Tokens per Sec:    30751, Lr: 0.000300
2025-05-29 19:32:30,957 - INFO - joeynmt.training - Epoch   4, Step:    19200, Batch Loss:     2.368700, Batch Acc: 0.294452, Tokens per Sec:    32576, Lr: 0.000300
2025-05-29 19:32:34,168 - INFO - joeynmt.training - Epoch   4, Step:    19300, Batch Loss:     2.338087, Batch Acc: 0.292272, Tokens per Sec:    21663, Lr: 0.000300
2025-05-29 19:32:36,278 - INFO - joeynmt.training - Epoch   4, Step:    19400, Batch Loss:     2.212386, Batch Acc: 0.294840, Tokens per Sec:    33381, Lr: 0.000300
2025-05-29 19:32:38,656 - INFO - joeynmt.training - Epoch   4, Step:    19500, Batch Loss:     2.269473, Batch Acc: 0.294997, Tokens per Sec:    29050, Lr: 0.000300
2025-05-29 19:32:38,657 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:32:38,657 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:32:50,417 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.32, ppl:  10.17, acc:   0.30, generation: 11.7500[sec], evaluation: 0.0000[sec]
2025-05-29 19:32:50,418 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:32:50,498 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/17000.ckpt
2025-05-29 19:32:50,504 - INFO - joeynmt.training - Example #0
2025-05-29 19:32:50,504 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:32:50,504 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:32:50,504 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'Ihnen', 'ein', 'paar', 'Bei@@', 'spiel@@', 'e', 'von', '1@@', '0@@', '0@@', '0@@', '.000', 'D@@', 'oll@@', 'ar', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:32:50,505 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:32:50,505 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:32:50,505 - INFO - joeynmt.training - 	Hypothesis: Und ich habe Ihnen ein paar Beispiele von 1000.000 Dollar zu ver<unk> ndern.
2025-05-29 19:32:50,505 - INFO - joeynmt.training - Example #1
2025-05-29 19:32:50,505 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:32:50,505 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:32:50,505 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'ein', 'sehr', 'wichtig@@', 'er', 'K@@', '<unk>', 'r@@', 'z@@', 'lich', 'f@@', '<unk>', 'r', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:32:50,505 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:32:50,505 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:32:50,505 - INFO - joeynmt.training - 	Hypothesis: Und das ist ein sehr wichtiger K<unk> rzlich f<unk> r die M<unk> glichkeiten zu ver<unk> ndern.
2025-05-29 19:32:50,505 - INFO - joeynmt.training - Example #2
2025-05-29 19:32:50,505 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:32:50,505 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:32:50,505 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'ein', 'sehr', 'wichtig@@', 'er', 'K@@', '<unk>', 'r@@', 'z@@', 'lich', 'der', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'die', 'ich', 'in', 'einem', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'die', 'ich', 'in', 'der', 'Welt', 'zu', '<unk>', 'ber@@', 'zeu@@', 'g@@', 'en,', 'die', 'wir', 'in', 'der', 'Welt', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:32:50,505 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:32:50,506 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:32:50,506 - INFO - joeynmt.training - 	Hypothesis: Und das ist ein sehr wichtiger K<unk> rzlich der K<unk> rper, die ich in einem K<unk> rper, die ich in der Welt zu <unk> berzeugen, die wir in der Welt zu ver<unk> ndern.
2025-05-29 19:32:50,506 - INFO - joeynmt.training - Example #3
2025-05-29 19:32:50,506 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:32:50,506 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:32:50,506 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'ein', 'sehr', 'wichtig@@', 'er', 'K@@', '<unk>', 'r@@', 'z@@', 'lich', 'und', 'ich', 'habe', 'ein', 'paar', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:32:50,506 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:32:50,506 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:32:50,506 - INFO - joeynmt.training - 	Hypothesis: Und das ist ein sehr wichtiger K<unk> rzlich und ich habe ein paar M<unk> glichkeiten zu ver<unk> ndern.
2025-05-29 19:32:50,506 - INFO - joeynmt.training - Example #4
2025-05-29 19:32:50,506 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:32:50,506 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:32:50,506 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'und', 'ich', 'habe', 'ein', 'paar', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'zu', '<unk>', 'ber@@', 'zeu@@', 'g@@', 'en,', 'die', 'ich', 'Ihnen', 'ein', 'paar', 'Bei@@', 'spiel@@', 'e', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:32:50,506 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:32:50,506 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:32:50,506 - INFO - joeynmt.training - 	Hypothesis: Und ich habe ein paar Minuten und ich habe ein paar M<unk> glichkeiten zu <unk> berzeugen, die ich Ihnen ein paar Beispiele zu ver<unk> ndern.
2025-05-29 19:32:52,817 - INFO - joeynmt.training - Epoch   4, Step:    19600, Batch Loss:     2.278886, Batch Acc: 0.291017, Tokens per Sec:    29682, Lr: 0.000300
2025-05-29 19:32:54,962 - INFO - joeynmt.training - Epoch   4, Step:    19700, Batch Loss:     2.263975, Batch Acc: 0.293850, Tokens per Sec:    33018, Lr: 0.000300
2025-05-29 19:32:57,198 - INFO - joeynmt.training - Epoch   4, Step:    19800, Batch Loss:     2.267935, Batch Acc: 0.295045, Tokens per Sec:    31406, Lr: 0.000300
2025-05-29 19:32:59,370 - INFO - joeynmt.training - Epoch   4, Step:    19900, Batch Loss:     2.252800, Batch Acc: 0.294598, Tokens per Sec:    33297, Lr: 0.000300
2025-05-29 19:33:01,677 - INFO - joeynmt.training - Epoch   4, Step:    20000, Batch Loss:     2.337050, Batch Acc: 0.293452, Tokens per Sec:    29756, Lr: 0.000300
2025-05-29 19:33:01,677 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:33:01,677 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:33:07,846 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.32, ppl:  10.13, acc:   0.30, generation: 6.1625[sec], evaluation: 0.0000[sec]
2025-05-29 19:33:07,846 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:33:07,935 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/17500.ckpt
2025-05-29 19:33:07,942 - INFO - joeynmt.training - Example #0
2025-05-29 19:33:07,942 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:33:07,942 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:33:07,942 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'm@@', '<unk>', 'chte', 'Ihnen', 'ein', 'paar', 'Bei@@', 'spiel@@', 'e', 'von', '1@@', '0@@', '0@@', '.000', 'D@@', 'oll@@', 'ar', 'f@@', '<unk>', 'r', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'zu', '<unk>', 'ber@@', 'w@@', '<unk>', 'h@@', 'l@@', 'en,', 'um', 'die', 'Welt', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:33:07,942 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:33:07,942 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:33:07,942 - INFO - joeynmt.training - 	Hypothesis: Ich m<unk> chte Ihnen ein paar Beispiele von 100.000 Dollar f<unk> r die M<unk> glichkeiten zu <unk> berw<unk> hlen, um die Welt zu erreichen.
2025-05-29 19:33:07,943 - INFO - joeynmt.training - Example #1
2025-05-29 19:33:07,943 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:33:07,943 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:33:07,943 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'm@@', '<unk>', 'chte', 'Ihnen', 'ein', 'paar', 'Bei@@', 'spiel@@', 'e', 'von', 'der', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:33:07,943 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:33:07,943 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:33:07,943 - INFO - joeynmt.training - 	Hypothesis: Ich m<unk> chte Ihnen ein paar Beispiele von der M<unk> glichkeiten zu ver<unk> ndern.
2025-05-29 19:33:07,943 - INFO - joeynmt.training - Example #2
2025-05-29 19:33:07,943 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:33:07,943 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:33:07,943 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'ein', 'M@@', 'e@@', 'er@@', 'es@@', 'p@@', 'ek@@', 't', 'von', 'der', 'M@@', '<unk>', 'glich@@', 'kei@@', 't.', '</s>']
2025-05-29 19:33:07,943 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:33:07,943 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:33:07,943 - INFO - joeynmt.training - 	Hypothesis: Und das ist ein Meerespekt von der M<unk> glichkeit.
2025-05-29 19:33:07,943 - INFO - joeynmt.training - Example #3
2025-05-29 19:33:07,943 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:33:07,943 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:33:07,943 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'm@@', '<unk>', 'chte', 'Ihnen', 'ein', 'paar', 'Bei@@', 'spiel@@', 'e', 'von', 'der', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:33:07,944 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:33:07,944 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:33:07,944 - INFO - joeynmt.training - 	Hypothesis: Ich m<unk> chte Ihnen ein paar Beispiele von der M<unk> glichkeiten und die M<unk> glichkeiten zu ver<unk> ndern.
2025-05-29 19:33:07,944 - INFO - joeynmt.training - Example #4
2025-05-29 19:33:07,944 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:33:07,944 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:33:07,944 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'm@@', '<unk>', 'chte', 'Ihnen', 'ein', 'paar', 'Bei@@', 'spiel@@', 'e', 'von', 'der', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:33:07,944 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:33:07,944 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:33:07,944 - INFO - joeynmt.training - 	Hypothesis: Ich m<unk> chte Ihnen ein paar Beispiele von der M<unk> glichkeiten zu ver<unk> ndern.
2025-05-29 19:33:10,246 - INFO - joeynmt.training - Epoch   4, Step:    20100, Batch Loss:     2.330680, Batch Acc: 0.295439, Tokens per Sec:    29599, Lr: 0.000300
2025-05-29 19:33:12,470 - INFO - joeynmt.training - Epoch   4, Step:    20200, Batch Loss:     2.379565, Batch Acc: 0.291208, Tokens per Sec:    32093, Lr: 0.000300
2025-05-29 19:33:14,668 - INFO - joeynmt.training - Epoch   4, Step:    20300, Batch Loss:     2.367491, Batch Acc: 0.292017, Tokens per Sec:    31757, Lr: 0.000300
2025-05-29 19:33:17,026 - INFO - joeynmt.training - Epoch   4, Step:    20400, Batch Loss:     2.254472, Batch Acc: 0.294603, Tokens per Sec:    29045, Lr: 0.000300
2025-05-29 19:33:19,347 - INFO - joeynmt.training - Epoch   4, Step:    20500, Batch Loss:     2.421608, Batch Acc: 0.294455, Tokens per Sec:    31196, Lr: 0.000300
2025-05-29 19:33:19,347 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:33:19,347 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:33:27,394 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.31, ppl:  10.09, acc:   0.30, generation: 8.0406[sec], evaluation: 0.0000[sec]
2025-05-29 19:33:27,394 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:33:27,482 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/18000.ckpt
2025-05-29 19:33:27,488 - INFO - joeynmt.training - Example #0
2025-05-29 19:33:27,488 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:33:27,488 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:33:27,488 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'Ihnen', 'ein', 'paar', 'Bei@@', 'spiel@@', 'e', 'von', 'einem', 'F@@', 'lu@@', 'g@@', 'zeu@@', 'g@@', ',', 'und', 'ich', 'm@@', '<unk>', 'chte', 'Ihnen', 'zeig@@', 'en,', 'dass', 'ich', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'zu', 'er@@', 'm@@', '<unk>', 'glich@@', 'en,', 'um', 'die', 'er@@', 'sten', 'M@@', 'al', 'in', 'der', 'L@@', 'age', 'f@@', '<unk>', 'r', 'die', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'die', 'wir', 'in', 'der', 'Welt', 'ver@@', '<unk>', 'n@@', 'der@@', 'n', 'k@@', '<unk>', 'n@@', 'n@@', 'en.', '</s>']
2025-05-29 19:33:27,489 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:33:27,489 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:33:27,489 - INFO - joeynmt.training - 	Hypothesis: Und ich habe Ihnen ein paar Beispiele von einem Flugzeug, und ich m<unk> chte Ihnen zeigen, dass ich die M<unk> glichkeiten zu erm<unk> glichen, um die ersten Mal in der Lage f<unk> r die K<unk> rper, die wir in der Welt ver<unk> ndern k<unk> nnen.
2025-05-29 19:33:27,489 - INFO - joeynmt.training - Example #1
2025-05-29 19:33:27,489 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:33:27,489 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:33:27,489 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'nicht', 'der', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'die', 'wir', 'nicht', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 't,', 'die', 'wir', 'nicht', 'nicht', 'nur', 'die', 'K@@', '<unk>', 'r@@', 'per@@', '.', '</s>']
2025-05-29 19:33:27,489 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:33:27,489 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:33:27,489 - INFO - joeynmt.training - 	Hypothesis: Und das ist nicht der K<unk> rper, die wir nicht die M<unk> glichkeit, die wir nicht nicht nur die K<unk> rper.
2025-05-29 19:33:27,489 - INFO - joeynmt.training - Example #2
2025-05-29 19:33:27,489 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:33:27,489 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:33:27,489 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'ein', 'M@@', 'om@@', 'ent', 'der', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'die', 'wir', 'in', 'der', 'L@@', 'age', 'in', 'der', 'L@@', 'age', 'in', 'der', 'Welt', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per@@', '.', '</s>']
2025-05-29 19:33:27,490 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:33:27,490 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:33:27,490 - INFO - joeynmt.training - 	Hypothesis: Und das ist ein Moment der K<unk> rper, die wir in der Lage in der Lage in der Welt zu ver<unk> ndern und die K<unk> rper.
2025-05-29 19:33:27,490 - INFO - joeynmt.training - Example #3
2025-05-29 19:33:27,490 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:33:27,490 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:33:27,490 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'ein', 'F@@', 'o@@', 'to', 'von', 'der', 'K@@', '<unk>', 'r@@', 'per@@', '.', '</s>']
2025-05-29 19:33:27,490 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:33:27,490 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:33:27,490 - INFO - joeynmt.training - 	Hypothesis: Es ist ein Foto von der K<unk> rper.
2025-05-29 19:33:27,490 - INFO - joeynmt.training - Example #4
2025-05-29 19:33:27,490 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:33:27,490 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:33:27,490 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Das', 'ist', 'ein', 'M@@', 'ann', 'ist', 'das', 'eine', 'M@@', 'en@@', 'ge', 'von', 'S@@', '<unk>', 'd@@', 'k@@', 'el@@', '.', '</s>']
2025-05-29 19:33:27,491 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:33:27,491 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:33:27,491 - INFO - joeynmt.training - 	Hypothesis: Das ist ein Mann ist das eine Menge von S<unk> dkel.
2025-05-29 19:33:29,891 - INFO - joeynmt.training - Epoch   4, Step:    20600, Batch Loss:     2.362223, Batch Acc: 0.294250, Tokens per Sec:    27848, Lr: 0.000300
2025-05-29 19:33:32,156 - INFO - joeynmt.training - Epoch   4, Step:    20700, Batch Loss:     2.408527, Batch Acc: 0.296523, Tokens per Sec:    31709, Lr: 0.000300
2025-05-29 19:33:34,432 - INFO - joeynmt.training - Epoch   4, Step:    20800, Batch Loss:     2.419192, Batch Acc: 0.294557, Tokens per Sec:    31140, Lr: 0.000300
2025-05-29 19:33:36,919 - INFO - joeynmt.training - Epoch   4, Step:    20900, Batch Loss:     2.377411, Batch Acc: 0.294940, Tokens per Sec:    28390, Lr: 0.000300
2025-05-29 19:33:40,201 - INFO - joeynmt.training - Epoch   4, Step:    21000, Batch Loss:     2.391231, Batch Acc: 0.297467, Tokens per Sec:    20799, Lr: 0.000300
2025-05-29 19:33:40,202 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:33:40,202 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:33:47,837 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.31, ppl:  10.08, acc:   0.30, generation: 7.6288[sec], evaluation: 0.0000[sec]
2025-05-29 19:33:47,838 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:33:47,919 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/18500.ckpt
2025-05-29 19:33:47,925 - INFO - joeynmt.training - Example #0
2025-05-29 19:33:47,925 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:33:47,925 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:33:47,925 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'und', 'ich', 'habe', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:33:47,925 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:33:47,925 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:33:47,925 - INFO - joeynmt.training - 	Hypothesis: Und ich habe ein paar Minuten und ich habe ein paar Minuten und die K<unk> rper zu ver<unk> ndern.
2025-05-29 19:33:47,925 - INFO - joeynmt.training - Example #1
2025-05-29 19:33:47,926 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:33:47,926 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:33:47,926 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'ein', 'M@@', 'ann', 'ist', 'ein', 'M@@', 'ann', 'der', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:33:47,926 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:33:47,926 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:33:47,926 - INFO - joeynmt.training - 	Hypothesis: Und das ist ein Mann ist ein Mann der K<unk> rper und die K<unk> rper zu ver<unk> ndern.
2025-05-29 19:33:47,926 - INFO - joeynmt.training - Example #2
2025-05-29 19:33:47,926 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:33:47,926 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:33:47,926 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'ein', 'M@@', 'ann', 'in', 'der', 'L@@', 'u@@', 'ft@@', 'w@@', 'are', 'und', 'ich', 'bin', 'ein', 'M@@', 'ann', 'in', 'der', 'L@@', 'age', 'in', 'der', 'L@@', 'u@@', 'ft@@', 'w@@', 'are', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:33:47,926 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:33:47,926 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:33:47,926 - INFO - joeynmt.training - 	Hypothesis: Und ich habe ein Mann in der Luftware und ich bin ein Mann in der Lage in der Luftware und die K<unk> rper zu ver<unk> ndern.
2025-05-29 19:33:47,926 - INFO - joeynmt.training - Example #3
2025-05-29 19:33:47,926 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:33:47,927 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:33:47,927 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'm@@', '<unk>', 'chte', 'Ihnen', 'ein', 'paar', 'Bei@@', 'spiel@@', 'e', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:33:47,927 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:33:47,927 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:33:47,927 - INFO - joeynmt.training - 	Hypothesis: Und ich m<unk> chte Ihnen ein paar Beispiele zu ver<unk> ndern.
2025-05-29 19:33:47,927 - INFO - joeynmt.training - Example #4
2025-05-29 19:33:47,927 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:33:47,927 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:33:47,927 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'm@@', '<unk>', 'chte', 'Ihnen', 'ein', 'paar', 'Bei@@', 'spiel@@', 'e', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:33:47,927 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:33:47,927 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:33:47,927 - INFO - joeynmt.training - 	Hypothesis: Und ich m<unk> chte Ihnen ein paar Beispiele zu ver<unk> ndern.
2025-05-29 19:33:50,167 - INFO - joeynmt.training - Epoch   4, Step:    21100, Batch Loss:     2.221328, Batch Acc: 0.293289, Tokens per Sec:    31033, Lr: 0.000300
2025-05-29 19:33:52,368 - INFO - joeynmt.training - Epoch   4, Step:    21200, Batch Loss:     2.220296, Batch Acc: 0.299788, Tokens per Sec:    32206, Lr: 0.000300
2025-05-29 19:33:54,494 - INFO - joeynmt.training - Epoch   4, Step:    21300, Batch Loss:     2.139019, Batch Acc: 0.295531, Tokens per Sec:    33276, Lr: 0.000300
2025-05-29 19:33:56,519 - INFO - joeynmt.training - Epoch   4: total training loss 12395.53
2025-05-29 19:33:56,520 - INFO - joeynmt.training - EPOCH 5
2025-05-29 19:33:56,829 - INFO - joeynmt.training - Epoch   5, Step:    21400, Batch Loss:     2.380457, Batch Acc: 0.304766, Tokens per Sec:    29581, Lr: 0.000300
2025-05-29 19:33:59,049 - INFO - joeynmt.training - Epoch   5, Step:    21500, Batch Loss:     2.252801, Batch Acc: 0.299779, Tokens per Sec:    32374, Lr: 0.000300
2025-05-29 19:33:59,049 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:33:59,049 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:34:14,967 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.30, ppl:  10.01, acc:   0.30, generation: 15.9049[sec], evaluation: 0.0000[sec]
2025-05-29 19:34:14,968 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:34:15,050 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/19000.ckpt
2025-05-29 19:34:15,056 - INFO - joeynmt.training - Example #0
2025-05-29 19:34:15,056 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:34:15,056 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:34:15,056 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'Ihnen', 'eine', 'Art', 'Art', 'von', 'D@@', 'aten', 'und', 'Wei@@', 'se', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n,', 'dass', 'sie', 'in', 'den', 'letz@@', 'ten', '1@@', '0@@', '0@@', 'ern', 'und', '1@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', ',', 'das', 'ist', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'zu', 'er@@', 'halt@@', 'en,', 'und', 'sie', 'haben', 'die', 'K@@', 'rank@@', 'heit', 'der', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'zu', 'ver@@', 'st@@', '<unk>', 'n@@', 'd@@', 'lich', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'um', 'die', '<unk>', 'ff@@', 'ent@@', 'lich@@', 'er', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:34:15,056 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:34:15,056 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:34:15,056 - INFO - joeynmt.training - 	Hypothesis: Und ich habe Ihnen eine Art Art von Daten und Weise zu ver<unk> ndern, dass sie in den letzten 100ern und 100000000000000, das ist ein paar Minuten und die M<unk> glichkeiten zu erhalten, und sie haben die Krankheit der K<unk> rper und die M<unk> glichkeiten zu verst<unk> ndlich zu verwenden, um die <unk> ffentlicher zu ver<unk> ndern.
2025-05-29 19:34:15,056 - INFO - joeynmt.training - Example #1
2025-05-29 19:34:15,056 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:34:15,056 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:34:15,056 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'nicht', 'nur', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 't,', 'die', 'wir', 'nicht', 'in', 'den', 'U@@', 'S@@', 'A', 'und', 'der', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:34:15,057 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:34:15,057 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:34:15,057 - INFO - joeynmt.training - 	Hypothesis: Und das ist nicht nur ein paar Minuten und die M<unk> glichkeit, die wir nicht in den USA und der K<unk> rper zu ver<unk> ndern.
2025-05-29 19:34:15,057 - INFO - joeynmt.training - Example #2
2025-05-29 19:34:15,057 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:34:15,057 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:34:15,057 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 't,', 'die', 'wir', 'in', 'der', 'L@@', 'age', 'in', 'der', 'L@@', 'age', 'in', 'den', 'letz@@', 'ten', 'Jahr@@', 'h@@', 'under@@', 't', 'und', 'der', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:34:15,057 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:34:15,057 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:34:15,057 - INFO - joeynmt.training - 	Hypothesis: Und das ist ein paar Minuten und die M<unk> glichkeit, die wir in der Lage in der Lage in den letzten Jahrhundert und der K<unk> rper zu ver<unk> ndern und die K<unk> rper zu ver<unk> ndern.
2025-05-29 19:34:15,057 - INFO - joeynmt.training - Example #3
2025-05-29 19:34:15,057 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:34:15,057 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:34:15,057 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Das', 'ist', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'zu', 'den', 'B@@', 'eg@@', 'in@@', 'n', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'zu', 'ver@@', 'w@@', 'end@@', 'en.', '</s>']
2025-05-29 19:34:15,057 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:34:15,058 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:34:15,058 - INFO - joeynmt.training - 	Hypothesis: Das ist ein paar Minuten und die M<unk> glichkeiten und die K<unk> rper und die K<unk> rper und die M<unk> glichkeiten zu den Beginn und die K<unk> rper und die K<unk> rper und die K<unk> rper und die K<unk> rper und die M<unk> glichkeiten und die M<unk> glichkeiten zu verwenden.
2025-05-29 19:34:15,058 - INFO - joeynmt.training - Example #4
2025-05-29 19:34:15,058 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:34:15,058 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:34:15,058 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'und', 'ich', 'habe', 'eine', 'M@@', 'en@@', 'ge', 'S@@', 'ei@@', 'te', 'der', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'zu', 'den', 'B@@', '<unk>', 'r@@', 'ger@@', 'n', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n,', 'und', 'sie', 'k@@', '<unk>', 'n@@', 'n@@', 'en.', '</s>']
2025-05-29 19:34:15,058 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:34:15,058 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:34:15,058 - INFO - joeynmt.training - 	Hypothesis: Und das ist ein paar Minuten und ich habe eine Menge Seite der K<unk> rper und die M<unk> glichkeiten zu den B<unk> rgern und die K<unk> rper zu ver<unk> ndern, und sie k<unk> nnen.
2025-05-29 19:34:17,499 - INFO - joeynmt.training - Epoch   5, Step:    21600, Batch Loss:     2.335939, Batch Acc: 0.303697, Tokens per Sec:    27980, Lr: 0.000300
2025-05-29 19:34:19,875 - INFO - joeynmt.training - Epoch   5, Step:    21700, Batch Loss:     2.301948, Batch Acc: 0.300419, Tokens per Sec:    29266, Lr: 0.000300
2025-05-29 19:34:22,178 - INFO - joeynmt.training - Epoch   5, Step:    21800, Batch Loss:     2.255806, Batch Acc: 0.302658, Tokens per Sec:    29940, Lr: 0.000300
2025-05-29 19:34:24,454 - INFO - joeynmt.training - Epoch   5, Step:    21900, Batch Loss:     2.441616, Batch Acc: 0.299062, Tokens per Sec:    30448, Lr: 0.000300
2025-05-29 19:34:26,673 - INFO - joeynmt.training - Epoch   5, Step:    22000, Batch Loss:     2.349982, Batch Acc: 0.301715, Tokens per Sec:    31667, Lr: 0.000300
2025-05-29 19:34:26,674 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:34:26,674 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:34:41,106 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.30, ppl:   9.98, acc:   0.31, generation: 14.4237[sec], evaluation: 0.0000[sec]
2025-05-29 19:34:41,106 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:34:41,194 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/19500.ckpt
2025-05-29 19:34:41,200 - INFO - joeynmt.training - Example #0
2025-05-29 19:34:41,201 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:34:41,201 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:34:41,201 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Wir', 'haben', 'eine', 'M@@', 'en@@', 'ge', 'M@@', '<unk>', 'glich@@', 'kei@@', 't,', 'die', 'wir', 'in', 'der', 'L@@', 'age', 'in', 'der', 'L@@', 'age', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'um', 'die', 'Welt', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:34:41,201 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:34:41,201 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:34:41,201 - INFO - joeynmt.training - 	Hypothesis: Wir haben eine Menge M<unk> glichkeit, die wir in der Lage in der Lage zu verwenden, um die Welt zu erreichen.
2025-05-29 19:34:41,201 - INFO - joeynmt.training - Example #1
2025-05-29 19:34:41,201 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:34:41,201 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:34:41,201 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'und', 'ich', 'habe', 'mich', 'nicht', 'ge@@', 'zeig@@', 't', 'hab@@', 'e,', 'dass', 'ich', 'nicht', 'nur', 'die', 'K@@', '<unk>', 'r@@', 'per@@', '.', '</s>']
2025-05-29 19:34:41,201 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:34:41,201 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:34:41,201 - INFO - joeynmt.training - 	Hypothesis: Und ich habe ein paar Minuten und ich habe mich nicht gezeigt habe, dass ich nicht nur die K<unk> rper.
2025-05-29 19:34:41,201 - INFO - joeynmt.training - Example #2
2025-05-29 19:34:41,202 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:34:41,202 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:34:41,202 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Das', 'ist', 'ein', 'M@@', 'ann', 'ist', 'das', 'eine', 'M@@', 'en@@', 'ge', 'S@@', 'ach@@', 'e,', 'die', 'ich', 'in', 'der', 'L@@', 'age', 'in', 'der', 'L@@', 'age', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'und', 'ich', 'habe', 'mich', 'ge@@', 'zeig@@', 't,', 'dass', 'es', 'eine', 'M@@', 'en@@', 'ge', 'S@@', 'ach@@', 'e,', 'die', 'wir', 'in', 'der', 'Welt', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:34:41,202 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:34:41,202 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:34:41,202 - INFO - joeynmt.training - 	Hypothesis: Das ist ein Mann ist das eine Menge Sache, die ich in der Lage in der Lage zu verwenden, und ich habe mich gezeigt, dass es eine Menge Sache, die wir in der Welt zu ver<unk> ndern.
2025-05-29 19:34:41,202 - INFO - joeynmt.training - Example #3
2025-05-29 19:34:41,202 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:34:41,202 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:34:41,202 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Sie', 'haben', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'sie', 'in', 'den', 'U@@', 'S@@', 'A', 'und', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'sie', 'k@@', '<unk>', 'n@@', 'n@@', 'te', 'es', 'sich', 'in', 'der', 'L@@', 'age', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'und', 'sie', 'k@@', '<unk>', 'n@@', 'n@@', 'ten', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per@@', '.', '</s>']
2025-05-29 19:34:41,202 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:34:41,202 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:34:41,202 - INFO - joeynmt.training - 	Hypothesis: Sie haben die M<unk> nnern und sie in den USA und und die M<unk> nnern und sie k<unk> nnte es sich in der Lage zu verwenden, und sie k<unk> nnten und die K<unk> rper.
2025-05-29 19:34:41,202 - INFO - joeynmt.training - Example #4
2025-05-29 19:34:41,202 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:34:41,202 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:34:41,202 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Das', 'ist', 'ein', 'M@@', 'ann', 'm@@', '<unk>', 'ss@@', 'en', 'wir', 'uns', 'in', 'die', 'L@@', 'age', 'der', 'Welt', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:34:41,202 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:34:41,203 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:34:41,203 - INFO - joeynmt.training - 	Hypothesis: Das ist ein Mann m<unk> ssen wir uns in die Lage der Welt zu ver<unk> ndern.
2025-05-29 19:34:43,402 - INFO - joeynmt.training - Epoch   5, Step:    22100, Batch Loss:     2.302114, Batch Acc: 0.302254, Tokens per Sec:    30987, Lr: 0.000300
2025-05-29 19:34:46,646 - INFO - joeynmt.training - Epoch   5, Step:    22200, Batch Loss:     2.375616, Batch Acc: 0.297791, Tokens per Sec:    21721, Lr: 0.000300
2025-05-29 19:34:48,581 - INFO - joeynmt.training - Epoch   5, Step:    22300, Batch Loss:     2.263456, Batch Acc: 0.300127, Tokens per Sec:    36736, Lr: 0.000300
2025-05-29 19:34:50,763 - INFO - joeynmt.training - Epoch   5, Step:    22400, Batch Loss:     2.227346, Batch Acc: 0.300308, Tokens per Sec:    32192, Lr: 0.000300
2025-05-29 19:34:52,891 - INFO - joeynmt.training - Epoch   5, Step:    22500, Batch Loss:     2.399495, Batch Acc: 0.300701, Tokens per Sec:    32927, Lr: 0.000300
2025-05-29 19:34:52,891 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:34:52,891 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:35:08,465 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.30, ppl:   9.95, acc:   0.30, generation: 15.5572[sec], evaluation: 0.0000[sec]
2025-05-29 19:35:08,465 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:35:08,548 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/20000.ckpt
2025-05-29 19:35:08,555 - INFO - joeynmt.training - Example #0
2025-05-29 19:35:08,555 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:35:08,555 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:35:08,555 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'Ihnen', 'ein', 'paar', 'Bei@@', 'spiel@@', 'e', 'von', 'einem', 'M@@', 'om@@', 'ent', 'der', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'die', 'wir', 'uns', 'in', 'der', 'Welt', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:35:08,555 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:35:08,555 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:35:08,555 - INFO - joeynmt.training - 	Hypothesis: Ich habe Ihnen ein paar Beispiele von einem Moment der M<unk> glichkeit der M<unk> glichkeit der K<unk> rper, die wir uns in der Welt zu erreichen.
2025-05-29 19:35:08,555 - INFO - joeynmt.training - Example #1
2025-05-29 19:35:08,555 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:35:08,555 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:35:08,556 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'denk@@', 'e,', 'dass', 'ich', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'M@@', 'itt@@', 'el@@', 'schi@@', 'en', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'M@@', 'itt@@', 'el@@', 'schi@@', 'en', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'M@@', 'itt@@', 'el@@', 'pun@@']
2025-05-29 19:35:08,556 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:35:08,556 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:35:08,556 - INFO - joeynmt.training - 	Hypothesis: Und ich denke, dass ich die M<unk> glichkeit der M<unk> glichkeit der M<unk> glichkeit der M<unk> glichkeit der M<unk> glichkeit der M<unk> glichkeit der M<unk> glichkeit der M<unk> glichkeit der Mittelschien und die M<unk> glichkeit der M<unk> glichkeit der Mittelschien und die M<unk> glichkeit der M<unk> nner und die M<unk> glichkeit der M<unk> glichkeit der M<unk> glichkeit der M<unk> nner und die M<unk> glichkeit der Mittelpun
2025-05-29 19:35:08,556 - INFO - joeynmt.training - Example #2
2025-05-29 19:35:08,556 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:35:08,556 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:35:08,556 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'denk@@', 'e,', 'dass', 'ich', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'die', 'wir', 'uns', 'in', 'der', 'Welt', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:35:08,556 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:35:08,556 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:35:08,556 - INFO - joeynmt.training - 	Hypothesis: Und ich denke, dass ich die M<unk> glichkeit der M<unk> glichkeit der M<unk> glichkeit der M<unk> glichkeit der M<unk> glichkeit der M<unk> glichkeit der M<unk> glichkeit der K<unk> rper, die wir uns in der Welt zu ver<unk> ndern.
2025-05-29 19:35:08,556 - INFO - joeynmt.training - Example #3
2025-05-29 19:35:08,556 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:35:08,556 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:35:08,556 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'M@@', 'itt@@', 'el@@', 'schi@@', 'en', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'die', 'wir', 'uns', 'er@@', 'laub@@', 'en,', 'die', 'wir', 'uns', 'er@@', 'laub@@', 'en,', 'die', 'wir', 'uns', 'in', 'der', 'Welt', 'ver@@', '<unk>', 'n@@', 'der@@', 'n', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'die', 'wir', 'uns', 'ver@@', '<unk>', 'n@@', 'der@@', 'n', 'k@@', '<unk>', 'n@@', 'n@@', 'en.', '</s>']
2025-05-29 19:35:08,556 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:35:08,557 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:35:08,557 - INFO - joeynmt.training - 	Hypothesis: Es ist ein paar Minuten und die M<unk> glichkeit der M<unk> glichkeit der M<unk> glichkeit der Mittelschien und die M<unk> glichkeit der M<unk> glichkeit der K<unk> rper, die wir uns erlauben, die wir uns erlauben, die wir uns in der Welt ver<unk> ndern und die M<unk> glichkeit der M<unk> nner und die M<unk> glichkeit der K<unk> rper, die wir uns ver<unk> ndern k<unk> nnen.
2025-05-29 19:35:08,557 - INFO - joeynmt.training - Example #4
2025-05-29 19:35:08,557 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:35:08,557 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:35:08,557 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'denk@@', 'e,', 'dass', 'ich', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'M@@', 'itt@@', 'el@@', 'schi@@', 'en,', 'die', 'ich', 'in', 'der', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'M@@', '<unk>', 'glich@@', 'keit']
2025-05-29 19:35:08,557 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:35:08,557 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:35:08,557 - INFO - joeynmt.training - 	Hypothesis: Und ich denke, dass ich die M<unk> glichkeit der M<unk> glichkeit der M<unk> glichkeit der M<unk> glichkeit der M<unk> glichkeit der M<unk> glichkeit der M<unk> glichkeit der M<unk> glichkeit der M<unk> glichkeit der M<unk> glichkeit der M<unk> glichkeit der Mittelschien, die ich in der M<unk> nner und die M<unk> glichkeit der M<unk> glichkeit der M<unk> glichkeit der M<unk> glichkeit der M<unk> nner und die M<unk> glichkeit der M<unk> glichkeit
2025-05-29 19:35:10,888 - INFO - joeynmt.training - Epoch   5, Step:    22600, Batch Loss:     2.276236, Batch Acc: 0.301310, Tokens per Sec:    28946, Lr: 0.000300
2025-05-29 19:35:13,111 - INFO - joeynmt.training - Epoch   5, Step:    22700, Batch Loss:     2.300802, Batch Acc: 0.303985, Tokens per Sec:    31063, Lr: 0.000300
2025-05-29 19:35:15,052 - INFO - joeynmt.training - Epoch   5, Step:    22800, Batch Loss:     2.224948, Batch Acc: 0.300065, Tokens per Sec:    35516, Lr: 0.000300
2025-05-29 19:35:17,979 - INFO - joeynmt.training - Epoch   5, Step:    22900, Batch Loss:     2.148026, Batch Acc: 0.299184, Tokens per Sec:    24131, Lr: 0.000300
2025-05-29 19:35:20,316 - INFO - joeynmt.training - Epoch   5, Step:    23000, Batch Loss:     2.220022, Batch Acc: 0.302936, Tokens per Sec:    29893, Lr: 0.000300
2025-05-29 19:35:20,316 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:35:20,316 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:35:32,282 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.30, ppl:   9.95, acc:   0.30, generation: 11.9577[sec], evaluation: 0.0000[sec]
2025-05-29 19:35:32,283 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:35:32,363 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/20500.ckpt
2025-05-29 19:35:32,368 - INFO - joeynmt.training - Example #0
2025-05-29 19:35:32,368 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:35:32,368 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:35:32,369 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'und', 'ich', 'habe', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'und', 'ich', 'habe', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:35:32,369 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:35:32,369 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:35:32,369 - INFO - joeynmt.training - 	Hypothesis: Ich habe ein paar Minuten und ich habe ein paar Minuten und ich habe ein paar Minuten und die M<unk> glichkeiten zu erreichen.
2025-05-29 19:35:32,369 - INFO - joeynmt.training - Example #1
2025-05-29 19:35:32,369 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:35:32,369 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:35:32,369 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'ein', 'g@@', 'ro@@', '<unk>', 'es', 'Bei@@', 'spi@@', 'el', 'der', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:35:32,369 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:35:32,369 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:35:32,369 - INFO - joeynmt.training - 	Hypothesis: Und das ist ein gro<unk> es Beispiel der K<unk> rper und die M<unk> glichkeiten und die M<unk> glichkeiten zu ver<unk> ndern.
2025-05-29 19:35:32,369 - INFO - joeynmt.training - Example #2
2025-05-29 19:35:32,369 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:35:32,369 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:35:32,369 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'ein', 'g@@', 'ro@@', '<unk>', 'es', 'Bei@@', 'spi@@', 'el', 'von', 'der', 'N@@', 'at@@', 'ur', 'in', 'der', 'L@@', 'age', 'der', 'Welt', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:35:32,369 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:35:32,370 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:35:32,370 - INFO - joeynmt.training - 	Hypothesis: Und das ist ein gro<unk> es Beispiel von der Natur in der Lage der Welt zu erreichen.
2025-05-29 19:35:32,370 - INFO - joeynmt.training - Example #3
2025-05-29 19:35:32,370 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:35:32,370 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:35:32,370 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'die', 'wir', 'uns', 'er@@', 'laub@@', 'en,', 'die', 'wir', 'uns', 'er@@', 'laub@@', 'en,', 'die', 'wir', 'uns', 'er@@', 'laub@@', 'en,', 'die', 'wir', 'uns', 'er@@', 'laub@@', 'en,', 'die', 'wir', 'uns', 'er@@', 'laub@@', 'en,', 'die', 'wir', 'uns', 'er@@', 'laub@@', 'en,', 'die', 'wir', 'uns', 'er@@', 'laub@@', 'en,', 'die', 'wir', 'uns', 'er@@', 'laub@@', 'en,', 'die', 'wir', 'uns', 'er@@', 'laub@@', 'en,', 'die', 'wir', 'uns', 'er@@', 'laub@@', 'en,', 'die', 'wir', 'uns', 'er@@', 'laub@@', 'en,', 'die', 'wir', 'uns', 'er@@', 'laub@@', 'en,', 'die', 'wir', 'uns', 'er@@', 'laub@@', 'en,', 'die', 'wir', 'uns', 'er@@']
2025-05-29 19:35:32,370 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:35:32,370 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:35:32,370 - INFO - joeynmt.training - 	Hypothesis: Und das ist ein paar Minuten und die M<unk> glichkeiten und die M<unk> glichkeiten und die K<unk> rper, die wir uns erlauben, die wir uns erlauben, die wir uns erlauben, die wir uns erlauben, die wir uns erlauben, die wir uns erlauben, die wir uns erlauben, die wir uns erlauben, die wir uns erlauben, die wir uns erlauben, die wir uns erlauben, die wir uns erlauben, die wir uns erlauben, die wir uns er
2025-05-29 19:35:32,370 - INFO - joeynmt.training - Example #4
2025-05-29 19:35:32,370 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:35:32,370 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:35:32,370 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:35:32,370 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:35:32,370 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:35:32,370 - INFO - joeynmt.training - 	Hypothesis: Und das ist ein paar Minuten und die M<unk> glichkeiten zu ver<unk> ndern.
2025-05-29 19:35:34,692 - INFO - joeynmt.training - Epoch   5, Step:    23100, Batch Loss:     2.163682, Batch Acc: 0.303877, Tokens per Sec:    29888, Lr: 0.000300
2025-05-29 19:35:36,923 - INFO - joeynmt.training - Epoch   5, Step:    23200, Batch Loss:     2.264966, Batch Acc: 0.301914, Tokens per Sec:    31449, Lr: 0.000300
2025-05-29 19:35:39,202 - INFO - joeynmt.training - Epoch   5, Step:    23300, Batch Loss:     2.313123, Batch Acc: 0.300265, Tokens per Sec:    30990, Lr: 0.000300
2025-05-29 19:35:41,546 - INFO - joeynmt.training - Epoch   5, Step:    23400, Batch Loss:     2.329877, Batch Acc: 0.300505, Tokens per Sec:    30468, Lr: 0.000300
2025-05-29 19:35:43,781 - INFO - joeynmt.training - Epoch   5, Step:    23500, Batch Loss:     2.269203, Batch Acc: 0.299744, Tokens per Sec:    30981, Lr: 0.000300
2025-05-29 19:35:43,781 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:35:43,781 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:35:58,847 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.30, ppl:   9.94, acc:   0.30, generation: 15.0548[sec], evaluation: 0.0000[sec]
2025-05-29 19:35:58,847 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:35:58,922 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/21000.ckpt
2025-05-29 19:35:58,928 - INFO - joeynmt.training - Example #0
2025-05-29 19:35:58,928 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:35:58,928 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:35:58,928 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'Ihnen', 'ein', 'paar', 'Bei@@', 'spiel@@', 'e', 'von', 'der', 'S@@', 'o@@', 'zi@@', 'al@@', '-@@', 'S@@', 'o@@', 'ur@@', 'c@@', 'en', 'und', 'ich', 'habe', 'mich', 'in', 'der', 'Welt', 'ver@@', '<unk>', 'n@@', 'der@@', 'n', 'k@@', '<unk>', 'n@@', 'n@@', 'en,', 'die', 'wir', 'in', 'der', 'Welt', 'ver@@', '<unk>', 'n@@', 'der@@', 'n', 'k@@', '<unk>', 'n@@', 'n@@', 'en,', 'die', 'wir', 'in', 'der', 'Welt', 'ver@@', '<unk>', 'n@@', 'der@@', 'n', 'k@@', '<unk>', 'n@@', 'n@@', 'en,', 'die', 'in', 'der', 'Welt', 'ver@@', '<unk>', 'n@@', 'der@@', 'n', 'k@@', '<unk>', 'n@@', 'n@@', 'en,', 'die', 'sich', 'in', 'der', 'Welt', 'ver@@', '<unk>', 'n@@', 'der@@', 'n', 'und', 'die', 'S@@', 'o@@', 'ft@@', 'war@@', 'e@@', '-@@', 'K@@', 'ar@@', 'te', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:35:58,928 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:35:58,928 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:35:58,928 - INFO - joeynmt.training - 	Hypothesis: Ich habe Ihnen ein paar Beispiele von der Sozial-Sourcen und ich habe mich in der Welt ver<unk> ndern k<unk> nnen, die wir in der Welt ver<unk> ndern k<unk> nnen, die wir in der Welt ver<unk> ndern k<unk> nnen, die in der Welt ver<unk> ndern k<unk> nnen, die sich in der Welt ver<unk> ndern und die Software-Karte zu erreichen.
2025-05-29 19:35:58,928 - INFO - joeynmt.training - Example #1
2025-05-29 19:35:58,928 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:35:58,929 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:35:58,929 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'Ihnen', 'eine', 'Art', 'von', 'der', 'S@@', 'o@@', 'ft@@', 'war@@', 'e@@', '-@@', 'S@@', 'o@@', 'ft@@', 'war@@', 'e@@', '-@@', 'S@@', 'o@@', 'ft@@', 'war@@', 'e@@', '-@@', 'S@@', 'o@@', 'ft@@', 'war@@', 'e@@', '-@@', 'S@@', 'o@@', 'zi@@', 'al@@', '-@@', 'S@@', 'o@@', 'ur@@', 'c@@', 'e@@', '-@@', 'S@@', 'o@@', 'ft@@', 'war@@', 'e@@', '-@@', 'S@@', 'o@@', 'ft@@', 'war@@', 'e@@', '-@@', 'S@@', 'e@@', 'x', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:35:58,929 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:35:58,929 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:35:58,929 - INFO - joeynmt.training - 	Hypothesis: Und ich habe Ihnen eine Art von der Software-Software-Software-Software-Sozial-Source-Software-Software-Sex zu ver<unk> ndern.
2025-05-29 19:35:58,929 - INFO - joeynmt.training - Example #2
2025-05-29 19:35:58,929 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:35:58,929 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:35:58,929 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Das', 'ist', 'die', 'S@@', 'o@@', 'ft@@', 'war@@', 'e@@', '-@@', 'S@@', 'o@@', 'ft@@', 'war@@', 'e@@', '-@@', 'S@@', 'o@@', 'ft@@', 'war@@', 'e@@', '-@@', 'S@@', 'o@@', 'ft@@', 'war@@', 'e@@', '-@@', 'S@@', 'o@@', 'ft@@', 'war@@', 'e@@', '-@@', 'S@@', 'o@@', 'ft@@', 'war@@', 'e@@', '-@@', 'S@@', 'o@@', 'ft@@', 'war@@', 'e@@', '-@@', 'S@@', 'o@@', 'ft@@', 'war@@', 'e@@', '-@@', 'S@@', 'o@@', 'ft@@', 'war@@', 'e@@', '-@@', 'S@@', 'o@@', 'zi@@', 'al@@', '-@@', 'S@@', 'o@@', 'ur@@', 'c@@', 'e@@', '-@@', 'S@@', 'o@@', 'ur@@', 'c@@', 'e@@', '-@@', 'S@@', 'o@@', 'ur@@', 'c@@', 'e@@', '-@@', 'S@@', 'o@@', 'ur@@', 'c@@', 'e@@', '-@@', 'S@@', 'o@@', 'ft@@', 'war@@', 'e@@', '-@@', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:35:58,929 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:35:58,929 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:35:58,929 - INFO - joeynmt.training - 	Hypothesis: Das ist die Software-Software-Software-Software-Software-Software-Software-Software-Software-Sozial-Source-Source-Source-Source-Software-K<unk> rper zu ver<unk> ndern.
2025-05-29 19:35:58,929 - INFO - joeynmt.training - Example #3
2025-05-29 19:35:58,929 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:35:58,929 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:35:58,929 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'Ihnen', 'ein', 'paar', 'Bei@@', 'spiel@@', 'e', 'von', 'einem', 'H@@', 'imm@@', 'el', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:35:58,929 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:35:58,929 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:35:58,929 - INFO - joeynmt.training - 	Hypothesis: Ich habe Ihnen ein paar Beispiele von einem Himmel zu erreichen.
2025-05-29 19:35:58,929 - INFO - joeynmt.training - Example #4
2025-05-29 19:35:58,930 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:35:58,930 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:35:58,930 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Das', 'ist', 'die', 'K@@', 'ar@@', 'te', 'der', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'S@@', 'o@@', 'ft@@', 'war@@', 'e@@', '-@@', 'S@@', 'o@@', 'zi@@', 'al@@', '-@@', 'S@@', 'o@@', 'ur@@', 'c@@', 'e@@', '-@@', 'S@@', 'o@@', 'zi@@', 'al@@', '-@@', 'S@@', 'o@@', 'ur@@', 'c@@', 'e@@', '-@@', 'K@@', 'ar@@', 'te', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:35:58,930 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:35:58,930 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:35:58,930 - INFO - joeynmt.training - 	Hypothesis: Das ist die Karte der K<unk> rper und die Software-Sozial-Source-Sozial-Source-Karte zu ver<unk> ndern.
2025-05-29 19:36:01,332 - INFO - joeynmt.training - Epoch   5, Step:    23600, Batch Loss:     2.259774, Batch Acc: 0.304469, Tokens per Sec:    28795, Lr: 0.000300
2025-05-29 19:36:03,566 - INFO - joeynmt.training - Epoch   5, Step:    23700, Batch Loss:     2.212866, Batch Acc: 0.298071, Tokens per Sec:    30913, Lr: 0.000300
2025-05-29 19:36:05,846 - INFO - joeynmt.training - Epoch   5, Step:    23800, Batch Loss:     2.183838, Batch Acc: 0.301390, Tokens per Sec:    32303, Lr: 0.000300
2025-05-29 19:36:08,020 - INFO - joeynmt.training - Epoch   5, Step:    23900, Batch Loss:     2.157238, Batch Acc: 0.302580, Tokens per Sec:    31960, Lr: 0.000300
2025-05-29 19:36:10,132 - INFO - joeynmt.training - Epoch   5, Step:    24000, Batch Loss:     2.289474, Batch Acc: 0.303670, Tokens per Sec:    32688, Lr: 0.000300
2025-05-29 19:36:10,132 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:36:10,132 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:36:19,140 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.29, ppl:   9.87, acc:   0.30, generation: 9.0014[sec], evaluation: 0.0000[sec]
2025-05-29 19:36:19,141 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:36:19,227 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/21500.ckpt
2025-05-29 19:36:19,234 - INFO - joeynmt.training - Example #0
2025-05-29 19:36:19,234 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:36:19,234 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:36:19,234 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'Ihnen', 'ein', 'paar', 'Bei@@', 'spiel@@', 'e', 'von', 'der', 'M@@', '<unk>', 'n@@', 'n@@', 'chen', 'und', 'das', 'ist', 'eine', 'sehr', 'sch@@', 'wi@@', 'er@@', 'ig@@', ',', 'die', 'ich', 'in', 'der', 'M@@', 'it@@', 'te', 'der', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:36:19,234 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:36:19,234 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:36:19,234 - INFO - joeynmt.training - 	Hypothesis: Und ich habe Ihnen ein paar Beispiele von der M<unk> nnchen und das ist eine sehr schwierig, die ich in der Mitte der K<unk> rper zu ver<unk> ndern.
2025-05-29 19:36:19,235 - INFO - joeynmt.training - Example #1
2025-05-29 19:36:19,235 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:36:19,235 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:36:19,235 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'eine', 'sehr', 'sch@@', 'wi@@', 'er@@', 'ig@@', ',', 'dass', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'nicht', 'nur', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:36:19,235 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:36:19,235 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:36:19,235 - INFO - joeynmt.training - 	Hypothesis: Und das ist eine sehr schwierig, dass die M<unk> glichkeit nicht nur die M<unk> glichkeit der K<unk> rper zu ver<unk> ndern.
2025-05-29 19:36:19,235 - INFO - joeynmt.training - Example #2
2025-05-29 19:36:19,235 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:36:19,235 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:36:19,235 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'ein', 'sehr', 'sch@@', 'wi@@', 'er@@', 'ig@@', 'es', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:36:19,235 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:36:19,235 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:36:19,235 - INFO - joeynmt.training - 	Hypothesis: Und das ist ein sehr schwieriges M<unk> nner und die M<unk> glichkeit der K<unk> rper zu ver<unk> ndern.
2025-05-29 19:36:19,235 - INFO - joeynmt.training - Example #3
2025-05-29 19:36:19,236 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:36:19,236 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:36:19,236 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'ein', 'sehr', 'sch@@', 'wi@@', 'er@@', 'ig@@', 'es', 'M@@', '<unk>', 'n@@', 'n@@', 'er,', 'der', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', 'w@@', 'end@@', 'en.', '</s>']
2025-05-29 19:36:19,236 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:36:19,236 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:36:19,236 - INFO - joeynmt.training - 	Hypothesis: Und das ist ein sehr schwieriges M<unk> nner, der die K<unk> rper zu verwenden.
2025-05-29 19:36:19,236 - INFO - joeynmt.training - Example #4
2025-05-29 19:36:19,236 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:36:19,236 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:36:19,236 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'eine', 'sehr', 'sch@@', 'wi@@', 'er@@', 'ig@@', ',', 'aber', 'es', 'ist', 'eine', 'sehr', 'sch@@', 'wi@@', 'er@@', 'ig@@', ',', 'dass', 'sie', 'in', 'der', 'M@@', 'it@@', 'te', 'der', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:36:19,236 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:36:19,236 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:36:19,236 - INFO - joeynmt.training - 	Hypothesis: Und das ist eine sehr schwierig, aber es ist eine sehr schwierig, dass sie in der Mitte der K<unk> rper zu ver<unk> ndern.
2025-05-29 19:36:21,464 - INFO - joeynmt.training - Epoch   5, Step:    24100, Batch Loss:     2.312960, Batch Acc: 0.302858, Tokens per Sec:    30874, Lr: 0.000300
2025-05-29 19:36:24,788 - INFO - joeynmt.training - Epoch   5, Step:    24200, Batch Loss:     2.233847, Batch Acc: 0.302920, Tokens per Sec:    20169, Lr: 0.000300
2025-05-29 19:36:27,437 - INFO - joeynmt.training - Epoch   5, Step:    24300, Batch Loss:     2.250995, Batch Acc: 0.297917, Tokens per Sec:    26299, Lr: 0.000300
2025-05-29 19:36:29,857 - INFO - joeynmt.training - Epoch   5, Step:    24400, Batch Loss:     2.325109, Batch Acc: 0.303553, Tokens per Sec:    29393, Lr: 0.000300
2025-05-29 19:36:31,800 - INFO - joeynmt.training - Epoch   5, Step:    24500, Batch Loss:     2.205172, Batch Acc: 0.299825, Tokens per Sec:    38017, Lr: 0.000300
2025-05-29 19:36:31,800 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:36:31,800 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:36:45,226 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.28, ppl:   9.82, acc:   0.31, generation: 13.4153[sec], evaluation: 0.0000[sec]
2025-05-29 19:36:45,226 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:36:45,311 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/22000.ckpt
2025-05-29 19:36:45,318 - INFO - joeynmt.training - Example #0
2025-05-29 19:36:45,318 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:36:45,318 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:36:45,318 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'es', 'nicht', 'ge@@', 'frag@@', 't,', 'was', 'ich', 'sag@@', 'en', 'm@@', '<unk>', 'ss@@', 'en,', 'dass', 'ich', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'was', 'ich', 'sag@@', 'en', 'm@@', '<unk>', 'ss@@', 'en,', 'dass', 'ich', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'mach@@', 'en.', '</s>']
2025-05-29 19:36:45,318 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:36:45,318 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:36:45,318 - INFO - joeynmt.training - 	Hypothesis: Und ich habe es nicht gefragt, was ich sagen m<unk> ssen, dass ich die M<unk> glichkeit der K<unk> rper zu verwenden, was ich sagen m<unk> ssen, dass ich die M<unk> glichkeit der K<unk> rper zu machen.
2025-05-29 19:36:45,318 - INFO - joeynmt.training - Example #1
2025-05-29 19:36:45,319 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:36:45,319 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:36:45,319 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'nicht', 'nur', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:36:45,319 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:36:45,319 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:36:45,319 - INFO - joeynmt.training - 	Hypothesis: Und das ist nicht nur ein paar Minuten und die M<unk> glichkeit der M<unk> glichkeit der K<unk> rper zu ver<unk> ndern.
2025-05-29 19:36:45,319 - INFO - joeynmt.training - Example #2
2025-05-29 19:36:45,319 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:36:45,319 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:36:45,319 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', 'w@@', 'end@@', 'en.', '</s>']
2025-05-29 19:36:45,319 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:36:45,319 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:36:45,319 - INFO - joeynmt.training - 	Hypothesis: Und das ist die M<unk> glichkeit der K<unk> rper und die M<unk> glichkeit der K<unk> rper zu verwenden.
2025-05-29 19:36:45,319 - INFO - joeynmt.training - Example #3
2025-05-29 19:36:45,320 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:36:45,320 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:36:45,320 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Sie', 'k@@', '<unk>', 'n@@', 'nen', 'sich', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'und', 'sie', 'k@@', '<unk>', 'n@@', 'nen', 'und', 'sie', 'k@@', '<unk>', 'n@@', 'nen', 'sich', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:36:45,320 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:36:45,320 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:36:45,320 - INFO - joeynmt.training - 	Hypothesis: Sie k<unk> nnen sich die M<unk> glichkeit und die M<unk> glichkeit der M<unk> glichkeit der K<unk> rper zu verwenden, und sie k<unk> nnen und sie k<unk> nnen sich die M<unk> glichkeit zu ver<unk> ndern.
2025-05-29 19:36:45,320 - INFO - joeynmt.training - Example #4
2025-05-29 19:36:45,320 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:36:45,320 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:36:45,320 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:36:45,320 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:36:45,320 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:36:45,321 - INFO - joeynmt.training - 	Hypothesis: Und das ist die M<unk> glichkeit der M<unk> glichkeit der M<unk> glichkeit der M<unk> glichkeit der K<unk> rper zu ver<unk> ndern.
2025-05-29 19:36:47,556 - INFO - joeynmt.training - Epoch   5, Step:    24600, Batch Loss:     2.334044, Batch Acc: 0.303110, Tokens per Sec:    30962, Lr: 0.000300
2025-05-29 19:36:49,821 - INFO - joeynmt.training - Epoch   5, Step:    24700, Batch Loss:     2.308044, Batch Acc: 0.304372, Tokens per Sec:    31487, Lr: 0.000300
2025-05-29 19:36:52,045 - INFO - joeynmt.training - Epoch   5, Step:    24800, Batch Loss:     2.270215, Batch Acc: 0.302216, Tokens per Sec:    31724, Lr: 0.000300
2025-05-29 19:36:54,392 - INFO - joeynmt.training - Epoch   5, Step:    24900, Batch Loss:     2.277999, Batch Acc: 0.299425, Tokens per Sec:    29842, Lr: 0.000300
2025-05-29 19:36:57,654 - INFO - joeynmt.training - Epoch   5, Step:    25000, Batch Loss:     2.352134, Batch Acc: 0.302120, Tokens per Sec:    21966, Lr: 0.000300
2025-05-29 19:36:57,654 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:36:57,654 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:37:12,622 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.28, ppl:   9.76, acc:   0.31, generation: 14.9549[sec], evaluation: 0.0000[sec]
2025-05-29 19:37:12,622 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:37:12,709 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/22500.ckpt
2025-05-29 19:37:12,715 - INFO - joeynmt.training - Example #0
2025-05-29 19:37:12,715 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:37:12,715 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:37:12,715 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'es', 'in', 'der', 'L@@', 'age', 'der', 'M@@', '<unk>', 'n@@', 'n@@', 'er,', 'die', 'ich', 'in', 'der', 'L@@', 'age', 'in', 'der', 'L@@', 'age', 'in', 'der', 'L@@', 'age', 'in', 'der', 'L@@', 'age', 'in', 'der', 'L@@', 'age', 'in', 'der', 'L@@', 'age', 'in', 'der', 'L@@', 'age', 'in', 'der', 'L@@', 'age', 'in', 'der', 'L@@', 'age', 'zu', 'ver@@', 'w@@', 'end@@', 'eten', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', 'w@@', 'end@@', 'et.', '</s>']
2025-05-29 19:37:12,715 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:37:12,715 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:37:12,715 - INFO - joeynmt.training - 	Hypothesis: Und ich habe es in der Lage der M<unk> nner, die ich in der Lage in der Lage in der Lage in der Lage in der Lage in der Lage in der Lage in der Lage in der Lage zu verwendeten und die K<unk> rper zu verwendet.
2025-05-29 19:37:12,715 - INFO - joeynmt.training - Example #1
2025-05-29 19:37:12,715 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:37:12,715 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:37:12,715 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'die', 'K@@', 'am@@', 'era', 'in', 'der', 'L@@', 'age', 'der', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'F@@', '<unk>', 'h@@', 'ig@@', 'kei@@', 'ten', 'der', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', 'am@@', 'era', 'und', 'der', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'die', 'die', 'sich', 'in', 'der', 'T@@', 'at', 'und', 'die', 'K@@', 'am@@', 'era', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und']
2025-05-29 19:37:12,716 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:37:12,716 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:37:12,716 - INFO - joeynmt.training - 	Hypothesis: Und das ist die Kamera in der Lage der K<unk> rper und die K<unk> rper und die K<unk> rper und die F<unk> higkeiten der K<unk> rper und die K<unk> rper und die K<unk> rper zu verwenden, und die K<unk> rper und die Kamera und der K<unk> rper und die K<unk> rper und die M<unk> glichkeit der K<unk> rper, die die sich in der Tat und die Kamera und die K<unk> rper und
2025-05-29 19:37:12,716 - INFO - joeynmt.training - Example #2
2025-05-29 19:37:12,716 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:37:12,716 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:37:12,716 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'eine', 'M@@', 'en@@', 'ge', 'S@@', 'ach@@', 'e,', 'die', 'wir', 'in', 'der', 'T@@', 'at', 'in', 'der', 'L@@', 'age', 'in', 'der', 'L@@', 'age', 'in', 'der', 'L@@', 'age', 'in', 'der', 'L@@', 'age', 'in', 'der', 'L@@', 'age', 'in', 'der', 'L@@', 'age', 'in', 'der', 'L@@', 'age', 'zu', 'er@@', 'for@@', 'sch@@', 'en.', '</s>']
2025-05-29 19:37:12,716 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:37:12,716 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:37:12,716 - INFO - joeynmt.training - 	Hypothesis: Und das ist eine Menge Sache, die wir in der Tat in der Lage in der Lage in der Lage in der Lage in der Lage in der Lage in der Lage zu erforschen.
2025-05-29 19:37:12,716 - INFO - joeynmt.training - Example #3
2025-05-29 19:37:12,716 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:37:12,716 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:37:12,716 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'eine', 'M@@', 'en@@', 'ge', 'und', 'ich', 'habe', 'es', 'in', 'der', 'L@@', 'age', 'der', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'die', 'wir', 'in', 'der', 'Welt', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:37:12,716 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:37:12,716 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:37:12,716 - INFO - joeynmt.training - 	Hypothesis: Und das ist eine Menge und ich habe es in der Lage der K<unk> rper und die K<unk> rper zu verwenden, die wir in der Welt ver<unk> ndern.
2025-05-29 19:37:12,716 - INFO - joeynmt.training - Example #4
2025-05-29 19:37:12,717 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:37:12,717 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:37:12,717 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'denk@@', 'e,', 'dass', 'ich', 'in', 'der', 'L@@', 'age', 'in', 'der', 'L@@', 'age', 'in', 'der', 'L@@', 'age', 'in', 'der', 'L@@', 'age', 'in', 'der', 'L@@', 'age', 'in', 'der', 'L@@', 'age', 'in', 'der', 'L@@', 'age', 'in', 'der', 'L@@', 'age', 'in', 'der', 'L@@', 'age', 'zu', 'er@@', 'for@@', 'sch@@', 'en.', '</s>']
2025-05-29 19:37:12,717 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:37:12,717 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:37:12,717 - INFO - joeynmt.training - 	Hypothesis: Und ich denke, dass ich in der Lage in der Lage in der Lage in der Lage in der Lage in der Lage in der Lage in der Lage in der Lage zu erforschen.
2025-05-29 19:37:14,921 - INFO - joeynmt.training - Epoch   5, Step:    25100, Batch Loss:     2.339216, Batch Acc: 0.305888, Tokens per Sec:    30239, Lr: 0.000300
2025-05-29 19:37:17,091 - INFO - joeynmt.training - Epoch   5, Step:    25200, Batch Loss:     2.291602, Batch Acc: 0.302620, Tokens per Sec:    31681, Lr: 0.000300
2025-05-29 19:37:19,417 - INFO - joeynmt.training - Epoch   5, Step:    25300, Batch Loss:     2.343897, Batch Acc: 0.303895, Tokens per Sec:    30119, Lr: 0.000300
2025-05-29 19:37:21,673 - INFO - joeynmt.training - Epoch   5, Step:    25400, Batch Loss:     2.314027, Batch Acc: 0.302210, Tokens per Sec:    32140, Lr: 0.000300
2025-05-29 19:37:23,924 - INFO - joeynmt.training - Epoch   5, Step:    25500, Batch Loss:     2.179116, Batch Acc: 0.299196, Tokens per Sec:    31444, Lr: 0.000300
2025-05-29 19:37:23,924 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:37:23,924 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:37:38,412 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.28, ppl:   9.77, acc:   0.31, generation: 14.4773[sec], evaluation: 0.0000[sec]
2025-05-29 19:37:38,496 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/23000.ckpt
2025-05-29 19:37:38,502 - INFO - joeynmt.training - Example #0
2025-05-29 19:37:38,503 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:37:38,503 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:37:38,503 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'eine', 'M@@', 'en@@', 'ge', 'S@@', 'ach@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'en,', 'dass', 'ich', 'das', 'nicht', 'nur', 'in', 'der', 'L@@', 'age', 'der', 'Welt', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:37:38,503 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:37:38,503 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:37:38,503 - INFO - joeynmt.training - 	Hypothesis: Ich habe eine Menge Sache, die ich Ihnen zeigen, dass ich das nicht nur in der Lage der Welt zu erreichen.
2025-05-29 19:37:38,503 - INFO - joeynmt.training - Example #1
2025-05-29 19:37:38,503 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:37:38,503 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:37:38,503 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'nicht', 'nur', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 't,', 'die', 'wir', 'nicht', 'in', 'der', 'L@@', 'age', 'nicht', 'ver@@', 'st@@', '<unk>', 'r@@', 'k@@', 'er', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 't,', 'die', 'wir', 'nicht', 'nur', 'mit', 'der', 'Welt', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:37:38,503 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:37:38,503 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:37:38,503 - INFO - joeynmt.training - 	Hypothesis: Und das ist nicht nur ein paar Minuten und die M<unk> glichkeit, die wir nicht in der Lage nicht verst<unk> rker und die M<unk> glichkeit, die wir nicht nur mit der Welt zu erreichen.
2025-05-29 19:37:38,503 - INFO - joeynmt.training - Example #2
2025-05-29 19:37:38,503 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:37:38,503 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:37:38,503 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'S@@', 'tra@@', '<unk>', 'e', 'ist', 'ein', 'sehr', 'sch@@', 'wi@@', 'er@@', 'ig@@', 'es', 'Pro@@', 'bl@@', 'em', 'der', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 't,', 'die', 'wir', 'in', 'der', 'L@@', 'age', 'der', 'von', 'der', 'L@@', 'eut@@', 'en', 'der', 'S@@', 'tra@@', '<unk>', 'e', 'der', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:37:38,504 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:37:38,504 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:37:38,504 - INFO - joeynmt.training - 	Hypothesis: Die Stra<unk> e ist ein sehr schwieriges Problem der K<unk> rper und die M<unk> glichkeit, die wir in der Lage der von der Leuten der Stra<unk> e der K<unk> rper zu ver<unk> ndern.
2025-05-29 19:37:38,504 - INFO - joeynmt.training - Example #3
2025-05-29 19:37:38,504 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:37:38,504 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:37:38,504 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'eine', 'M@@', 'en@@', 'ge', 'S@@', 'ach@@', 'e,', 'die', 'ich', 'Ihnen', 'nicht', 'zeig@@', 'en,', 'dass', 'es', 'nicht', 'nur', 'in', 'der', 'L@@', 'age', 'ist,', 'dass', 'es', 'nicht', 'nur', 'in', 'der', 'L@@', 'age', 'ist,', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:37:38,504 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:37:38,504 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:37:38,504 - INFO - joeynmt.training - 	Hypothesis: Und das ist eine Menge Sache, die ich Ihnen nicht zeigen, dass es nicht nur in der Lage ist, dass es nicht nur in der Lage ist, die K<unk> rper zu erreichen.
2025-05-29 19:37:38,504 - INFO - joeynmt.training - Example #4
2025-05-29 19:37:38,504 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:37:38,504 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:37:38,504 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'S@@', 'tra@@', '<unk>', 'e', 'ist', 'nicht', 'nur', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 't,', 'die', 'wir', 'in', 'der', 'Welt', 'zu', 'er@@', 'rei@@', 'chen,', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 't,', 'die', 'wir', 'uns', 'nicht', 'ver@@', 'st@@', '<unk>', 'n@@', 'd@@', 'lich', 'zu', 'er@@', 'kl@@', '<unk>', 'r@@', 'en,', 'die', 'wir', 'uns', 'nicht', 'nur', 'in', 'der', 'L@@', 'age', 'in', 'der', 'L@@', 'age', 'in', 'der', 'L@@', 'age', 'zu', 'er@@', 'for@@', 'sch@@', 'en.', '</s>']
2025-05-29 19:37:38,504 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:37:38,504 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:37:38,505 - INFO - joeynmt.training - 	Hypothesis: Die Stra<unk> e ist nicht nur ein paar Minuten und die M<unk> glichkeit, die wir in der Welt zu erreichen, und die M<unk> glichkeit, die wir uns nicht verst<unk> ndlich zu erkl<unk> ren, die wir uns nicht nur in der Lage in der Lage in der Lage zu erforschen.
2025-05-29 19:37:40,962 - INFO - joeynmt.training - Epoch   5, Step:    25600, Batch Loss:     2.211463, Batch Acc: 0.306563, Tokens per Sec:    28389, Lr: 0.000300
2025-05-29 19:37:43,032 - INFO - joeynmt.training - Epoch   5, Step:    25700, Batch Loss:     2.369435, Batch Acc: 0.301018, Tokens per Sec:    34555, Lr: 0.000300
2025-05-29 19:37:45,182 - INFO - joeynmt.training - Epoch   5, Step:    25800, Batch Loss:     2.365255, Batch Acc: 0.307551, Tokens per Sec:    33353, Lr: 0.000300
2025-05-29 19:37:47,330 - INFO - joeynmt.training - Epoch   5, Step:    25900, Batch Loss:     2.297563, Batch Acc: 0.303889, Tokens per Sec:    33174, Lr: 0.000300
2025-05-29 19:37:49,485 - INFO - joeynmt.training - Epoch   5, Step:    26000, Batch Loss:     2.357203, Batch Acc: 0.302393, Tokens per Sec:    33947, Lr: 0.000300
2025-05-29 19:37:49,485 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:37:49,485 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:38:05,564 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.28, ppl:   9.75, acc:   0.31, generation: 16.0668[sec], evaluation: 0.0000[sec]
2025-05-29 19:38:05,564 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:38:05,652 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/23500.ckpt
2025-05-29 19:38:05,658 - INFO - joeynmt.training - Example #0
2025-05-29 19:38:05,658 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:38:05,658 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:38:05,659 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'es', 'nicht', 'nur', 'in', 'der', 'N@@', 'at@@', 'ur', 'und', 'ich', 'bin', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'und', 'ich', 'wei@@', '<unk>', ',', 'dass', 'ich', 'es', 'nicht', 'nur', 'in', 'der', 'Welt', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:38:05,659 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:38:05,659 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:38:05,659 - INFO - joeynmt.training - 	Hypothesis: Und ich habe es nicht nur in der Natur und ich bin ein paar Minuten und ich wei<unk> , dass ich es nicht nur in der Welt zu erreichen.
2025-05-29 19:38:05,659 - INFO - joeynmt.training - Example #1
2025-05-29 19:38:05,659 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:38:05,659 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:38:05,659 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'wenn', 'wir', 'uns', 'die', 'F@@', '<unk>', 'h@@', 'ig@@', 'keit', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:38:05,659 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:38:05,659 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:38:05,659 - INFO - joeynmt.training - 	Hypothesis: Und wenn wir uns die F<unk> higkeit zu erreichen.
2025-05-29 19:38:05,659 - INFO - joeynmt.training - Example #2
2025-05-29 19:38:05,660 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:38:05,660 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:38:05,660 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'wenn', 'wir', 'uns', 'die', 'F@@', '<unk>', 'h@@', 'ig@@', 'keit', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:38:05,660 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:38:05,660 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:38:05,660 - INFO - joeynmt.training - 	Hypothesis: Und wenn wir uns die F<unk> higkeit zu erreichen.
2025-05-29 19:38:05,660 - INFO - joeynmt.training - Example #3
2025-05-29 19:38:05,660 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:38:05,660 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:38:05,660 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Sie', 'haben', 'eine', 'M@@', 'en@@', 'ge', 'S@@', 'ach@@', 'e,', 'die', 'wir', 'uns', 'er@@', 'laub@@', 'en,', 'die', 'wir', 'uns', 'er@@', 'laub@@', 'en,', 'die', 'wir', 'nicht', 'nur', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'zu', 'er@@', 'for@@', 'sch@@', 'en.', '</s>']
2025-05-29 19:38:05,660 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:38:05,660 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:38:05,660 - INFO - joeynmt.training - 	Hypothesis: Sie haben eine Menge Sache, die wir uns erlauben, die wir uns erlauben, die wir nicht nur die M<unk> glichkeit zu erforschen.
2025-05-29 19:38:05,660 - INFO - joeynmt.training - Example #4
2025-05-29 19:38:05,661 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:38:05,661 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:38:05,661 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'wenn', 'wir', 'uns', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:38:05,661 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:38:05,661 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:38:05,661 - INFO - joeynmt.training - 	Hypothesis: Und wenn wir uns die M<unk> glichkeit zu erreichen.
2025-05-29 19:38:07,932 - INFO - joeynmt.training - Epoch   5, Step:    26100, Batch Loss:     2.179833, Batch Acc: 0.302473, Tokens per Sec:    28741, Lr: 0.000300
2025-05-29 19:38:09,827 - INFO - joeynmt.training - Epoch   5, Step:    26200, Batch Loss:     2.295694, Batch Acc: 0.302528, Tokens per Sec:    37546, Lr: 0.000300
2025-05-29 19:38:11,981 - INFO - joeynmt.training - Epoch   5, Step:    26300, Batch Loss:     2.287900, Batch Acc: 0.298488, Tokens per Sec:    32695, Lr: 0.000300
2025-05-29 19:38:14,434 - INFO - joeynmt.training - Epoch   5, Step:    26400, Batch Loss:     2.284808, Batch Acc: 0.302432, Tokens per Sec:    28641, Lr: 0.000300
2025-05-29 19:38:17,116 - INFO - joeynmt.training - Epoch   5, Step:    26500, Batch Loss:     2.302122, Batch Acc: 0.301418, Tokens per Sec:    25909, Lr: 0.000300
2025-05-29 19:38:17,116 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:38:17,116 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:38:31,555 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.28, ppl:   9.74, acc:   0.31, generation: 14.4257[sec], evaluation: 0.0000[sec]
2025-05-29 19:38:31,556 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:38:31,640 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/24000.ckpt
2025-05-29 19:38:31,646 - INFO - joeynmt.training - Example #0
2025-05-29 19:38:31,646 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:38:31,646 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:38:31,646 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'um', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'die', 'sich', 'in', 'der', 'Welt', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:38:31,646 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:38:31,646 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:38:31,646 - INFO - joeynmt.training - 	Hypothesis: Ich habe die M<unk> glichkeiten und die M<unk> glichkeiten und die M<unk> glichkeiten zu verwenden, um die M<unk> glichkeiten zu verwenden, die sich in der Welt zu ver<unk> ndern und die M<unk> glichkeiten zu ver<unk> ndern.
2025-05-29 19:38:31,646 - INFO - joeynmt.training - Example #1
2025-05-29 19:38:31,646 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:38:31,646 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:38:31,646 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'sag@@', 'te,', '"@@', 'Ich', 'habe', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'von', 'der', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'dass', 'ich', 'nicht', 'nur', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'dass', 'ich', 'nicht', 'nur', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:38:31,647 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:38:31,647 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:38:31,647 - INFO - joeynmt.training - 	Hypothesis: Und ich sagte, "Ich habe die M<unk> glichkeiten von der M<unk> glichkeiten zu verwenden, dass ich nicht nur die M<unk> glichkeiten zu verwenden, dass ich nicht nur die M<unk> glichkeiten zu ver<unk> ndern.
2025-05-29 19:38:31,647 - INFO - joeynmt.training - Example #2
2025-05-29 19:38:31,647 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:38:31,647 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:38:31,647 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'sag@@', 'te,', '"@@', 'Ich', 'habe', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'von', 'der', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'zu', 'einem', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:38:31,647 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:38:31,647 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:38:31,647 - INFO - joeynmt.training - 	Hypothesis: Und ich sagte, "Ich habe die M<unk> glichkeiten von der M<unk> glichkeiten zu einem K<unk> rper zu ver<unk> ndern.
2025-05-29 19:38:31,647 - INFO - joeynmt.training - Example #3
2025-05-29 19:38:31,647 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:38:31,647 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:38:31,647 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'ein', 'sehr', 'gut@@', 'es', 'Bei@@', 'spi@@', 'el', 'der', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'die', 'sich', 'in', 'der', 'Welt', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:38:31,647 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:38:31,647 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:38:31,647 - INFO - joeynmt.training - 	Hypothesis: Es ist ein sehr gutes Beispiel der M<unk> glichkeiten und die M<unk> glichkeiten zu verwenden, die sich in der Welt zu ver<unk> ndern.
2025-05-29 19:38:31,647 - INFO - joeynmt.training - Example #4
2025-05-29 19:38:31,648 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:38:31,648 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:38:31,648 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'sag@@', 'te,', '"@@', 'Ich', 'habe', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'von', 'der', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'dass', 'ich', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'dass', 'ich', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'dass', 'ich', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'dass', 'ich', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:38:31,648 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:38:31,648 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:38:31,648 - INFO - joeynmt.training - 	Hypothesis: Und ich sagte, "Ich habe die M<unk> glichkeiten von der M<unk> glichkeiten zu verwenden, dass ich die M<unk> glichkeiten zu verwenden, dass ich die M<unk> glichkeiten zu verwenden, dass ich die M<unk> glichkeiten zu verwenden, dass ich die M<unk> glichkeiten zu ver<unk> ndern.
2025-05-29 19:38:34,115 - INFO - joeynmt.training - Epoch   5, Step:    26600, Batch Loss:     2.188596, Batch Acc: 0.301537, Tokens per Sec:    27962, Lr: 0.000300
2025-05-29 19:38:37,563 - INFO - joeynmt.training - Epoch   5, Step:    26700, Batch Loss:     2.255385, Batch Acc: 0.303970, Tokens per Sec:    20099, Lr: 0.000300
2025-05-29 19:38:38,306 - INFO - joeynmt.training - Epoch   5: total training loss 12175.56
2025-05-29 19:38:38,306 - INFO - joeynmt.training - EPOCH 6
2025-05-29 19:38:39,887 - INFO - joeynmt.training - Epoch   6, Step:    26800, Batch Loss:     2.186466, Batch Acc: 0.308679, Tokens per Sec:    29066, Lr: 0.000300
2025-05-29 19:38:41,989 - INFO - joeynmt.training - Epoch   6, Step:    26900, Batch Loss:     2.317481, Batch Acc: 0.311265, Tokens per Sec:    34727, Lr: 0.000300
2025-05-29 19:38:44,064 - INFO - joeynmt.training - Epoch   6, Step:    27000, Batch Loss:     2.284286, Batch Acc: 0.308896, Tokens per Sec:    33915, Lr: 0.000300
2025-05-29 19:38:44,064 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:38:44,064 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:38:52,473 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.28, ppl:   9.77, acc:   0.31, generation: 8.4026[sec], evaluation: 0.0000[sec]
2025-05-29 19:38:52,555 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/24500.ckpt
2025-05-29 19:38:52,561 - INFO - joeynmt.training - Example #0
2025-05-29 19:38:52,561 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:38:52,561 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:38:52,561 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'und', 'ich', 'habe', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'und', 'ich', 'habe', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'zu', 'k@@', '<unk>', 'n@@', 'n@@', 'en.', '</s>']
2025-05-29 19:38:52,561 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:38:52,561 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:38:52,561 - INFO - joeynmt.training - 	Hypothesis: Und ich habe ein paar Minuten und ich habe ein paar Minuten und ich habe ein paar Minuten zu k<unk> nnen.
2025-05-29 19:38:52,561 - INFO - joeynmt.training - Example #1
2025-05-29 19:38:52,561 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:38:52,561 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:38:52,561 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'die', 'B@@', 'r@@', '<unk>', 'ck@@', 'e', 'von', 'der', 'M@@', 'it@@', 'te', 'der', 'M@@', 'en@@', 'ge', 'der', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:38:52,561 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:38:52,562 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:38:52,562 - INFO - joeynmt.training - 	Hypothesis: Und das ist die Br<unk> cke von der Mitte der Menge der K<unk> rper zu ver<unk> ndern.
2025-05-29 19:38:52,562 - INFO - joeynmt.training - Example #2
2025-05-29 19:38:52,562 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:38:52,562 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:38:52,562 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Das', 'ist', 'ein', 'M@@', 'ann', 'ist', 'ein', 'sehr', 'sch@@', '<unk>', 'n@@', 'es', 'Pro@@', 'jek@@', 't', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:38:52,562 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:38:52,562 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:38:52,562 - INFO - joeynmt.training - 	Hypothesis: Das ist ein Mann ist ein sehr sch<unk> nes Projekt und die M<unk> glichkeit der K<unk> rper zu ver<unk> ndern.
2025-05-29 19:38:52,562 - INFO - joeynmt.training - Example #3
2025-05-29 19:38:52,562 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:38:52,562 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:38:52,562 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'ein', 'sehr', 'sch@@', '<unk>', 'n@@', 'es', 'Pro@@', 'bl@@', 'em', 'ist,', 'dass', 'wir', 'das', 'nicht', 'ver@@', 'st@@', '<unk>', 'n@@', 'd@@', 'et.', '</s>']
2025-05-29 19:38:52,562 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:38:52,562 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:38:52,562 - INFO - joeynmt.training - 	Hypothesis: Und das ist ein sehr sch<unk> nes Problem ist, dass wir das nicht verst<unk> ndet.
2025-05-29 19:38:52,562 - INFO - joeynmt.training - Example #4
2025-05-29 19:38:52,563 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:38:52,563 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:38:52,563 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Das', 'ist', 'ein', 'g@@', 'ro@@', '<unk>', 'er', 'M@@', 'ann', 'ist', 'ein', 'sehr', 'sch@@', '<unk>', 'n@@', 'es', 'M@@', 'it@@', 'ge@@', 'f@@', '<unk>', 'h@@', 'l', 'und', 'sie', 'ist', 'nicht', 'nur', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'zu', 'ver@@', 'bess@@', 'ern@@', '.', '</s>']
2025-05-29 19:38:52,563 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:38:52,563 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:38:52,563 - INFO - joeynmt.training - 	Hypothesis: Das ist ein gro<unk> er Mann ist ein sehr sch<unk> nes Mitgef<unk> hl und sie ist nicht nur ein paar Minuten und die M<unk> glichkeit zu verbessern.
2025-05-29 19:38:54,787 - INFO - joeynmt.training - Epoch   6, Step:    27100, Batch Loss:     2.172694, Batch Acc: 0.312203, Tokens per Sec:    29438, Lr: 0.000300
2025-05-29 19:38:56,792 - INFO - joeynmt.training - Epoch   6, Step:    27200, Batch Loss:     2.318055, Batch Acc: 0.313108, Tokens per Sec:    35831, Lr: 0.000300
2025-05-29 19:38:58,724 - INFO - joeynmt.training - Epoch   6, Step:    27300, Batch Loss:     2.242622, Batch Acc: 0.310318, Tokens per Sec:    37569, Lr: 0.000300
2025-05-29 19:39:00,937 - INFO - joeynmt.training - Epoch   6, Step:    27400, Batch Loss:     2.231187, Batch Acc: 0.310311, Tokens per Sec:    31845, Lr: 0.000300
2025-05-29 19:39:03,261 - INFO - joeynmt.training - Epoch   6, Step:    27500, Batch Loss:     2.260044, Batch Acc: 0.310858, Tokens per Sec:    30495, Lr: 0.000300
2025-05-29 19:39:03,262 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:39:03,262 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:39:17,173 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.27, ppl:   9.67, acc:   0.31, generation: 13.9023[sec], evaluation: 0.0000[sec]
2025-05-29 19:39:17,173 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:39:17,260 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/25500.ckpt
2025-05-29 19:39:17,265 - INFO - joeynmt.training - Example #0
2025-05-29 19:39:17,266 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:39:17,266 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:39:17,266 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'mir', 'ge@@', 'frag@@', 't,', 'wie', 'ich', 'das', 'hier', 'in', 'der', 'L@@', 'age', 'der', 'Welt', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:39:17,266 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:39:17,266 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:39:17,266 - INFO - joeynmt.training - 	Hypothesis: Und ich habe mir gefragt, wie ich das hier in der Lage der Welt zu ver<unk> ndern.
2025-05-29 19:39:17,266 - INFO - joeynmt.training - Example #1
2025-05-29 19:39:17,266 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:39:17,266 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:39:17,266 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'denk@@', 'e,', 'dass', 'die', 'M@@', '<unk>', 'n@@', 'ner', 'in', 'der', 'L@@', 'age', 'nicht', 'nur', 'die', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'die', 'wir', 'nicht', 'nur', 'die', 'M@@', '<unk>', 'n@@', 'ner', 'in', 'der', 'Welt', 'nicht', 'nur', 'ein', 'paar', 'T@@', 'ag@@', 'en', 'und', 'die', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'Fr@@', 'auen', 'in', 'der', 'Welt', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:39:17,266 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:39:17,266 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:39:17,267 - INFO - joeynmt.training - 	Hypothesis: Und ich denke, dass die M<unk> nner in der Lage nicht nur die K<unk> rper, die wir nicht nur die M<unk> nner in der Welt nicht nur ein paar Tagen und die M<unk> nner und Frauen in der Welt zu ver<unk> ndern.
2025-05-29 19:39:17,267 - INFO - joeynmt.training - Example #2
2025-05-29 19:39:17,267 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:39:17,267 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:39:17,267 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'sag@@', 'te,', '"@@', 'Ich', 'bin', 'in', 'ein', 'paar', 'Jahren', 'in', 'einem', 'K@@', 'op@@', 'f', 'in', 'einem', 'K@@', 'op@@', 'f', 'und', 'ich', 'wei@@', '<unk>', ',', 'dass', 'ich', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'in', 'der', 'Welt', 'nicht', 'nur', 'ein', 'paar', 'T@@', 'age', 'in', 'der', 'Welt', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:39:17,267 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:39:17,267 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:39:17,267 - INFO - joeynmt.training - 	Hypothesis: Und ich sagte, "Ich bin in ein paar Jahren in einem Kopf in einem Kopf und ich wei<unk> , dass ich ein paar Minuten in der Welt nicht nur ein paar Tage in der Welt zu ver<unk> ndern.
2025-05-29 19:39:17,267 - INFO - joeynmt.training - Example #3
2025-05-29 19:39:17,267 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:39:17,267 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:39:17,267 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'denk@@', 'e,', 'dass', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'die', 'ich', 'in', 'der', 'Welt', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:39:17,267 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:39:17,267 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:39:17,267 - INFO - joeynmt.training - 	Hypothesis: Und ich denke, dass die M<unk> glichkeit der K<unk> rper, die ich in der Welt ver<unk> ndern.
2025-05-29 19:39:17,267 - INFO - joeynmt.training - Example #4
2025-05-29 19:39:17,268 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:39:17,268 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:39:17,268 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'sag@@', 'te', 'mi@@', 'r,', 'dass', 'ich', 'das', 'nicht', 'nur', 'ein', 'paar', 'T@@', 'age', 'in', 'den', 'letz@@', 'ten', '1@@', '5', 'Jahren', 'in', 'der', 'Welt', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:39:17,268 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:39:17,268 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:39:17,268 - INFO - joeynmt.training - 	Hypothesis: Und ich sagte mir, dass ich das nicht nur ein paar Tage in den letzten 15 Jahren in der Welt zu ver<unk> ndern.
2025-05-29 19:39:19,580 - INFO - joeynmt.training - Epoch   6, Step:    27600, Batch Loss:     2.280619, Batch Acc: 0.309334, Tokens per Sec:    29634, Lr: 0.000300
2025-05-29 19:39:21,992 - INFO - joeynmt.training - Epoch   6, Step:    27700, Batch Loss:     2.255775, Batch Acc: 0.304577, Tokens per Sec:    29134, Lr: 0.000300
2025-05-29 19:39:23,943 - INFO - joeynmt.training - Epoch   6, Step:    27800, Batch Loss:     2.205306, Batch Acc: 0.312011, Tokens per Sec:    36255, Lr: 0.000300
2025-05-29 19:39:25,973 - INFO - joeynmt.training - Epoch   6, Step:    27900, Batch Loss:     2.521008, Batch Acc: 0.309944, Tokens per Sec:    34848, Lr: 0.000300
2025-05-29 19:39:28,247 - INFO - joeynmt.training - Epoch   6, Step:    28000, Batch Loss:     2.175060, Batch Acc: 0.307703, Tokens per Sec:    31662, Lr: 0.000300
2025-05-29 19:39:28,247 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:39:28,247 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:39:42,307 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.27, ppl:   9.65, acc:   0.31, generation: 14.0493[sec], evaluation: 0.0000[sec]
2025-05-29 19:39:42,307 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:39:42,393 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/27000.ckpt
2025-05-29 19:39:42,399 - INFO - joeynmt.training - Example #0
2025-05-29 19:39:42,399 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:39:42,399 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:39:42,399 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'mich', 'ge@@', 'frag@@', 't,', 'was', 'ich', 'tun', 'm@@', '<unk>', 'ss@@', 'en,', 'was', 'ich', 'in', 'der', 'L@@', 'age', 'der', 'S@@', 'tra@@', '<unk>', 'e', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:39:42,399 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:39:42,399 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:39:42,399 - INFO - joeynmt.training - 	Hypothesis: Und ich habe mich gefragt, was ich tun m<unk> ssen, was ich in der Lage der Stra<unk> e zu erreichen.
2025-05-29 19:39:42,399 - INFO - joeynmt.training - Example #1
2025-05-29 19:39:42,399 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:39:42,399 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:39:42,399 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'die', 'S@@', 'o@@', 'ft@@', 'w@@', 'are', 'der', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'S@@', 'o@@', 'ft@@', 'w@@', 'are', 'der', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:39:42,400 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:39:42,400 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:39:42,400 - INFO - joeynmt.training - 	Hypothesis: Und das ist die Software der K<unk> rper und die Software der K<unk> rper zu ver<unk> ndern.
2025-05-29 19:39:42,400 - INFO - joeynmt.training - Example #2
2025-05-29 19:39:42,400 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:39:42,400 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:39:42,400 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'mich', 'ge@@', 'frag@@', 't,', 'was', 'ich', 'tun', 'soll@@', 'te,', 'und', 'ich', 'habe', 'es', 'in', 'der', 'L@@', 'age', 'der', 'S@@', 'tra@@', '<unk>', 'e', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:39:42,400 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:39:42,400 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:39:42,400 - INFO - joeynmt.training - 	Hypothesis: Und ich habe mich gefragt, was ich tun sollte, und ich habe es in der Lage der Stra<unk> e zu erreichen.
2025-05-29 19:39:42,400 - INFO - joeynmt.training - Example #3
2025-05-29 19:39:42,400 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:39:42,400 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:39:42,400 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'es', 'in', 'der', 'L@@', 'age', 'der', 'S@@', 'tra@@', '<unk>', 'e', 'und', 'ich', 'habe', 'es', 'in', 'der', 'L@@', 'age', 'der', 'S@@', 'tra@@', '<unk>', 'e', 'und', 'ich', 'habe', 'es', 'in', 'der', 'L@@', 'u@@', 'ft', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'und', 'ich', 'bin', 'mir', 'nicht', 'so', 'g@@', 'ro@@', '<unk>', 'ar@@', 'tig@@', '.', '</s>']
2025-05-29 19:39:42,400 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:39:42,400 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:39:42,400 - INFO - joeynmt.training - 	Hypothesis: Und ich habe es in der Lage der Stra<unk> e und ich habe es in der Lage der Stra<unk> e und ich habe es in der Luft zu verwenden, und ich bin mir nicht so gro<unk> artig.
2025-05-29 19:39:42,401 - INFO - joeynmt.training - Example #4
2025-05-29 19:39:42,401 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:39:42,401 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:39:42,401 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'Ihnen', 'ein', 'paar', 'Bei@@', 'spiel@@', 'e', 'von', 'einem', 'H@@', 'aus@@', ',', 'und', 'ich', 'habe', 'mich', 'ge@@', 'frag@@', 't,', 'was', 'ich', 'tun', 'soll@@', 'te,', '</s>']
2025-05-29 19:39:42,401 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:39:42,401 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:39:42,401 - INFO - joeynmt.training - 	Hypothesis: Und ich habe Ihnen ein paar Beispiele von einem Haus, und ich habe mich gefragt, was ich tun sollte,
2025-05-29 19:39:45,740 - INFO - joeynmt.training - Epoch   6, Step:    28100, Batch Loss:     2.387295, Batch Acc: 0.307499, Tokens per Sec:    21071, Lr: 0.000300
2025-05-29 19:39:47,997 - INFO - joeynmt.training - Epoch   6, Step:    28200, Batch Loss:     2.272115, Batch Acc: 0.309174, Tokens per Sec:    31537, Lr: 0.000300
2025-05-29 19:39:50,282 - INFO - joeynmt.training - Epoch   6, Step:    28300, Batch Loss:     2.235255, Batch Acc: 0.307089, Tokens per Sec:    30742, Lr: 0.000300
2025-05-29 19:39:52,493 - INFO - joeynmt.training - Epoch   6, Step:    28400, Batch Loss:     2.240976, Batch Acc: 0.309410, Tokens per Sec:    31685, Lr: 0.000300
2025-05-29 19:39:54,599 - INFO - joeynmt.training - Epoch   6, Step:    28500, Batch Loss:     2.224713, Batch Acc: 0.306451, Tokens per Sec:    34283, Lr: 0.000300
2025-05-29 19:39:54,599 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:39:54,599 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:40:09,588 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.26, ppl:   9.58, acc:   0.32, generation: 14.9737[sec], evaluation: 0.0000[sec]
2025-05-29 19:40:09,588 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:40:09,667 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/25000.ckpt
2025-05-29 19:40:09,674 - INFO - joeynmt.training - Example #0
2025-05-29 19:40:09,674 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:40:09,674 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:40:09,674 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'die', 'L@@', '<unk>', 'n@@', 'der@@', ',', 'die', 'ich', 'in', 'der', 'L@@', 'age', 'der', 'S@@', 'tra@@', '<unk>', 'e', 'und', 'die', 'L@@', '<unk>', 'n@@', 'der@@', ',', 'die', 'S@@', 'itu@@', 'ation', 'von', 'der', 'S@@', 'tra@@', '<unk>', 'e', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'um', 'die', 'Welt', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n,', 'die', 'die', 'L@@', '<unk>', 'n@@', 'der@@', 'n', 'und', 'die', 'L@@', '<unk>', 'n@@', 'der@@', 'n', 'der', 'Welt', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n,', 'die', 'die', 'in', 'der', 'L@@', 'age', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'die', 'sie', 'in', 'den', 'U@@', 'S@@', 'A', 'und', 'die', 'S@@', 'tra@@', '<unk>', 'e', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'um', 'die', '<unk>', 'ber', 'die', 'Welt', 'zu', 'ver@@', '<unk>', 'n@@']
2025-05-29 19:40:09,675 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:40:09,675 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:40:09,675 - INFO - joeynmt.training - 	Hypothesis: Und ich habe die L<unk> nder, die ich in der Lage der Stra<unk> e und die L<unk> nder, die Situation von der Stra<unk> e zu verwenden, um die Welt zu ver<unk> ndern, die die L<unk> ndern und die L<unk> ndern der Welt zu ver<unk> ndern, die die in der Lage zu verwenden, die sie in den USA und die Stra<unk> e zu verwenden, um die <unk> ber die Welt zu ver<unk> n
2025-05-29 19:40:09,675 - INFO - joeynmt.training - Example #1
2025-05-29 19:40:09,675 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:40:09,675 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:40:09,675 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'sag@@', 'e', 'mi@@', 'r,', 'dass', 'die', 'L@@', '<unk>', 'n@@', 'der@@', 'n', 'nicht', 'nur', 'die', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'die', 'nicht', 'nur', 'die', 'K@@', 'om@@', 'pl@@', 'ex@@', 'it@@', '<unk>', 't', 'der', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:40:09,675 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:40:09,675 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:40:09,675 - INFO - joeynmt.training - 	Hypothesis: Und ich sage mir, dass die L<unk> ndern nicht nur die K<unk> rper, die nicht nur die Komplexit<unk> t der K<unk> rper zu ver<unk> ndern.
2025-05-29 19:40:09,675 - INFO - joeynmt.training - Example #2
2025-05-29 19:40:09,675 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:40:09,675 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:40:09,675 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'ein', 'paar', 'T@@', 'age', 'in', 'einem', 'P@@', 'lan@@', 'eten', 'in', 'der', 'L@@', 'age', 'ver@@', '<unk>', 'n@@', 'der@@', 'n', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'die', 'wir', 'in', 'der', 'Welt', 'ver@@', '<unk>', 'n@@', 'der@@', 'n', 'k@@', '<unk>', 'n@@', 'n@@', 'en.', '</s>']
2025-05-29 19:40:09,676 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:40:09,676 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:40:09,676 - INFO - joeynmt.training - 	Hypothesis: Und ich habe ein paar Tage in einem Planeten in der Lage ver<unk> ndern und die K<unk> rper, die wir in der Welt ver<unk> ndern k<unk> nnen.
2025-05-29 19:40:09,676 - INFO - joeynmt.training - Example #3
2025-05-29 19:40:09,676 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:40:09,676 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:40:09,676 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Sie', 'haben', 'die', 'K@@', 'om@@', 'pl@@', 'ex@@', 'it@@', '<unk>', 't', 'und', 'sie', 'haben', 'die', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'die', 'wir', 'in', 'der', 'L@@', 'age', 'ver@@', 'st@@', '<unk>', 'r@@', 'k@@', 't.', '</s>']
2025-05-29 19:40:09,676 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:40:09,676 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:40:09,676 - INFO - joeynmt.training - 	Hypothesis: Sie haben die Komplexit<unk> t und sie haben die K<unk> rper, die wir in der Lage verst<unk> rkt.
2025-05-29 19:40:09,676 - INFO - joeynmt.training - Example #4
2025-05-29 19:40:09,676 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:40:09,676 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:40:09,676 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'die', 'L@@', '<unk>', 'n@@', 'der@@', ',', 'die', 'ich', 'in', 'der', 'L@@', 'age', 'f@@', '<unk>', 'r', 'die', 'L@@', '<unk>', 'n@@', 'der@@', ',', 'die', 'ich', 'in', 'der', 'L@@', 'age', 'f@@', '<unk>', 'r', 'die', 'S@@', 'ei@@', 'te', 'der', 'Welt', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:40:09,677 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:40:09,677 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:40:09,677 - INFO - joeynmt.training - 	Hypothesis: Und ich habe die L<unk> nder, die ich in der Lage f<unk> r die L<unk> nder, die ich in der Lage f<unk> r die Seite der Welt zu ver<unk> ndern.
2025-05-29 19:40:12,036 - INFO - joeynmt.training - Epoch   6, Step:    28600, Batch Loss:     2.221758, Batch Acc: 0.306257, Tokens per Sec:    28595, Lr: 0.000300
2025-05-29 19:40:14,406 - INFO - joeynmt.training - Epoch   6, Step:    28700, Batch Loss:     2.307476, Batch Acc: 0.309318, Tokens per Sec:    29445, Lr: 0.000300
2025-05-29 19:40:17,561 - INFO - joeynmt.training - Epoch   6, Step:    28800, Batch Loss:     2.265347, Batch Acc: 0.308632, Tokens per Sec:    22713, Lr: 0.000300
2025-05-29 19:40:19,682 - INFO - joeynmt.training - Epoch   6, Step:    28900, Batch Loss:     2.272660, Batch Acc: 0.305806, Tokens per Sec:    33756, Lr: 0.000300
2025-05-29 19:40:21,826 - INFO - joeynmt.training - Epoch   6, Step:    29000, Batch Loss:     2.228930, Batch Acc: 0.307327, Tokens per Sec:    32383, Lr: 0.000300
2025-05-29 19:40:21,826 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:40:21,826 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:40:35,759 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.26, ppl:   9.59, acc:   0.32, generation: 13.9215[sec], evaluation: 0.0000[sec]
2025-05-29 19:40:35,841 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/26000.ckpt
2025-05-29 19:40:35,846 - INFO - joeynmt.training - Example #0
2025-05-29 19:40:35,847 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:40:35,847 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:40:35,847 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'mir', 'ge@@', 'zeig@@', 't,', 'dass', 'ich', 'Ihnen', 'ein', 'paar', 'Bei@@', 'spiel@@', 'e', 'von', '1@@', '0@@', '0@@', '.000', 'D@@', 'oll@@', 'ar', 'zu', 'er@@', 'rei@@', 'chen,', 'und', 'ich', 'habe', 'es', 'in', 'der', 'Welt', 'zu', 'er@@', 'rei@@', 'chen,', 'und', 'ich', 'habe', 'es', 'in', 'der', 'Welt', 'ver@@', '<unk>', 'n@@', 'der@@', 't', 'und', 'es', 'in', 'der', 'Welt', 'zu', 'er@@', 'rei@@', 'chen,', 'und', 'ich', 'da@@', 'chte', 'mi@@', 'r,', 'dass', 'ich', 'in', 'der', 'Welt', 'in', 'der', 'Welt', 'ver@@', '<unk>', 'n@@', 'der@@', 't', 'hab@@', 'e.', '</s>']
2025-05-29 19:40:35,847 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:40:35,847 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:40:35,847 - INFO - joeynmt.training - 	Hypothesis: Und ich habe mir gezeigt, dass ich Ihnen ein paar Beispiele von 100.000 Dollar zu erreichen, und ich habe es in der Welt zu erreichen, und ich habe es in der Welt ver<unk> ndert und es in der Welt zu erreichen, und ich dachte mir, dass ich in der Welt in der Welt ver<unk> ndert habe.
2025-05-29 19:40:35,847 - INFO - joeynmt.training - Example #1
2025-05-29 19:40:35,847 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:40:35,847 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:40:35,847 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'ein', 'sehr', 'sch@@', 'wi@@', 'er@@', 'ig@@', 'es', 'Bei@@', 'spi@@', 'el', 'der', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'der', 'die', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'die', 'nicht', 'nur', 'f@@', '<unk>', 'r', 'die', 'K@@', '<unk>', 'r@@', 'per@@', 's', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'K@@', '<unk>', 'r@@', 'per@@', 'lich@@', 'keit', 'der', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'die', 'sie', 'nicht', 'ein@@', 'mal', 'in', 'der', 'Welt', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:40:35,847 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:40:35,847 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:40:35,847 - INFO - joeynmt.training - 	Hypothesis: Und das ist ein sehr schwieriges Beispiel der K<unk> rper, der die K<unk> rper, die nicht nur f<unk> r die K<unk> rpers und die M<unk> glichkeit der K<unk> rperlichkeit der K<unk> rper, die sie nicht einmal in der Welt zu erreichen.
2025-05-29 19:40:35,848 - INFO - joeynmt.training - Example #2
2025-05-29 19:40:35,848 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:40:35,848 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:40:35,848 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Das', 'ist', 'ein', 'g@@', 'ro@@', '<unk>', 'ar@@', 'tig@@', 'es', 'Bei@@', 'spi@@', 'el', 'f@@', '<unk>', 'r', 'die', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'der', 'die', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'die', 'wir', 'in', 'der', 'Welt', 'in', 'der', 'Welt', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:40:35,848 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:40:35,848 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:40:35,848 - INFO - joeynmt.training - 	Hypothesis: Das ist ein gro<unk> artiges Beispiel f<unk> r die K<unk> rper, der die K<unk> rper, die wir in der Welt in der Welt zu erreichen.
2025-05-29 19:40:35,848 - INFO - joeynmt.training - Example #3
2025-05-29 19:40:35,848 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:40:35,848 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:40:35,848 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'es', 'in', 'der', 'L@@', 'u@@', 'ft', 'und', 'ich', 'habe', 'mich', 'ge@@', 'zeig@@', 't,', 'dass', 'ich', 'das', 'Leben', 'in', 'der', 'L@@', 'u@@', 'ft', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'die', 'wir', 'in', 'der', 'Welt', 'ver@@', '<unk>', 'n@@', 'der@@', 't', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per@@', 'lich@@', 'keit', 'der', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'die', 'sie', 'in', 'den', 'U@@', 'S@@', 'A', 'und', 'der', 'K@@', '<unk>', 'r@@', 'per@@', 't@@', 'es', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:40:35,848 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:40:35,848 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:40:35,848 - INFO - joeynmt.training - 	Hypothesis: Und ich habe es in der Luft und ich habe mich gezeigt, dass ich das Leben in der Luft und die M<unk> glichkeit der K<unk> rper, die wir in der Welt ver<unk> ndert und die K<unk> rperlichkeit der K<unk> rper, die sie in den USA und der K<unk> rpertes zu erreichen.
2025-05-29 19:40:35,848 - INFO - joeynmt.training - Example #4
2025-05-29 19:40:35,848 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:40:35,848 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:40:35,848 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Das', 'ist', 'ein', 'g@@', 'ro@@', '<unk>', 'ar@@', 'tig@@', 'es', 'Bei@@', 'spi@@', 'el', 'f@@', '<unk>', 'r', 'die', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'die', 'ich', 'Ihnen', 'heute', 'zeig@@', 'en,', 'wie', 'ich', 'es', 'in', 'der', 'Welt', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:40:35,849 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:40:35,849 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:40:35,849 - INFO - joeynmt.training - 	Hypothesis: Das ist ein gro<unk> artiges Beispiel f<unk> r die K<unk> rper, die ich Ihnen heute zeigen, wie ich es in der Welt zu erreichen.
2025-05-29 19:40:38,035 - INFO - joeynmt.training - Epoch   6, Step:    29100, Batch Loss:     2.220735, Batch Acc: 0.313319, Tokens per Sec:    31019, Lr: 0.000300
2025-05-29 19:40:40,166 - INFO - joeynmt.training - Epoch   6, Step:    29200, Batch Loss:     2.209501, Batch Acc: 0.306252, Tokens per Sec:    32414, Lr: 0.000300
2025-05-29 19:40:42,164 - INFO - joeynmt.training - Epoch   6, Step:    29300, Batch Loss:     2.333719, Batch Acc: 0.306272, Tokens per Sec:    34547, Lr: 0.000300
2025-05-29 19:40:44,273 - INFO - joeynmt.training - Epoch   6, Step:    29400, Batch Loss:     2.158504, Batch Acc: 0.310841, Tokens per Sec:    33922, Lr: 0.000300
2025-05-29 19:40:46,603 - INFO - joeynmt.training - Epoch   6, Step:    29500, Batch Loss:     2.384371, Batch Acc: 0.309792, Tokens per Sec:    30424, Lr: 0.000300
2025-05-29 19:40:46,603 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:40:46,604 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:40:59,440 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.26, ppl:   9.56, acc:   0.32, generation: 12.8255[sec], evaluation: 0.0000[sec]
2025-05-29 19:40:59,440 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:40:59,525 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/26500.ckpt
2025-05-29 19:40:59,531 - INFO - joeynmt.training - Example #0
2025-05-29 19:40:59,531 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:40:59,531 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:40:59,531 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'und', 'ich', 'habe', 'es', 'in', 'der', 'L@@', 'u@@', 'ft', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'um', 'die', 'Welt', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:40:59,532 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:40:59,532 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:40:59,532 - INFO - joeynmt.training - 	Hypothesis: Ich habe ein paar Minuten und ich habe es in der Luft zu verwenden, um die Welt zu erreichen.
2025-05-29 19:40:59,532 - INFO - joeynmt.training - Example #1
2025-05-29 19:40:59,532 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:40:59,532 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:40:59,532 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'es', 'in', 'der', 'L@@', 'u@@', 'ft', 'der', 'B@@', '<unk>', 'h@@', 'n@@', 'e,', 'die', 'ich', 'nicht', 'ver@@', 'w@@', 'end@@', 'et,', 'dass', 'es', 'nicht', 'nur', 'die', 'K@@', '<unk>', 'n@@', 'st@@', 'ler', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'zu', 'ver@@', 'w@@', 'end@@', 'en.', '</s>']
2025-05-29 19:40:59,532 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:40:59,532 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:40:59,532 - INFO - joeynmt.training - 	Hypothesis: Und ich habe es in der Luft der B<unk> hne, die ich nicht verwendet, dass es nicht nur die K<unk> nstler und die M<unk> glichkeiten zu verwenden.
2025-05-29 19:40:59,532 - INFO - joeynmt.training - Example #2
2025-05-29 19:40:59,532 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:40:59,532 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:40:59,532 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'S@@', 'ter@@', 'ne', 'ist', 'die', 'K@@', 'l@@', 'ein@@', 'k@@', 'r@@', '<unk>', 'f@@', 'te', 'der', 'K@@', 'l@@', 'ein@@', 'k@@', 'r@@', '<unk>', 'f@@', 'te', 'der', 'Welt', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:40:59,533 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:40:59,533 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:40:59,533 - INFO - joeynmt.training - 	Hypothesis: Die Sterne ist die Kleinkr<unk> fte der Kleinkr<unk> fte der Welt zu ver<unk> ndern.
2025-05-29 19:40:59,533 - INFO - joeynmt.training - Example #3
2025-05-29 19:40:59,533 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:40:59,533 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:40:59,533 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'eine', 'sehr', 'sch@@', 'wi@@', 'eri@@', 'g', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'und', 'die', 'K@@', '<unk>', 'n@@', 'st@@', 'ler', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'die', 'die', 'sich', 'in', 'die', 'L@@', 'u@@', 'ft', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'die', 'die', 'sich', '<unk>', 'ber@@', 'ra@@', 'sch@@', 'en@@', 'k@@', 'en.', '</s>']
2025-05-29 19:40:59,533 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:40:59,533 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:40:59,533 - INFO - joeynmt.training - 	Hypothesis: Es ist eine sehr schwierig und die M<unk> glichkeiten und die K<unk> nstler und die K<unk> rper zu verwenden, die die sich in die Luft zu verwenden, die die sich <unk> berraschenken.
2025-05-29 19:40:59,533 - INFO - joeynmt.training - Example #4
2025-05-29 19:40:59,533 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:40:59,533 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:40:59,533 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'mei@@', 'sten', 'von', 'uns', 'haben', 'wir', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'ver@@', 'r@@', '<unk>', 'ck@@', 't', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'die', 'ich', 'in', 'der', 'Welt', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:40:59,533 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:40:59,533 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:40:59,533 - INFO - joeynmt.training - 	Hypothesis: Die meisten von uns haben wir die M<unk> glichkeiten verr<unk> ckt und die M<unk> glichkeiten zu verwenden, die ich in der Welt zu ver<unk> ndern.
2025-05-29 19:41:01,885 - INFO - joeynmt.training - Epoch   6, Step:    29600, Batch Loss:     2.213308, Batch Acc: 0.311584, Tokens per Sec:    30021, Lr: 0.000300
2025-05-29 19:41:04,165 - INFO - joeynmt.training - Epoch   6, Step:    29700, Batch Loss:     2.234059, Batch Acc: 0.305046, Tokens per Sec:    30837, Lr: 0.000300
2025-05-29 19:41:06,551 - INFO - joeynmt.training - Epoch   6, Step:    29800, Batch Loss:     2.256106, Batch Acc: 0.314514, Tokens per Sec:    29473, Lr: 0.000300
2025-05-29 19:41:09,046 - INFO - joeynmt.training - Epoch   6, Step:    29900, Batch Loss:     2.229866, Batch Acc: 0.308822, Tokens per Sec:    28816, Lr: 0.000300
2025-05-29 19:41:11,673 - INFO - joeynmt.training - Epoch   6, Step:    30000, Batch Loss:     2.415798, Batch Acc: 0.310426, Tokens per Sec:    26646, Lr: 0.000300
2025-05-29 19:41:11,673 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:41:11,673 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:41:27,451 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.25, ppl:   9.53, acc:   0.32, generation: 15.7630[sec], evaluation: 0.0000[sec]
2025-05-29 19:41:27,451 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:41:27,531 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/27500.ckpt
2025-05-29 19:41:27,537 - INFO - joeynmt.training - Example #0
2025-05-29 19:41:27,537 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:41:27,537 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:41:27,537 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'das', 'er@@', 'ste', 'M@@', 'al', 'in', 'der', 'L@@', 'age', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'die', 'ich', 'in', 'den', 'letz@@', 'ten', '1@@', '0@@', '0@@', 'ern', 'und', '1@@', '0@@', '0@@', '.000', 'D@@', 'oll@@', 'ar', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'und', 'das', 'ist', 'ein', 'sehr', 'sch@@', 'le@@', 'cht@@', 'es', 'M@@', '<unk>', 'd@@', 'chen', 'in', 'der', 'L@@', 'age', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'die', 'in', 'den', '19@@', '8@@', '0@@', 'ern', 'in', 'der', 'Welt', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:41:27,537 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:41:27,537 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:41:27,537 - INFO - joeynmt.training - 	Hypothesis: Und ich habe das erste Mal in der Lage zu verwenden, die ich in den letzten 100ern und 100.000 Dollar zu verwenden, und das ist ein sehr schlechtes M<unk> dchen in der Lage zu verwenden, die in den 1980ern in der Welt zu ver<unk> ndern.
2025-05-29 19:41:27,537 - INFO - joeynmt.training - Example #1
2025-05-29 19:41:27,538 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:41:27,538 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:41:27,538 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'die', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'die', 'wir', 'in', 'den', 'K@@', 'op@@', 'f', 'der', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'des', 'K@@', '<unk>', 'r@@', 'per@@', 's', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per@@', 's', 'f@@', '<unk>', 'r', 'die', 'K@@', '<unk>', 'r@@', 'per@@', 's', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'die', 'wir', 'nicht', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:41:27,538 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:41:27,538 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:41:27,538 - INFO - joeynmt.training - 	Hypothesis: Und das ist die K<unk> rper, die wir in den Kopf der K<unk> rper und die M<unk> glichkeit des K<unk> rpers und die K<unk> rpers f<unk> r die K<unk> rpers und die K<unk> rper, die wir nicht ver<unk> ndern.
2025-05-29 19:41:27,538 - INFO - joeynmt.training - Example #2
2025-05-29 19:41:27,538 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:41:27,538 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:41:27,538 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'ein', 'sehr', 'sch@@', 'le@@', 'cht@@', 'es', 'M@@', 'at@@', 'eri@@', 'al', 'in', 'der', 'L@@', 'age', 'der', 'K@@', 'at@@', 'z@@', 'en@@', 'z', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'und', 'das', 'ist', 'ein', 'sehr', 'sch@@', 'le@@', 'cht@@', 'er', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'die', 'sich', 'in', 'der', 'Welt', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:41:27,538 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:41:27,538 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:41:27,538 - INFO - joeynmt.training - 	Hypothesis: Und das ist ein sehr schlechtes Material in der Lage der Katzenz zu verwenden, und das ist ein sehr schlechter und die M<unk> glichkeit der K<unk> rper zu verwenden, die sich in der Welt zu ver<unk> ndern.
2025-05-29 19:41:27,538 - INFO - joeynmt.training - Example #3
2025-05-29 19:41:27,538 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:41:27,538 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:41:27,538 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'die', 'K@@', 'ar@@', 'te', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'und', 'die', 'K@@', 'ar@@', 'te', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'die', 'sich', '<unk>', 'ber@@', 'all', 'auf', 'der', 'Welt', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:41:27,539 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:41:27,539 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:41:27,539 - INFO - joeynmt.training - 	Hypothesis: Und das ist die Karte und die M<unk> glichkeit der K<unk> rper und die M<unk> glichkeit der K<unk> rper zu verwenden, und die Karte zu verwenden, die sich <unk> berall auf der Welt zu ver<unk> ndern.
2025-05-29 19:41:27,539 - INFO - joeynmt.training - Example #4
2025-05-29 19:41:27,539 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:41:27,539 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:41:27,539 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'die', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'aber', 'es', 'ist', 'nicht', 'nur', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 't,', 'die', 'ich', 'Ihnen', 'zeig@@', 'en,', 'wie', 'ich', 'das', 'Leben', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:41:27,539 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:41:27,539 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:41:27,539 - INFO - joeynmt.training - 	Hypothesis: Und das ist die K<unk> rper, aber es ist nicht nur ein paar Minuten und die M<unk> glichkeit, die ich Ihnen zeigen, wie ich das Leben zu ver<unk> ndern.
2025-05-29 19:41:29,897 - INFO - joeynmt.training - Epoch   6, Step:    30100, Batch Loss:     2.290053, Batch Acc: 0.305444, Tokens per Sec:    28052, Lr: 0.000300
2025-05-29 19:41:32,449 - INFO - joeynmt.training - Epoch   6, Step:    30200, Batch Loss:     2.208304, Batch Acc: 0.309044, Tokens per Sec:    28172, Lr: 0.000300
2025-05-29 19:41:34,767 - INFO - joeynmt.training - Epoch   6, Step:    30300, Batch Loss:     2.268052, Batch Acc: 0.309082, Tokens per Sec:    29803, Lr: 0.000300
2025-05-29 19:41:36,675 - INFO - joeynmt.training - Epoch   6, Step:    30400, Batch Loss:     2.218512, Batch Acc: 0.312669, Tokens per Sec:    36931, Lr: 0.000300
2025-05-29 19:41:38,482 - INFO - joeynmt.training - Epoch   6, Step:    30500, Batch Loss:     2.408583, Batch Acc: 0.308098, Tokens per Sec:    40777, Lr: 0.000300
2025-05-29 19:41:38,482 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:41:38,482 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:41:49,444 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.25, ppl:   9.51, acc:   0.32, generation: 10.9523[sec], evaluation: 0.0000[sec]
2025-05-29 19:41:49,444 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:41:49,522 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/28000.ckpt
2025-05-29 19:41:49,527 - INFO - joeynmt.training - Example #0
2025-05-29 19:41:49,528 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:41:49,528 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:41:49,528 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'es', 'in', 'der', 'L@@', 'age', 'ges@@', 'ag@@', 't,', 'dass', 'ich', 'das', 'Leben', 'in', 'der', 'L@@', 'age', 'der', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:41:49,528 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:41:49,528 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:41:49,528 - INFO - joeynmt.training - 	Hypothesis: Und ich habe es in der Lage gesagt, dass ich das Leben in der Lage der K<unk> rper und die M<unk> glichkeit der K<unk> rper zu ver<unk> ndern.
2025-05-29 19:41:49,528 - INFO - joeynmt.training - Example #1
2025-05-29 19:41:49,528 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:41:49,528 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:41:49,528 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'es', 'in', 'der', 'L@@', 'age', 'der', 'M@@', '<unk>', 'd@@', 'chen', 'in', 'der', 'L@@', 'age', 'der', 'L@@', 'u@@', 'ft', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:41:49,528 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:41:49,528 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:41:49,528 - INFO - joeynmt.training - 	Hypothesis: Und ich habe es in der Lage der M<unk> dchen in der Lage der Luft zu erreichen.
2025-05-29 19:41:49,528 - INFO - joeynmt.training - Example #2
2025-05-29 19:41:49,528 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:41:49,528 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:41:49,528 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Das', 'ist', 'ein', 'M@@', 'at@@', 'eri@@', 'al', 'f@@', '<unk>', 'r', 'die', 'K@@', 'at@@', 'z@@', 'e', 'der', 'K@@', 'at@@', 'z@@', 'e', 'in', 'der', 'L@@', 'age', 'f@@', '<unk>', 'r', 'die', 'K@@', 'at@@', 'z@@', 'e', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:41:49,529 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:41:49,529 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:41:49,529 - INFO - joeynmt.training - 	Hypothesis: Das ist ein Material f<unk> r die Katze der Katze in der Lage f<unk> r die Katze zu erreichen.
2025-05-29 19:41:49,529 - INFO - joeynmt.training - Example #3
2025-05-29 19:41:49,529 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:41:49,529 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:41:49,529 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'es', 'in', 'der', 'L@@', 'age', 'ges@@', 'ag@@', 't,', 'dass', 'ich', 'das', 'Leben', 'in', 'der', 'L@@', 'u@@', 'ft', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:41:49,529 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:41:49,529 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:41:49,529 - INFO - joeynmt.training - 	Hypothesis: Und ich habe es in der Lage gesagt, dass ich das Leben in der Luft zu erreichen.
2025-05-29 19:41:49,529 - INFO - joeynmt.training - Example #4
2025-05-29 19:41:49,529 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:41:49,529 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:41:49,529 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'einen', 'K@@', 'op@@', 'f', 'von', 'einem', 'K@@', 'op@@', 'f', 'von', 'einem', 'K@@', 'op@@', 'f', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:41:49,529 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:41:49,529 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:41:49,529 - INFO - joeynmt.training - 	Hypothesis: Und ich habe einen Kopf von einem Kopf von einem Kopf zu ver<unk> ndern.
2025-05-29 19:41:51,613 - INFO - joeynmt.training - Epoch   6, Step:    30600, Batch Loss:     2.280008, Batch Acc: 0.307377, Tokens per Sec:    31953, Lr: 0.000300
2025-05-29 19:41:53,739 - INFO - joeynmt.training - Epoch   6, Step:    30700, Batch Loss:     2.132604, Batch Acc: 0.310338, Tokens per Sec:    32363, Lr: 0.000300
2025-05-29 19:41:55,761 - INFO - joeynmt.training - Epoch   6, Step:    30800, Batch Loss:     2.235874, Batch Acc: 0.310844, Tokens per Sec:    34798, Lr: 0.000300
2025-05-29 19:41:58,864 - INFO - joeynmt.training - Epoch   6, Step:    30900, Batch Loss:     2.195456, Batch Acc: 0.310934, Tokens per Sec:    22817, Lr: 0.000300
2025-05-29 19:42:00,896 - INFO - joeynmt.training - Epoch   6, Step:    31000, Batch Loss:     2.268892, Batch Acc: 0.311821, Tokens per Sec:    34405, Lr: 0.000300
2025-05-29 19:42:00,897 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:42:00,897 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:42:11,018 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.25, ppl:   9.50, acc:   0.32, generation: 10.1138[sec], evaluation: 0.0000[sec]
2025-05-29 19:42:11,019 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:42:11,102 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/29000.ckpt
2025-05-29 19:42:11,108 - INFO - joeynmt.training - Example #0
2025-05-29 19:42:11,108 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:42:11,109 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:42:11,109 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'eine', 'M@@', 'ut@@', 'ter', 'und', 'ich', 'habe', 'eine', 'M@@', 'ut@@', 'ter', 'und', 'ich', 'm@@', '<unk>', 'chte', 'mich', 'in', 'der', 'L@@', 'age', 'der', 'L@@', 'age', 'der', 'S@@', 'tra@@', '<unk>', 'e', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:42:11,109 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:42:11,109 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:42:11,109 - INFO - joeynmt.training - 	Hypothesis: Und ich habe eine Mutter und ich habe eine Mutter und ich m<unk> chte mich in der Lage der Lage der Stra<unk> e zu erreichen.
2025-05-29 19:42:11,109 - INFO - joeynmt.training - Example #1
2025-05-29 19:42:11,109 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:42:11,109 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:42:11,109 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'ein', 'sehr', 'sch@@', 'wi@@', 'eri@@', 'g', 'f@@', '<unk>', 'r', 'die', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'die', 'wir', 'nicht', 'nur', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:42:11,109 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:42:11,109 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:42:11,109 - INFO - joeynmt.training - 	Hypothesis: Und das ist ein sehr schwierig f<unk> r die K<unk> rper, die wir nicht nur die K<unk> rper zu ver<unk> ndern.
2025-05-29 19:42:11,109 - INFO - joeynmt.training - Example #2
2025-05-29 19:42:11,109 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:42:11,109 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:42:11,109 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'ein', 'sehr', '<unk>', 'h@@', 'n@@', 'lich@@', 'es', 'Pro@@', 'bl@@', 'em', 'ist,', 'dass', 'es', 'nicht', 'nur', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'und', 'die', 'K@@', 'at@@', 'a@@', 'str@@', 'op@@', 'h@@', 'e', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:42:11,110 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:42:11,110 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:42:11,110 - INFO - joeynmt.training - 	Hypothesis: Und das ist ein sehr <unk> hnliches Problem ist, dass es nicht nur ein paar Minuten und die Katastrophe zu ver<unk> ndern.
2025-05-29 19:42:11,110 - INFO - joeynmt.training - Example #3
2025-05-29 19:42:11,110 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:42:11,110 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:42:11,110 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'die', 'wir', 'in', 'der', 'Welt', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:42:11,110 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:42:11,110 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:42:11,110 - INFO - joeynmt.training - 	Hypothesis: Es ist ein paar Minuten und die M<unk> glichkeiten und die K<unk> rper, die wir in der Welt zu ver<unk> ndern.
2025-05-29 19:42:11,110 - INFO - joeynmt.training - Example #4
2025-05-29 19:42:11,110 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:42:11,110 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:42:11,110 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'ein', 'sehr', 'sch@@', 'wi@@', 'er@@', 'ig@@', 'es', 'Pro@@', 'bl@@', 'em', 'ist,', 'dass', 'es', 'nicht', 'nur', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'in', 'der', 'L@@', 'age', 'ist.', '</s>']
2025-05-29 19:42:11,110 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:42:11,110 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:42:11,110 - INFO - joeynmt.training - 	Hypothesis: Und das ist ein sehr schwieriges Problem ist, dass es nicht nur ein paar Minuten in der Lage ist.
2025-05-29 19:42:13,332 - INFO - joeynmt.training - Epoch   6, Step:    31100, Batch Loss:     2.198870, Batch Acc: 0.305618, Tokens per Sec:    29634, Lr: 0.000300
2025-05-29 19:42:15,520 - INFO - joeynmt.training - Epoch   6, Step:    31200, Batch Loss:     2.103087, Batch Acc: 0.313987, Tokens per Sec:    32224, Lr: 0.000300
2025-05-29 19:42:17,504 - INFO - joeynmt.training - Epoch   6, Step:    31300, Batch Loss:     2.284295, Batch Acc: 0.308572, Tokens per Sec:    35853, Lr: 0.000300
2025-05-29 19:42:19,511 - INFO - joeynmt.training - Epoch   6, Step:    31400, Batch Loss:     2.290831, Batch Acc: 0.310526, Tokens per Sec:    35594, Lr: 0.000300
2025-05-29 19:42:21,617 - INFO - joeynmt.training - Epoch   6, Step:    31500, Batch Loss:     2.345915, Batch Acc: 0.309031, Tokens per Sec:    33967, Lr: 0.000300
2025-05-29 19:42:21,617 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:42:21,617 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:42:34,667 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.25, ppl:   9.47, acc:   0.32, generation: 13.0390[sec], evaluation: 0.0000[sec]
2025-05-29 19:42:34,667 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:42:34,751 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/28500.ckpt
2025-05-29 19:42:34,756 - INFO - joeynmt.training - Example #0
2025-05-29 19:42:34,757 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:42:34,757 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:42:34,757 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'mich', 'ge@@', 'frag@@', 't', 'und', 'ich', 'habe', 'es', 'in', 'der', 'L@@', 'age', 'der', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'die', 'ich', 'in', 'den', 'letz@@', 'ten', '1@@', '0@@', 'ern', 'und', '1@@', '0@@', 'ern', 'in', 'der', 'Welt', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:42:34,757 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:42:34,757 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:42:34,757 - INFO - joeynmt.training - 	Hypothesis: Ich habe mich gefragt und ich habe es in der Lage der K<unk> rper, die ich in den letzten 10ern und 10ern in der Welt zu erreichen.
2025-05-29 19:42:34,757 - INFO - joeynmt.training - Example #1
2025-05-29 19:42:34,757 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:42:34,757 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:42:34,757 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'sag@@', 'e', 'nicht,', 'dass', 'ich', 'nicht', 'nur', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'nicht', 'nur', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'der', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'dass', 'es', 'nicht', 'nur', 'f@@', '<unk>', 'r', 'die', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'die', 'ich', 'nicht', 'nur', 'f@@', '<unk>', 'r', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:42:34,757 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:42:34,757 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:42:34,757 - INFO - joeynmt.training - 	Hypothesis: Und ich sage nicht, dass ich nicht nur die M<unk> glichkeiten nicht nur die M<unk> glichkeiten der K<unk> rper, dass es nicht nur f<unk> r die K<unk> rper, die ich nicht nur f<unk> r die M<unk> glichkeiten zu erreichen.
2025-05-29 19:42:34,757 - INFO - joeynmt.training - Example #2
2025-05-29 19:42:34,757 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:42:34,757 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:42:34,758 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Das', 'ist', 'ein', 'sehr', 'einf@@', 'ach@@', 'es', 'Bei@@', 'spiel@@', ',', 'der', 'der', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'der', 'die', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'die', 'die', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'die', 'wir', 'in', 'der', 'Welt', 'ver@@', '<unk>', 'n@@', 'der@@', 'n', 'k@@', '<unk>', 'n@@', 'n@@', 'en.', '</s>']
2025-05-29 19:42:34,758 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:42:34,758 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:42:34,758 - INFO - joeynmt.training - 	Hypothesis: Das ist ein sehr einfaches Beispiel, der der K<unk> rper, der die K<unk> rper, die die K<unk> rper, die wir in der Welt ver<unk> ndern k<unk> nnen.
2025-05-29 19:42:34,758 - INFO - joeynmt.training - Example #3
2025-05-29 19:42:34,758 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:42:34,758 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:42:34,758 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'mich', 'ge@@', 'frag@@', 't', 'und', 'ich', 'sag@@', 'e', 'mich', 'an', 'und', 'ich', 'sag@@', 'te,', '"@@', 'Ich', 'habe', 'es', 'nicht', 'nur', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'und', 'ich', 'sag@@', 'e', 'Ihnen', 'und', 'sag@@', 'te,', '"@@', 'Ich', 'habe', 'es', 'nicht', 'nur', 'f@@', '<unk>', 'r', 'die', 'K@@', 'rank@@', 'heit', 'der', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'dass', 'ich', 'nicht', 'nur', 'f@@', '<unk>', 'r', 'die', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'die', 'die', 'K@@', 'rank@@', 'heit', 'der', 'Welt', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:42:34,758 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:42:34,758 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:42:34,758 - INFO - joeynmt.training - 	Hypothesis: Ich habe mich gefragt und ich sage mich an und ich sagte, "Ich habe es nicht nur ein paar Minuten und ich sage Ihnen und sagte, "Ich habe es nicht nur f<unk> r die Krankheit der K<unk> rper, dass ich nicht nur f<unk> r die K<unk> rper, die die Krankheit der Welt zu erreichen.
2025-05-29 19:42:34,758 - INFO - joeynmt.training - Example #4
2025-05-29 19:42:34,758 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:42:34,758 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:42:34,758 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'sag@@', 'te,', '"@@', 'Ich', 'habe', 'eine', 'M@@', 'en@@', 'ge', 'S@@', 'ei@@', 'te', 'der', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'dass', 'ich', 'nicht', 'nur', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'der', 'Welt', 'ver@@', '<unk>', 'n@@', 'der@@', 'n', 'k@@', '<unk>', 'n@@', 'n@@', 'en.', '</s>']
2025-05-29 19:42:34,758 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:42:34,758 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:42:34,758 - INFO - joeynmt.training - 	Hypothesis: Und ich sagte, "Ich habe eine Menge Seite der K<unk> rper, dass ich nicht nur die M<unk> glichkeiten der Welt ver<unk> ndern k<unk> nnen.
2025-05-29 19:42:36,844 - INFO - joeynmt.training - Epoch   6, Step:    31600, Batch Loss:     2.287998, Batch Acc: 0.309860, Tokens per Sec:    33751, Lr: 0.000300
2025-05-29 19:42:38,777 - INFO - joeynmt.training - Epoch   6, Step:    31700, Batch Loss:     2.277021, Batch Acc: 0.306496, Tokens per Sec:    36303, Lr: 0.000300
2025-05-29 19:42:40,644 - INFO - joeynmt.training - Epoch   6, Step:    31800, Batch Loss:     2.216499, Batch Acc: 0.310740, Tokens per Sec:    37661, Lr: 0.000300
2025-05-29 19:42:42,754 - INFO - joeynmt.training - Epoch   6, Step:    31900, Batch Loss:     2.339850, Batch Acc: 0.309008, Tokens per Sec:    33838, Lr: 0.000300
2025-05-29 19:42:44,816 - INFO - joeynmt.training - Epoch   6, Step:    32000, Batch Loss:     2.311556, Batch Acc: 0.306641, Tokens per Sec:    34232, Lr: 0.000300
2025-05-29 19:42:44,816 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:42:44,816 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:42:58,915 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.25, ppl:   9.46, acc:   0.32, generation: 14.0891[sec], evaluation: 0.0000[sec]
2025-05-29 19:42:58,915 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:42:58,996 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/29500.ckpt
2025-05-29 19:42:59,002 - INFO - joeynmt.training - Example #0
2025-05-29 19:42:59,002 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:42:59,002 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:42:59,002 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'das', 'ges@@', 'ag@@', 't,', 'was', 'ich', 'sag@@', 'te,', '"@@', 'Ich', 'habe', 'das', 'er@@', 'ste', 'M@@', 'al', 'in', 'den', 'letz@@', 'ten', '1@@', '0@@', '0@@', 'ern@@', ',', '1@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '.000', 'D@@', 'oll@@', 'ar', 'f@@', '<unk>', 'r', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'von', '1@@', '0@@', '0@@', '0@@', '.000', 'D@@', 'oll@@', 'ar', 'f@@', '<unk>', 'r', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:42:59,002 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:42:59,003 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:42:59,003 - INFO - joeynmt.training - 	Hypothesis: Und ich habe das gesagt, was ich sagte, "Ich habe das erste Mal in den letzten 100ern, 1000000000.000 Dollar f<unk> r die M<unk> glichkeit von 1000.000 Dollar f<unk> r die M<unk> glichkeit der K<unk> rper zu ver<unk> ndern.
2025-05-29 19:42:59,003 - INFO - joeynmt.training - Example #1
2025-05-29 19:42:59,003 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:42:59,003 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:42:59,003 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'eine', 'M@@', 'en@@', 'ge', 'S@@', 'ach@@', 'e,', 'die', 'wir', 'in', 'der', 'Welt', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:42:59,003 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:42:59,003 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:42:59,003 - INFO - joeynmt.training - 	Hypothesis: Und das ist eine Menge Sache, die wir in der Welt ver<unk> ndern.
2025-05-29 19:42:59,003 - INFO - joeynmt.training - Example #2
2025-05-29 19:42:59,003 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:42:59,003 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:42:59,003 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'ein', 'M@@', 'at@@', 'eri@@', 'al', 'f@@', '<unk>', 'r', 'die', 'M@@', 'at@@', 'h@@', 'em@@', 'ati@@', 'k', 'f@@', '<unk>', 'r', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'M@@', 'at@@', 'h@@', 'em@@', 'ati@@', 'k', 'f@@', '<unk>', 'r', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:42:59,003 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:42:59,003 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:42:59,003 - INFO - joeynmt.training - 	Hypothesis: Und das ist ein Material f<unk> r die Mathematik f<unk> r die K<unk> rper und die Mathematik f<unk> r die K<unk> rper zu ver<unk> ndern.
2025-05-29 19:42:59,003 - INFO - joeynmt.training - Example #3
2025-05-29 19:42:59,003 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:42:59,003 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:42:59,003 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'ein', 'g@@', 'ro@@', '<unk>', 'es', 'Bei@@', 'spi@@', 'el', 'der', 'M@@', 'it@@', 'te', 'der', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', 'w@@', 'andel@@', 'n.', '</s>']
2025-05-29 19:42:59,004 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:42:59,004 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:42:59,004 - INFO - joeynmt.training - 	Hypothesis: Es ist ein gro<unk> es Beispiel der Mitte der K<unk> rper und die K<unk> rper zu verwandeln.
2025-05-29 19:42:59,004 - INFO - joeynmt.training - Example #4
2025-05-29 19:42:59,004 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:42:59,004 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:42:59,004 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'eine', 'M@@', 'en@@', 'ge', 'S@@', 'ach@@', 'e,', 'die', 'ich', 'in', 'den', 'letz@@', 'ten', '1@@', '00', 'Jahren', 'in', 'der', 'Welt', 'ver@@', '<unk>', 'n@@', 'der@@', 'n', 'und', 'dann', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:42:59,004 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:42:59,004 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:42:59,004 - INFO - joeynmt.training - 	Hypothesis: Und das ist eine Menge Sache, die ich in den letzten 100 Jahren in der Welt ver<unk> ndern und dann die M<unk> nnern und die M<unk> glichkeit der K<unk> rper zu ver<unk> ndern.
2025-05-29 19:43:00,373 - INFO - joeynmt.training - Epoch   6: total training loss 11990.55
2025-05-29 19:43:00,373 - INFO - joeynmt.training - EPOCH 7
2025-05-29 19:43:01,130 - INFO - joeynmt.training - Epoch   7, Step:    32100, Batch Loss:     2.192154, Batch Acc: 0.318875, Tokens per Sec:    33634, Lr: 0.000300
2025-05-29 19:43:03,997 - INFO - joeynmt.training - Epoch   7, Step:    32200, Batch Loss:     2.215122, Batch Acc: 0.318767, Tokens per Sec:    24760, Lr: 0.000300
2025-05-29 19:43:05,924 - INFO - joeynmt.training - Epoch   7, Step:    32300, Batch Loss:     2.191077, Batch Acc: 0.315302, Tokens per Sec:    36171, Lr: 0.000300
2025-05-29 19:43:07,775 - INFO - joeynmt.training - Epoch   7, Step:    32400, Batch Loss:     2.253136, Batch Acc: 0.314143, Tokens per Sec:    38017, Lr: 0.000300
2025-05-29 19:43:09,621 - INFO - joeynmt.training - Epoch   7, Step:    32500, Batch Loss:     2.250380, Batch Acc: 0.317960, Tokens per Sec:    38159, Lr: 0.000300
2025-05-29 19:43:09,621 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:43:09,622 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:43:23,462 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.25, ppl:   9.45, acc:   0.32, generation: 13.8289[sec], evaluation: 0.0000[sec]
2025-05-29 19:43:23,462 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:43:23,545 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/30000.ckpt
2025-05-29 19:43:23,551 - INFO - joeynmt.training - Example #0
2025-05-29 19:43:23,551 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:43:23,551 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:43:23,551 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'und', 'ich', 'habe', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'in', 'der', 'L@@', 'age', 'der', 'L@@', 'age', 'der', 'K@@', 'reb@@', 's@@', 'z@@', 'ellen', 'in', 'der', 'L@@', 'age', 'er@@', 'l@@', 'eben', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'Er@@', 'de', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:43:23,551 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:43:23,551 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:43:23,551 - INFO - joeynmt.training - 	Hypothesis: Ich habe ein paar Minuten und ich habe ein paar Minuten in der Lage der Lage der Krebszellen in der Lage erleben und die M<unk> glichkeit der Erde zu erreichen.
2025-05-29 19:43:23,551 - INFO - joeynmt.training - Example #1
2025-05-29 19:43:23,551 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:43:23,551 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:43:23,551 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'ge@@', 'frag@@', 't', 'und', 'ich', 'habe', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:43:23,552 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:43:23,552 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:43:23,552 - INFO - joeynmt.training - 	Hypothesis: Und ich habe ein paar Minuten gefragt und ich habe die M<unk> glichkeit der K<unk> rper zu ver<unk> ndern.
2025-05-29 19:43:23,552 - INFO - joeynmt.training - Example #2
2025-05-29 19:43:23,552 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:43:23,552 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:43:23,552 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Das', 'ist', 'ein', 'g@@', 'ro@@', '<unk>', 'es', 'Bei@@', 'spi@@', 'el', 'in', 'der', 'L@@', 'age', 'der', 'L@@', 'age', 'der', 'H@@', '<unk>', 'l@@', 'f@@', 'te', 'der', 'K@@', 'l@@', 'ini@@', 'k', 'und', 'die', 'M@@', 'at@@', 'h@@', 'em@@', 'ati@@', 'k', 'und', 'die', 'M@@', 'at@@', 'h@@', 'em@@', 'ati@@', 'k', 'und', 'die', 'M@@', 'at@@', 'h@@', 'em@@', 'ati@@', 'k', 'und', 'die', 'M@@', 'at@@', 'h@@', 'em@@', 'ati@@', 'k', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'K@@', 'l@@', 'ini@@', 'k', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:43:23,552 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:43:23,552 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:43:23,552 - INFO - joeynmt.training - 	Hypothesis: Das ist ein gro<unk> es Beispiel in der Lage der Lage der H<unk> lfte der Klinik und die Mathematik und die Mathematik und die Mathematik und die Mathematik und die M<unk> glichkeit der Klinik zu ver<unk> ndern.
2025-05-29 19:43:23,552 - INFO - joeynmt.training - Example #3
2025-05-29 19:43:23,552 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:43:23,552 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:43:23,552 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'ein', 'g@@', 'ro@@', '<unk>', 'es', 'Bei@@', 'spi@@', 'el', 'und', 'der', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', 'k@@', 'auf@@', 'en.', '</s>']
2025-05-29 19:43:23,552 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:43:23,552 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:43:23,552 - INFO - joeynmt.training - 	Hypothesis: Es ist ein gro<unk> es Beispiel und der K<unk> rper zu verkaufen.
2025-05-29 19:43:23,552 - INFO - joeynmt.training - Example #4
2025-05-29 19:43:23,553 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:43:23,553 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:43:23,553 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'mei@@', 'sten', 'von', 'uns', 'haben', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'in', 'der', 'L@@', 'age', 'der', 'S@@', 'tra@@', '<unk>', 'e', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:43:23,553 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:43:23,553 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:43:23,553 - INFO - joeynmt.training - 	Hypothesis: Die meisten von uns haben die M<unk> glichkeit in der Lage der Stra<unk> e und die M<unk> glichkeit der K<unk> rper zu ver<unk> ndern.
2025-05-29 19:43:25,652 - INFO - joeynmt.training - Epoch   7, Step:    32600, Batch Loss:     2.296021, Batch Acc: 0.313778, Tokens per Sec:    32556, Lr: 0.000300
2025-05-29 19:43:27,720 - INFO - joeynmt.training - Epoch   7, Step:    32700, Batch Loss:     2.227684, Batch Acc: 0.317093, Tokens per Sec:    33871, Lr: 0.000300
2025-05-29 19:43:29,767 - INFO - joeynmt.training - Epoch   7, Step:    32800, Batch Loss:     2.096911, Batch Acc: 0.316973, Tokens per Sec:    35414, Lr: 0.000300
2025-05-29 19:43:31,756 - INFO - joeynmt.training - Epoch   7, Step:    32900, Batch Loss:     2.193194, Batch Acc: 0.317505, Tokens per Sec:    34038, Lr: 0.000300
2025-05-29 19:43:33,700 - INFO - joeynmt.training - Epoch   7, Step:    33000, Batch Loss:     2.273494, Batch Acc: 0.312983, Tokens per Sec:    36383, Lr: 0.000300
2025-05-29 19:43:33,701 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:43:33,701 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:43:49,298 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.25, ppl:   9.45, acc:   0.32, generation: 15.5847[sec], evaluation: 0.0000[sec]
2025-05-29 19:43:49,375 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/30500.ckpt
2025-05-29 19:43:49,381 - INFO - joeynmt.training - Example #0
2025-05-29 19:43:49,381 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:43:49,381 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:43:49,382 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'die', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'ich', 'habe', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'Fr@@', 'auen', 'in', 'den', 'letz@@', 'ten', '1@@', '5', 'Jahren', 'in', 'der', 'Welt', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:43:49,382 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:43:49,382 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:43:49,382 - INFO - joeynmt.training - 	Hypothesis: Ich habe die M<unk> nner und ich habe die M<unk> glichkeit der M<unk> nner und Frauen in den letzten 15 Jahren in der Welt zu ver<unk> ndern.
2025-05-29 19:43:49,382 - INFO - joeynmt.training - Example #1
2025-05-29 19:43:49,382 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:43:49,382 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:43:49,382 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'die', 'K@@', '<unk>', 'n@@', 'st@@', 'l@@', 'er@@', 'in', 'der', 'L@@', 'age', 'der', 'K@@', '<unk>', 'ni@@', 'g@@', 'in', 'der', 'L@@', 'age', 'der', 'B@@', '<unk>', 'h@@', 'ne', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'K@@', '<unk>', 'ni@@', 'g@@', 're@@', 'ich', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'die', 'ich', 'nicht', 'nur', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'K@@', '<unk>', 'ni@@', 'g@@', 're@@', 'ich', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:43:49,382 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:43:49,382 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:43:49,382 - INFO - joeynmt.training - 	Hypothesis: Es ist die K<unk> nstlerin der Lage der K<unk> nigin der Lage der B<unk> hne und die M<unk> glichkeit der K<unk> nigreich zu verwenden, die ich nicht nur die M<unk> glichkeit der M<unk> glichkeit der K<unk> nigreich zu ver<unk> ndern.
2025-05-29 19:43:49,382 - INFO - joeynmt.training - Example #2
2025-05-29 19:43:49,382 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:43:49,382 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:43:49,383 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'K@@', 'at@@', 'eg@@', 'or@@', 'ie', 'ist', 'ein', 'sehr', 'gut@@', 'es', 'Bei@@', 'spi@@', 'el', 'der', 'K@@', 'li@@', 'ma@@', 'w@@', 'andel@@', ',', 'und', 'es', 'ist', 'ein', 'sehr', 'gut@@', 'es', 'Bei@@', 'spi@@', 'el', 'der', 'K@@', 'li@@', 'ma@@', 'w@@', 'andel@@', ',', 'und', 'es', 'ist', 'ein', 'g@@', 'ro@@', '<unk>', 'er', 'M@@', 'at@@', 'eri@@', 'ali@@', 'en', 'und', 'die', 'M@@', 'at@@', 'eri@@', 'ali@@', 'en', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:43:49,383 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:43:49,383 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:43:49,383 - INFO - joeynmt.training - 	Hypothesis: Die Kategorie ist ein sehr gutes Beispiel der Klimawandel, und es ist ein sehr gutes Beispiel der Klimawandel, und es ist ein gro<unk> er Materialien und die Materialien zu ver<unk> ndern.
2025-05-29 19:43:49,383 - INFO - joeynmt.training - Example #3
2025-05-29 19:43:49,383 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:43:49,383 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:43:49,383 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'ein', 'g@@', 'ro@@', '<unk>', 'es', 'Pro@@', 'bl@@', 'em', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'und', 'es', 'ist', 'nicht', 'nur', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'und', 'die', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'Fr@@', 'auen', 'und', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'und', 'es', 'ist', 'nicht', 'nur', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'K@@', '<unk>', 'ni@@', 'g@@', 're@@', 'ich', 'zu', 'ver@@', 'w@@', 'end@@', 'en.', '</s>']
2025-05-29 19:43:49,383 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:43:49,383 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:43:49,383 - INFO - joeynmt.training - 	Hypothesis: Es ist ein gro<unk> es Problem zu verwenden, und es ist nicht nur ein paar Minuten und die M<unk> nner und Frauen und K<unk> rper, und es ist nicht nur ein paar Minuten und die M<unk> glichkeit der K<unk> nigreich zu verwenden.
2025-05-29 19:43:49,383 - INFO - joeynmt.training - Example #4
2025-05-29 19:43:49,383 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:43:49,383 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:43:49,383 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'mei@@', 'sten', 'von', 'Ihnen', 'k@@', 'ur@@', 'z', 'von', 'Ihnen', 'ist', 'ein', 'paar', 'Bei@@', 'spiel@@', 'e', 'f@@', '<unk>', 'r', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'Welt', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:43:49,384 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:43:49,384 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:43:49,384 - INFO - joeynmt.training - 	Hypothesis: Die meisten von Ihnen kurz von Ihnen ist ein paar Beispiele f<unk> r die M<unk> glichkeit der Welt zu ver<unk> ndern.
2025-05-29 19:43:51,339 - INFO - joeynmt.training - Epoch   7, Step:    33100, Batch Loss:     2.280764, Batch Acc: 0.315492, Tokens per Sec:    35388, Lr: 0.000300
2025-05-29 19:43:53,168 - INFO - joeynmt.training - Epoch   7, Step:    33200, Batch Loss:     2.176706, Batch Acc: 0.316700, Tokens per Sec:    37697, Lr: 0.000300
2025-05-29 19:43:55,209 - INFO - joeynmt.training - Epoch   7, Step:    33300, Batch Loss:     2.288728, Batch Acc: 0.315182, Tokens per Sec:    34758, Lr: 0.000300
2025-05-29 19:43:57,317 - INFO - joeynmt.training - Epoch   7, Step:    33400, Batch Loss:     2.250074, Batch Acc: 0.316589, Tokens per Sec:    33089, Lr: 0.000300
2025-05-29 19:43:59,364 - INFO - joeynmt.training - Epoch   7, Step:    33500, Batch Loss:     2.283286, Batch Acc: 0.314130, Tokens per Sec:    34034, Lr: 0.000300
2025-05-29 19:43:59,365 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:43:59,365 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:44:13,662 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.24, ppl:   9.43, acc:   0.32, generation: 14.2887[sec], evaluation: 0.0000[sec]
2025-05-29 19:44:13,663 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:44:13,747 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/31000.ckpt
2025-05-29 19:44:13,752 - INFO - joeynmt.training - Example #0
2025-05-29 19:44:13,753 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:44:13,753 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:44:13,753 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'Ihnen', 'einen', 'W@@', 'eg', 'zu', 'zeig@@', 'en,', 'dass', 'ich', 'das', 'nicht', 'nur', 'f@@', '<unk>', 'r', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', 'li@@', 'eren', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'die', 'in', 'den', 'U@@', 'S@@', 'A', 'und', 'der', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', 'li@@', 'eren', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', 'w@@', 'end@@', 'en.', '</s>']
2025-05-29 19:44:13,753 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:44:13,753 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:44:13,753 - INFO - joeynmt.training - 	Hypothesis: Und ich habe Ihnen einen Weg zu zeigen, dass ich das nicht nur f<unk> r die K<unk> rper zu verlieren und die K<unk> rper zu verwenden, die in den USA und der K<unk> rper zu verlieren und die K<unk> rper zu verwenden.
2025-05-29 19:44:13,753 - INFO - joeynmt.training - Example #1
2025-05-29 19:44:13,753 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:44:13,753 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:44:13,753 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'denk@@', 'e,', 'dass', 'ich', 'die', 'K@@', '<unk>', 'r@@', 'per', 'nicht', 'mehr', 'als', 'die', 'K@@', '<unk>', 'r@@', 'per', 'nicht', 'mehr', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:44:13,753 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:44:13,753 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:44:13,753 - INFO - joeynmt.training - 	Hypothesis: Und ich denke, dass ich die K<unk> rper nicht mehr als die K<unk> rper nicht mehr zu erreichen.
2025-05-29 19:44:13,753 - INFO - joeynmt.training - Example #2
2025-05-29 19:44:13,753 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:44:13,753 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:44:13,753 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'sag@@', 'e', 'Ihnen', 'ein', 'paar', 'Bei@@', 'spiel@@', 'e', 'von', 'der', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:44:13,754 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:44:13,754 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:44:13,754 - INFO - joeynmt.training - 	Hypothesis: Und ich sage Ihnen ein paar Beispiele von der K<unk> rper zu erreichen.
2025-05-29 19:44:13,754 - INFO - joeynmt.training - Example #3
2025-05-29 19:44:13,754 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:44:13,754 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:44:13,754 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'ein', 'bis@@', 'schen', 'mehr', 'als', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'mehr', 'als', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'die', 'sich', 'in', 'die', 'L@@', 'u@@', 'ft@@', 'w@@', 'are', 'zu', 'b@@', 'au@@', 'en.', '</s>']
2025-05-29 19:44:13,754 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:44:13,754 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:44:13,754 - INFO - joeynmt.training - 	Hypothesis: Es ist ein bisschen mehr als die K<unk> rper und mehr als die K<unk> rper zu verwenden, die sich in die Luftware zu bauen.
2025-05-29 19:44:13,754 - INFO - joeynmt.training - Example #4
2025-05-29 19:44:13,754 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:44:13,754 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:44:13,754 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'glaub@@', 'e,', 'dass', 'ich', 'das', 'nicht', 'nur', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'die', 'ich', 'in', 'der', 'Welt', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:44:13,754 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:44:13,754 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:44:13,754 - INFO - joeynmt.training - 	Hypothesis: Und ich glaube, dass ich das nicht nur ein paar Minuten und die K<unk> rper, die ich in der Welt zu erreichen.
2025-05-29 19:44:15,828 - INFO - joeynmt.training - Epoch   7, Step:    33600, Batch Loss:     2.271559, Batch Acc: 0.314548, Tokens per Sec:    32459, Lr: 0.000300
2025-05-29 19:44:17,741 - INFO - joeynmt.training - Epoch   7, Step:    33700, Batch Loss:     2.239089, Batch Acc: 0.316704, Tokens per Sec:    37365, Lr: 0.000300
2025-05-29 19:44:19,529 - INFO - joeynmt.training - Epoch   7, Step:    33800, Batch Loss:     2.234310, Batch Acc: 0.316345, Tokens per Sec:    39996, Lr: 0.000300
2025-05-29 19:44:21,420 - INFO - joeynmt.training - Epoch   7, Step:    33900, Batch Loss:     2.310374, Batch Acc: 0.318067, Tokens per Sec:    37520, Lr: 0.000300
2025-05-29 19:44:23,342 - INFO - joeynmt.training - Epoch   7, Step:    34000, Batch Loss:     2.207700, Batch Acc: 0.315377, Tokens per Sec:    35900, Lr: 0.000300
2025-05-29 19:44:23,342 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:44:23,342 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:44:36,132 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.24, ppl:   9.44, acc:   0.32, generation: 12.7824[sec], evaluation: 0.0000[sec]
2025-05-29 19:44:36,216 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/31500.ckpt
2025-05-29 19:44:36,222 - INFO - joeynmt.training - Example #0
2025-05-29 19:44:36,223 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:44:36,223 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:44:36,223 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'es', 'in', 'der', 'M@@', 'it@@', 'te', 'der', 'K@@', 'rank@@', 'hei@@', 'ten', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:44:36,223 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:44:36,223 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:44:36,223 - INFO - joeynmt.training - 	Hypothesis: Und ich habe es in der Mitte der Krankheiten und die K<unk> rper und die K<unk> rper zu ver<unk> ndern.
2025-05-29 19:44:36,223 - INFO - joeynmt.training - Example #1
2025-05-29 19:44:36,223 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:44:36,223 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:44:36,223 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'denk@@', 'e,', 'dass', 'die', 'K@@', '<unk>', 'r@@', 'per', 'der', 'K@@', '<unk>', 'r@@', 'per', 'nicht', 'nur', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:44:36,223 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:44:36,223 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:44:36,223 - INFO - joeynmt.training - 	Hypothesis: Und ich denke, dass die K<unk> rper der K<unk> rper nicht nur die K<unk> rper zu ver<unk> ndern.
2025-05-29 19:44:36,223 - INFO - joeynmt.training - Example #2
2025-05-29 19:44:36,224 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:44:36,224 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:44:36,224 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'denk@@', 'e', 'es', 'ist', 'ein', 'sehr', 'gut@@', 'es', 'Bei@@', 'spi@@', 'el', 'der', 'W@@', 'in@@', 'd', 'der', 'K@@', 'at@@', 'z@@', ',', 'der', 'in', 'der', 'wir', 'uns', 'in', 'der', 'Welt', 'ver@@', '<unk>', 'n@@', 'der@@', 'n', 'k@@', '<unk>', 'n@@', 'n@@', 'en.', '</s>']
2025-05-29 19:44:36,224 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:44:36,224 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:44:36,224 - INFO - joeynmt.training - 	Hypothesis: Und ich denke es ist ein sehr gutes Beispiel der Wind der Katz, der in der wir uns in der Welt ver<unk> ndern k<unk> nnen.
2025-05-29 19:44:36,224 - INFO - joeynmt.training - Example #3
2025-05-29 19:44:36,224 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:44:36,224 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:44:36,224 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Sie', 'k@@', '<unk>', 'n@@', 'nen', 'sich', 'in', 'die', 'K@@', 'rank@@', 'hei@@', 'ten', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:44:36,224 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:44:36,224 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:44:36,224 - INFO - joeynmt.training - 	Hypothesis: Sie k<unk> nnen sich in die Krankheiten und die K<unk> rper und die K<unk> rper zu ver<unk> ndern.
2025-05-29 19:44:36,224 - INFO - joeynmt.training - Example #4
2025-05-29 19:44:36,224 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:44:36,224 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:44:36,224 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'es', 'in', 'der', 'W@@', '<unk>', 'r@@', 'ter', 'in', 'der', 'Welt', 'ver@@', '<unk>', 'n@@', 'der@@', 't', 'und', 'ich', 'habe', 'eine', 'S@@', 'ache', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:44:36,224 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:44:36,225 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:44:36,225 - INFO - joeynmt.training - 	Hypothesis: Und ich habe es in der W<unk> rter in der Welt ver<unk> ndert und ich habe eine Sache zu ver<unk> ndern.
2025-05-29 19:44:38,297 - INFO - joeynmt.training - Epoch   7, Step:    34100, Batch Loss:     2.157933, Batch Acc: 0.316875, Tokens per Sec:    32641, Lr: 0.000300
2025-05-29 19:44:40,365 - INFO - joeynmt.training - Epoch   7, Step:    34200, Batch Loss:     2.136999, Batch Acc: 0.320852, Tokens per Sec:    33706, Lr: 0.000300
2025-05-29 19:44:43,460 - INFO - joeynmt.training - Epoch   7, Step:    34300, Batch Loss:     2.104899, Batch Acc: 0.315573, Tokens per Sec:    22823, Lr: 0.000300
2025-05-29 19:44:45,503 - INFO - joeynmt.training - Epoch   7, Step:    34400, Batch Loss:     2.257334, Batch Acc: 0.314840, Tokens per Sec:    34276, Lr: 0.000300
2025-05-29 19:44:47,586 - INFO - joeynmt.training - Epoch   7, Step:    34500, Batch Loss:     2.194675, Batch Acc: 0.313568, Tokens per Sec:    33817, Lr: 0.000300
2025-05-29 19:44:47,586 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:44:47,586 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:45:02,098 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.24, ppl:   9.41, acc:   0.32, generation: 14.4996[sec], evaluation: 0.0000[sec]
2025-05-29 19:45:02,098 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:45:02,181 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/32000.ckpt
2025-05-29 19:45:02,186 - INFO - joeynmt.training - Example #0
2025-05-29 19:45:02,187 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:45:02,187 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:45:02,187 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'das', 'er@@', 'ste', 'M@@', 'al', 'in', 'der', 'L@@', 'age', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'M@@', '<unk>', 'glich@@', 'keit', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'S@@', 'tra@@', '<unk>', 'e', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:45:02,187 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:45:02,187 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:45:02,187 - INFO - joeynmt.training - 	Hypothesis: Und ich habe das erste Mal in der Lage und die M<unk> glichkeit der M<unk> glichkeit und die M<unk> glichkeit der Stra<unk> e zu erreichen.
2025-05-29 19:45:02,187 - INFO - joeynmt.training - Example #1
2025-05-29 19:45:02,187 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:45:02,187 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:45:02,187 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'm@@', '<unk>', 'chte', 'Ihnen', 'ein', 'Bei@@', 'spi@@', 'el', 'zeig@@', 'en,', 'dass', 'die', 'M@@', '<unk>', 'd@@', 'chen', 'nicht', 'nur', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'M@@', 'it@@', 'te', 'der', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'M@@', '<unk>', 'd@@', 'chen', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:45:02,187 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:45:02,187 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:45:02,187 - INFO - joeynmt.training - 	Hypothesis: Und ich m<unk> chte Ihnen ein Beispiel zeigen, dass die M<unk> dchen nicht nur die M<unk> glichkeit der K<unk> rper und die M<unk> glichkeit der Mitte der K<unk> rper und die M<unk> dchen zu erreichen.
2025-05-29 19:45:02,187 - INFO - joeynmt.training - Example #2
2025-05-29 19:45:02,187 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:45:02,188 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:45:02,188 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Das', 'ist', 'ein', 'g@@', 'ro@@', '<unk>', 'er', 'M@@', 'at@@', 'eri@@', 'ali@@', 'en', 'in', 'der', 'L@@', 'age', 'der', 'L@@', 'ehr@@', 'er', 'und', 'die', 'M@@', 'at@@', 'eri@@', 'ali@@', 'en', 'zu', 'k@@', '<unk>', 'n@@', 'n@@', 'en.', '</s>']
2025-05-29 19:45:02,188 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:45:02,188 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:45:02,188 - INFO - joeynmt.training - 	Hypothesis: Das ist ein gro<unk> er Materialien in der Lage der Lehrer und die Materialien zu k<unk> nnen.
2025-05-29 19:45:02,188 - INFO - joeynmt.training - Example #3
2025-05-29 19:45:02,188 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:45:02,188 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:45:02,188 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Sie', 'k@@', '<unk>', 'n@@', 'nen', 'sich', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'M@@', '<unk>', 'd@@', 'chen', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:45:02,188 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:45:02,188 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:45:02,188 - INFO - joeynmt.training - 	Hypothesis: Sie k<unk> nnen sich die M<unk> glichkeit und die M<unk> glichkeit der K<unk> rper und die M<unk> glichkeit der K<unk> rper und die M<unk> glichkeit der K<unk> rper und die M<unk> dchen und die M<unk> glichkeit zu erreichen.
2025-05-29 19:45:02,188 - INFO - joeynmt.training - Example #4
2025-05-29 19:45:02,188 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:45:02,188 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:45:02,188 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'm@@', '<unk>', 'chte', 'Ihnen', 'ein', 'Bei@@', 'spi@@', 'el', 'zeig@@', 'en,', 'wie', 'man', 'das', 'B@@', 'est@@', 'e', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'M@@', 'it@@', 'te', 'der', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'M@@', 'it@@', 'te', 'der', 'M@@', 'it@@', 'te', 'der', 'M@@', 'it@@', 'te', 'der', 'M@@', 'it@@', 'te', 'der', 'M@@', '<unk>', 'r@@', 'k@@', 'te', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ern']
2025-05-29 19:45:02,189 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:45:02,189 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:45:02,189 - INFO - joeynmt.training - 	Hypothesis: Und ich m<unk> chte Ihnen ein Beispiel zeigen, wie man das Beste und die M<unk> glichkeit der K<unk> rper und die M<unk> glichkeit der K<unk> rper und die M<unk> glichkeit der K<unk> rper und die M<unk> glichkeit der Mitte der K<unk> rper und die M<unk> glichkeit der K<unk> rper und die M<unk> glichkeit der Mitte der Mitte der Mitte der Mitte der M<unk> rkte und die M<unk> nnern
2025-05-29 19:45:04,580 - INFO - joeynmt.training - Epoch   7, Step:    34600, Batch Loss:     2.266657, Batch Acc: 0.314060, Tokens per Sec:    28632, Lr: 0.000300
2025-05-29 19:45:06,655 - INFO - joeynmt.training - Epoch   7, Step:    34700, Batch Loss:     2.252975, Batch Acc: 0.314056, Tokens per Sec:    34049, Lr: 0.000300
2025-05-29 19:45:08,717 - INFO - joeynmt.training - Epoch   7, Step:    34800, Batch Loss:     2.295819, Batch Acc: 0.311862, Tokens per Sec:    33089, Lr: 0.000300
2025-05-29 19:45:10,839 - INFO - joeynmt.training - Epoch   7, Step:    34900, Batch Loss:     2.245700, Batch Acc: 0.318201, Tokens per Sec:    33600, Lr: 0.000300
2025-05-29 19:45:12,957 - INFO - joeynmt.training - Epoch   7, Step:    35000, Batch Loss:     2.331263, Batch Acc: 0.312369, Tokens per Sec:    33691, Lr: 0.000300
2025-05-29 19:45:12,957 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:45:12,957 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:45:28,406 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.24, ppl:   9.36, acc:   0.32, generation: 15.4367[sec], evaluation: 0.0000[sec]
2025-05-29 19:45:28,406 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:45:28,489 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/33000.ckpt
2025-05-29 19:45:28,495 - INFO - joeynmt.training - Example #0
2025-05-29 19:45:28,495 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:45:28,495 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:45:28,495 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'Ihnen', 'ein', 'paar', 'Bei@@', 'spiel@@', 'e', 'von', 'der', 'S@@', 'tra@@', '<unk>', 'en@@', 'f@@', 't,', 'die', 'ich', 'in', 'den', 'letz@@', 'ten', '1@@', '5', 'Jahren', 'in', 'der', 'L@@', 'age', 'der', 'S@@', 'tra@@', '<unk>', 'e', 'zu', 'er@@', 'rei@@', 'chen,', 'um', 'die', '<unk>', 'ber@@', 'all', 'in', 'der', 'L@@', 'age', 'zu', 'er@@', 'rei@@', 'chen,', 'die', 'sie', 'in', 'den', 'n@@', '<unk>', 'ch@@', 'sten', '3@@', '0', 'Milli@@', 'onen', 'Menschen', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'die', 'in', 'den', '19@@', '8@@', '0@@', 'ern', 'und', '1@@', '0@@', '0@@', 'ern', 'und', '1@@', '5', 'Proz@@', 'ent', 'der', 'K@@', 'l@@', 'ein@@', 'er@@', 'l@@', 'ei', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'des', 'K@@', 'li@@', 'ma@@', 'w@@', 'an@@', 'del', 'zu', 'er@@', 'rei@@', 'chen,', 'und']
2025-05-29 19:45:28,495 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:45:28,495 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:45:28,495 - INFO - joeynmt.training - 	Hypothesis: Und ich habe Ihnen ein paar Beispiele von der Stra<unk> enft, die ich in den letzten 15 Jahren in der Lage der Stra<unk> e zu erreichen, um die <unk> berall in der Lage zu erreichen, die sie in den n<unk> chsten 30 Millionen Menschen zu verwenden, die in den 1980ern und 100ern und 15 Prozent der Kleinerlei und die M<unk> glichkeit des Klimawandel zu erreichen, und
2025-05-29 19:45:28,495 - INFO - joeynmt.training - Example #1
2025-05-29 19:45:28,495 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:45:28,495 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:45:28,495 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'Ihnen', 'ein', 'paar', 'Bei@@', 'spiel@@', 'e', 'von', 'der', 'S@@', 'tra@@', '<unk>', 'en@@', 'f@@', '.', '</s>']
2025-05-29 19:45:28,496 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:45:28,496 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:45:28,496 - INFO - joeynmt.training - 	Hypothesis: Und ich habe Ihnen ein paar Beispiele von der Stra<unk> enf.
2025-05-29 19:45:28,496 - INFO - joeynmt.training - Example #2
2025-05-29 19:45:28,496 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:45:28,496 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:45:28,496 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'Ihnen', 'ein', 'paar', 'Bei@@', 'spiel@@', 'e', 'von', 'der', 'S@@', 'tra@@', '<unk>', 'en@@', 'f@@', '.', '</s>']
2025-05-29 19:45:28,496 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:45:28,496 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:45:28,496 - INFO - joeynmt.training - 	Hypothesis: Und ich habe Ihnen ein paar Beispiele von der Stra<unk> enf.
2025-05-29 19:45:28,496 - INFO - joeynmt.training - Example #3
2025-05-29 19:45:28,496 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:45:28,496 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:45:28,496 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'ein', 'g@@', 'ro@@', '<unk>', 'es', 'Pro@@', 'bl@@', 'em', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'das', 'ist', 'ein', 'g@@', 'ro@@', '<unk>', 'es', 'Pro@@', 'bl@@', 'em', 'zu', 'ver@@', 'w@@', 'end@@', 'en.', '</s>']
2025-05-29 19:45:28,496 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:45:28,496 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:45:28,496 - INFO - joeynmt.training - 	Hypothesis: Es ist ein gro<unk> es Problem zu verwenden, das ist ein gro<unk> es Problem zu verwenden.
2025-05-29 19:45:28,496 - INFO - joeynmt.training - Example #4
2025-05-29 19:45:28,496 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:45:28,496 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:45:28,497 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'Ihnen', 'ein', 'paar', 'Bei@@', 'spiel@@', 'e', 'von', 'der', 'S@@', 'ache', 'zu', 'er@@', 'rei@@', 'chen,', 'und', 'ich', 'habe', 'es', 'in', 'der', 'L@@', 'age', 'ges@@', 'ag@@', 't,', 'dass', 'ich', 'in', 'der', 'L@@', 'age', 'ist,', 'die', 'ich', 'in', 'der', 'L@@', 'age', 'f@@', '<unk>', 'r', 'mich', 'zu', 'er@@', 'kl@@', '<unk>', 'r@@', 'en,', 'dass', 'ich', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'in', 'der', 'L@@', 'age', 'ist,', 'die', 'ich', 'in', 'der', 'L@@', 'age', 'f@@', '<unk>', 'r', 'die', 'K@@', 'ar@@', 'te', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'und', 'ich', 'habe', 'es', 'in', 'der', 'H@@', '<unk>', 'h@@', 'e', 'zu', 'k@@', '<unk>', 'n@@', 'n@@', 'en.', '</s>']
2025-05-29 19:45:28,497 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:45:28,497 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:45:28,497 - INFO - joeynmt.training - 	Hypothesis: Und ich habe Ihnen ein paar Beispiele von der Sache zu erreichen, und ich habe es in der Lage gesagt, dass ich in der Lage ist, die ich in der Lage f<unk> r mich zu erkl<unk> ren, dass ich ein paar Minuten in der Lage ist, die ich in der Lage f<unk> r die Karte zu verwenden, und ich habe es in der H<unk> he zu k<unk> nnen.
2025-05-29 19:45:30,504 - INFO - joeynmt.training - Epoch   7, Step:    35100, Batch Loss:     2.299126, Batch Acc: 0.314480, Tokens per Sec:    33663, Lr: 0.000300
2025-05-29 19:45:32,248 - INFO - joeynmt.training - Epoch   7, Step:    35200, Batch Loss:     2.261252, Batch Acc: 0.311531, Tokens per Sec:    38981, Lr: 0.000300
2025-05-29 19:45:34,042 - INFO - joeynmt.training - Epoch   7, Step:    35300, Batch Loss:     2.197238, Batch Acc: 0.314457, Tokens per Sec:    38529, Lr: 0.000300
2025-05-29 19:45:35,915 - INFO - joeynmt.training - Epoch   7, Step:    35400, Batch Loss:     2.262025, Batch Acc: 0.314786, Tokens per Sec:    38932, Lr: 0.000300
2025-05-29 19:45:37,840 - INFO - joeynmt.training - Epoch   7, Step:    35500, Batch Loss:     2.176663, Batch Acc: 0.317330, Tokens per Sec:    36703, Lr: 0.000300
2025-05-29 19:45:37,841 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:45:37,841 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:45:51,667 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.23, ppl:   9.32, acc:   0.32, generation: 13.8153[sec], evaluation: 0.0000[sec]
2025-05-29 19:45:51,667 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:45:51,750 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/32500.ckpt
2025-05-29 19:45:51,755 - INFO - joeynmt.training - Example #0
2025-05-29 19:45:51,755 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:45:51,755 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:45:51,755 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'mir', 'ein', 'paar', 'Jahre', 'al@@', 't', 'und', 'ich', 'habe', 'es', 'in', 'den', 'U@@', 'S@@', 'A', 'und', 'und', 'ich', 'habe', 'es', 'in', 'den', 'letz@@', 'ten', '1@@', '0@@', '0@@', 'er', 'Jahren', 'er@@', 'rei@@', 'ch@@', 't.', '</s>']
2025-05-29 19:45:51,756 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:45:51,756 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:45:51,756 - INFO - joeynmt.training - 	Hypothesis: Ich habe mir ein paar Jahre alt und ich habe es in den USA und und ich habe es in den letzten 100er Jahren erreicht.
2025-05-29 19:45:51,756 - INFO - joeynmt.training - Example #1
2025-05-29 19:45:51,756 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:45:51,756 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:45:51,756 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'mich', 'ge@@', 'frag@@', 't,', 'ob', 'es', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'und', 'ich', 'habe', 'es', 'in', 'der', 'L@@', 'age', 'ges@@', 'pro@@', 'chen', 'hab@@', 'e,', 'und', 'ich', 'habe', 'es', 'nicht', 'nur', 'die', 'K@@', '<unk>', 'r@@', 'z@@', 'lich', 'ver@@', 'st@@', 'and@@', 'en', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:45:51,756 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:45:51,756 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:45:51,756 - INFO - joeynmt.training - 	Hypothesis: Und ich habe mich gefragt, ob es ein paar Minuten und ich habe es in der Lage gesprochen habe, und ich habe es nicht nur die K<unk> rzlich verstanden und die M<unk> glichkeit zu ver<unk> ndern.
2025-05-29 19:45:51,756 - INFO - joeynmt.training - Example #2
2025-05-29 19:45:51,756 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:45:51,756 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:45:51,756 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'mei@@', 'sten', 'von', 'Ihnen', 'k@@', '<unk>', 'n@@', 'nen', '<unk>', 'ber', 'die', 'K@@', 'li@@', 'ma@@', 'w@@', 'an@@', 'del', 'zu', 'spr@@', 'ech@@', 'en.', '</s>']
2025-05-29 19:45:51,756 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:45:51,757 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:45:51,757 - INFO - joeynmt.training - 	Hypothesis: Die meisten von Ihnen k<unk> nnen <unk> ber die Klimawandel zu sprechen.
2025-05-29 19:45:51,757 - INFO - joeynmt.training - Example #3
2025-05-29 19:45:51,757 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:45:51,757 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:45:51,757 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Sie', 'k@@', '<unk>', 'n@@', 'nen', 'sich', 'in', 'den', 'U@@', 'S@@', 'A', 'und', 'der', 'K@@', '<unk>', 'r@@', 'z@@', 'lich', 'in', 'der', 'L@@', 'age', 'sein,', 'die', 'wir', 'in', 'der', 'Welt', 'ver@@', '<unk>', 'n@@', 'der@@', 'n', 'k@@', '<unk>', 'n@@', 'n@@', 'en.', '</s>']
2025-05-29 19:45:51,757 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:45:51,757 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:45:51,757 - INFO - joeynmt.training - 	Hypothesis: Sie k<unk> nnen sich in den USA und der K<unk> rzlich in der Lage sein, die wir in der Welt ver<unk> ndern k<unk> nnen.
2025-05-29 19:45:51,757 - INFO - joeynmt.training - Example #4
2025-05-29 19:45:51,757 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:45:51,757 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:45:51,757 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'mei@@', 'sten', 'von', 'Ihnen', 'k@@', '<unk>', 'n@@', 'nen', '<unk>', 'ber', 'die', 'H@@', '<unk>', 'l@@', 'f@@', 'te', 'der', 'K@@', 'ar@@', 'te', 'zu', 'spr@@', 'ech@@', 'en.', '</s>']
2025-05-29 19:45:51,757 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:45:51,757 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:45:51,757 - INFO - joeynmt.training - 	Hypothesis: Die meisten von Ihnen k<unk> nnen <unk> ber die H<unk> lfte der Karte zu sprechen.
2025-05-29 19:45:53,813 - INFO - joeynmt.training - Epoch   7, Step:    35600, Batch Loss:     2.147317, Batch Acc: 0.311239, Tokens per Sec:    32732, Lr: 0.000300
2025-05-29 19:45:55,846 - INFO - joeynmt.training - Epoch   7, Step:    35700, Batch Loss:     2.133547, Batch Acc: 0.313031, Tokens per Sec:    34106, Lr: 0.000300
2025-05-29 19:45:57,845 - INFO - joeynmt.training - Epoch   7, Step:    35800, Batch Loss:     2.099340, Batch Acc: 0.315577, Tokens per Sec:    35195, Lr: 0.000300
2025-05-29 19:45:59,830 - INFO - joeynmt.training - Epoch   7, Step:    35900, Batch Loss:     2.202842, Batch Acc: 0.316752, Tokens per Sec:    37043, Lr: 0.000300
2025-05-29 19:46:01,725 - INFO - joeynmt.training - Epoch   7, Step:    36000, Batch Loss:     2.317985, Batch Acc: 0.315279, Tokens per Sec:    35828, Lr: 0.000300
2025-05-29 19:46:01,726 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:46:01,726 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:46:16,938 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.23, ppl:   9.33, acc:   0.32, generation: 15.1985[sec], evaluation: 0.0000[sec]
2025-05-29 19:46:17,023 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/34000.ckpt
2025-05-29 19:46:17,029 - INFO - joeynmt.training - Example #0
2025-05-29 19:46:17,029 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:46:17,029 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:46:17,029 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'eine', 'M@@', 'en@@', 'ge', 'S@@', 'ach@@', 'e,', 'die', 'ich', 'in', 'den', 'letz@@', 'ten', '1@@', '5', 'Jahren', 'in', 'den', 'letz@@', 'ten', '1@@', '5', 'Jahren', 'in', 'den', 'letz@@', 'ten', '1@@', '5', 'Jahren', 'in', 'den', 'letz@@', 'ten', '1@@', '5', 'Jahren', 'in', 'den', 'letz@@', 'ten', '1@@', '5', 'Jahren', 'in', 'den', 'letz@@', 'ten', '1@@', '5', 'Jahren', 'in', 'den', 'letz@@', 'ten', '1@@', '5', 'Jahren', 'in', 'den', 'letz@@', 'ten', '1@@', '0@@', 'ern', 'und', '1@@', '00', 'Milli@@', 'onen', 'D@@', 'oll@@', 'ar', 'f@@', '<unk>', 'r', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'Wel@@', 't@@', 'k@@', 'ri@@', 'eg', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'von', '1@@', '00', 'Milli@@', 'onen', 'D@@', 'oll@@', 'ar', 'pr@@', '<unk>']
2025-05-29 19:46:17,030 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:46:17,030 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:46:17,030 - INFO - joeynmt.training - 	Hypothesis: Ich habe eine Menge Sache, die ich in den letzten 15 Jahren in den letzten 15 Jahren in den letzten 15 Jahren in den letzten 15 Jahren in den letzten 15 Jahren in den letzten 15 Jahren in den letzten 15 Jahren in den letzten 10ern und 100 Millionen Dollar f<unk> r die M<unk> glichkeit der Weltkrieg zu ver<unk> ndern und die M<unk> glichkeiten von 100 Millionen Dollar pr<unk>
2025-05-29 19:46:17,030 - INFO - joeynmt.training - Example #1
2025-05-29 19:46:17,030 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:46:17,030 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:46:17,030 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'm@@', '<unk>', 'chte', 'Ihnen', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 't,', 'die', 'ich', 'nicht', 'nur', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 't,', 'die', 'wir', 'nicht', 'nur', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 't,', 'die', 'wir', 'nicht', 'er@@', 'war@@', 'ten,', 'sondern', 'wir', 'k@@', '<unk>', 'n@@', 'n@@', 'en,', 'die', 'wir', 'in', 'den', 'K@@', 'op@@', 'f', 'der', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n', 'k@@', '<unk>', 'n@@', 'n@@', 'en.', '</s>']
2025-05-29 19:46:17,030 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:46:17,030 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:46:17,030 - INFO - joeynmt.training - 	Hypothesis: Und ich m<unk> chte Ihnen die M<unk> glichkeit, die ich nicht nur die M<unk> glichkeit, die wir nicht nur die M<unk> glichkeit, die wir nicht erwarten, sondern wir k<unk> nnen, die wir in den Kopf der K<unk> rper zu ver<unk> ndern k<unk> nnen.
2025-05-29 19:46:17,030 - INFO - joeynmt.training - Example #2
2025-05-29 19:46:17,030 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:46:17,030 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:46:17,030 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'm@@', '<unk>', 'chte', 'Ihnen', 'ein', 'Bei@@', 'spiel@@', ',', 'das', 'ist', 'eine', 'M@@', 'en@@', 'ge', 'S@@', 'ach@@', 'e,', 'die', 'ich', 'nicht', 'nur', 'die', 'M@@', 'at@@', 'h@@', 'em@@', 'ati@@', 'k', 'f@@', '<unk>', 'r', 'die', 'M@@', 'at@@', 'h@@', 'em@@', 'ati@@', 'k', 'f@@', '<unk>', 'r', 'die', 'M@@', 'at@@', 'h@@', 'em@@', 'ati@@', 'k@@', 'er', 'und', 'die', 'M@@', 'at@@', 'h@@', 'em@@', 'ati@@', 'k', 'und', 'die', 'M@@', 'at@@', 'h@@', 'em@@', 'ati@@', 'k', 'und', 'die', 'M@@', 'at@@', 'h@@', 'em@@', 'ati@@', 'k', 'ver@@', 'st@@', '<unk>', 'n@@', 'd@@', 'lich', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:46:17,030 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:46:17,031 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:46:17,031 - INFO - joeynmt.training - 	Hypothesis: Und ich m<unk> chte Ihnen ein Beispiel, das ist eine Menge Sache, die ich nicht nur die Mathematik f<unk> r die Mathematik f<unk> r die Mathematiker und die Mathematik und die Mathematik und die Mathematik verst<unk> ndlich zu erreichen.
2025-05-29 19:46:17,031 - INFO - joeynmt.training - Example #3
2025-05-29 19:46:17,031 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:46:17,031 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:46:17,031 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'm@@', '<unk>', 'chte', 'Ihnen', 'ein', 'Bei@@', 'spiel@@', ',', 'das', 'ich', 'Ihnen', 'sag@@', 'en,', 'dass', 'es', 'eine', 'M@@', 'en@@', 'ge', 'M@@', '<unk>', 'glich@@', 'kei@@', 't,', 'die', 'ich', 'er@@', 'w@@', '<unk>', 'h@@', 'n@@', 't', 'und', 'ich', 'm@@', '<unk>', 'chte', 'Ihnen', 'ein', 'paar', 'Bei@@', 'spiel@@', 'e', 'f@@', '<unk>', 'r', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 't,', 'die', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:46:17,031 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:46:17,031 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:46:17,031 - INFO - joeynmt.training - 	Hypothesis: Und ich m<unk> chte Ihnen ein Beispiel, das ich Ihnen sagen, dass es eine Menge M<unk> glichkeit, die ich erw<unk> hnt und ich m<unk> chte Ihnen ein paar Beispiele f<unk> r die M<unk> glichkeit, die die M<unk> glichkeit der K<unk> rper zu ver<unk> ndern und die M<unk> glichkeiten zu erreichen.
2025-05-29 19:46:17,031 - INFO - joeynmt.training - Example #4
2025-05-29 19:46:17,031 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:46:17,031 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:46:17,031 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'm@@', '<unk>', 'chte', 'Ihnen', 'ein', 'paar', 'Bei@@', 'spiel@@', 'e', 'f@@', '<unk>', 'r', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 't,', 'die', 'ich', 'nicht', 'nur', 'eine', 'M@@', 'en@@', 'ge', 'M@@', '<unk>', 'glich@@', 'kei@@', 't,', 'die', 'ich', 'nicht', 'nur', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 't,', 'sondern', 'auch', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 't,', 'die', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 't,', 'die', 'die', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'M@@', '<unk>', 'glich@@', 'kei@@', 't,', 'die', 'wir', 'uns', 'in', 'den', 'letz@@', 'ten', '1@@', '5', 'Jahren', 'in', 'den', 'letz@@', 'ten', '1@@', '5', 'Jahren', 'in', 'den', 'letz@@', 'ten', '1@@', '5', 'Jahr@@', 'en.', '</s>']
2025-05-29 19:46:17,031 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:46:17,031 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:46:17,032 - INFO - joeynmt.training - 	Hypothesis: Und ich m<unk> chte Ihnen ein paar Beispiele f<unk> r die M<unk> glichkeit, die ich nicht nur eine Menge M<unk> glichkeit, die ich nicht nur die M<unk> glichkeit, sondern auch die M<unk> glichkeit, die die M<unk> glichkeit, die die die M<unk> glichkeit der M<unk> glichkeit, die wir uns in den letzten 15 Jahren in den letzten 15 Jahren in den letzten 15 Jahren.
2025-05-29 19:46:19,097 - INFO - joeynmt.training - Epoch   7, Step:    36100, Batch Loss:     2.318024, Batch Acc: 0.313505, Tokens per Sec:    32312, Lr: 0.000300
2025-05-29 19:46:21,192 - INFO - joeynmt.training - Epoch   7, Step:    36200, Batch Loss:     2.233452, Batch Acc: 0.319263, Tokens per Sec:    33564, Lr: 0.000300
2025-05-29 19:46:24,339 - INFO - joeynmt.training - Epoch   7, Step:    36300, Batch Loss:     2.146533, Batch Acc: 0.317413, Tokens per Sec:    22814, Lr: 0.000300
2025-05-29 19:46:26,466 - INFO - joeynmt.training - Epoch   7, Step:    36400, Batch Loss:     2.204842, Batch Acc: 0.316322, Tokens per Sec:    33296, Lr: 0.000300
2025-05-29 19:46:28,531 - INFO - joeynmt.training - Epoch   7, Step:    36500, Batch Loss:     2.295683, Batch Acc: 0.314116, Tokens per Sec:    32953, Lr: 0.000300
2025-05-29 19:46:28,531 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:46:28,531 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:46:41,684 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.23, ppl:   9.28, acc:   0.32, generation: 13.1439[sec], evaluation: 0.0000[sec]
2025-05-29 19:46:41,684 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:46:41,764 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/33500.ckpt
2025-05-29 19:46:41,770 - INFO - joeynmt.training - Example #0
2025-05-29 19:46:41,771 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:46:41,771 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:46:41,771 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'mich', 'ge@@', 'frag@@', 't,', 'ob', 'ich', 'es', 'in', 'der', 'L@@', 'u@@', 'ft@@', 'fahr@@', 't', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:46:41,771 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:46:41,771 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:46:41,771 - INFO - joeynmt.training - 	Hypothesis: Und ich habe mich gefragt, ob ich es in der Luftfahrt und die M<unk> glichkeit der K<unk> rper zu ver<unk> ndern.
2025-05-29 19:46:41,771 - INFO - joeynmt.training - Example #1
2025-05-29 19:46:41,771 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:46:41,771 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:46:41,771 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'ein', 'M@@', '<unk>', 'd@@', 'chen', 'der', 'K@@', '<unk>', 'ni@@', 'g@@', '.', '</s>']
2025-05-29 19:46:41,771 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:46:41,771 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:46:41,771 - INFO - joeynmt.training - 	Hypothesis: Und das ist ein M<unk> dchen der K<unk> nig.
2025-05-29 19:46:41,771 - INFO - joeynmt.training - Example #2
2025-05-29 19:46:41,771 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:46:41,771 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:46:41,771 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'ein', 'M@@', 'at@@', 'eri@@', 'al@@', ',', 'das', 'ist', 'ein', 'M@@', 'at@@', 'eri@@', 'al@@', ',', 'das', 'ist', 'ein', 'M@@', 'at@@', 'eri@@', 'al@@', ',', 'das', 'ist', 'ein', 'M@@', 'at@@', 'eri@@', 'al@@', '.', '</s>']
2025-05-29 19:46:41,772 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:46:41,772 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:46:41,772 - INFO - joeynmt.training - 	Hypothesis: Und das ist ein Material, das ist ein Material, das ist ein Material, das ist ein Material.
2025-05-29 19:46:41,772 - INFO - joeynmt.training - Example #3
2025-05-29 19:46:41,772 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:46:41,772 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:46:41,772 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'ein', 'M@@', '<unk>', 'd@@', 'chen', 'und', 'das', 'ist', 'ein', 'M@@', '<unk>', 'd@@', 'chen', 'und', 'das', 'ist', 'ein', 'M@@', '<unk>', 'd@@', 'chen', 'und', 'das', 'ist', 'ein', 'M@@', '<unk>', 'd@@', 'chen', 'und', 'das', 'ist', 'ein', 'M@@', '<unk>', 'd@@', 'chen', 'und', 'das', 'ist', 'ein', 'M@@', '<unk>', 'd@@', 'chen', 'der', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 't,', 'die', 'wir', 'nicht', 'nur', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 't,', 'die', 'wir', 'nicht', 'ver@@', '<unk>', 'n@@', 'der@@', 'n', 'k@@', '<unk>', 'n@@', 'n@@', 'en.', '</s>']
2025-05-29 19:46:41,772 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:46:41,772 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:46:41,772 - INFO - joeynmt.training - 	Hypothesis: Und das ist ein M<unk> dchen und das ist ein M<unk> dchen und das ist ein M<unk> dchen und das ist ein M<unk> dchen und das ist ein M<unk> dchen und das ist ein M<unk> dchen der K<unk> rper und die M<unk> glichkeit, die wir nicht nur ein paar Minuten und die M<unk> glichkeit, die wir nicht ver<unk> ndern k<unk> nnen.
2025-05-29 19:46:41,772 - INFO - joeynmt.training - Example #4
2025-05-29 19:46:41,772 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:46:41,772 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:46:41,772 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'mei@@', 'sten', 'von', 'Ihnen', 'k@@', 'ur@@', 'z', 'zeig@@', 'en,', 'wie', 'wir', 'es', 'uns', 'er@@', 'm@@', '<unk>', 'glich@@', 'en,', 'dass', 'wir', 'uns', 'nicht', 'nur', 'ein', 'paar', 'Bei@@', 'spiel@@', 'e', 'f@@', '<unk>', 'r', 'die', 'K@@', '<unk>', 'ni@@', 'g@@', 'in', 'der', 'Welt', 'ver@@', '<unk>', 'n@@', 'der@@', 'n', 'k@@', '<unk>', 'n@@', 'n@@', 'en.', '</s>']
2025-05-29 19:46:41,772 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:46:41,772 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:46:41,772 - INFO - joeynmt.training - 	Hypothesis: Die meisten von Ihnen kurz zeigen, wie wir es uns erm<unk> glichen, dass wir uns nicht nur ein paar Beispiele f<unk> r die K<unk> nigin der Welt ver<unk> ndern k<unk> nnen.
2025-05-29 19:46:43,826 - INFO - joeynmt.training - Epoch   7, Step:    36600, Batch Loss:     2.236680, Batch Acc: 0.313008, Tokens per Sec:    34086, Lr: 0.000300
2025-05-29 19:46:45,865 - INFO - joeynmt.training - Epoch   7, Step:    36700, Batch Loss:     2.425745, Batch Acc: 0.315187, Tokens per Sec:    35130, Lr: 0.000300
2025-05-29 19:46:47,934 - INFO - joeynmt.training - Epoch   7, Step:    36800, Batch Loss:     2.300584, Batch Acc: 0.317494, Tokens per Sec:    33718, Lr: 0.000300
2025-05-29 19:46:49,999 - INFO - joeynmt.training - Epoch   7, Step:    36900, Batch Loss:     2.097227, Batch Acc: 0.317565, Tokens per Sec:    34608, Lr: 0.000300
2025-05-29 19:46:52,029 - INFO - joeynmt.training - Epoch   7, Step:    37000, Batch Loss:     2.183493, Batch Acc: 0.318173, Tokens per Sec:    34918, Lr: 0.000300
2025-05-29 19:46:52,029 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:46:52,030 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:47:05,902 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.22, ppl:   9.24, acc:   0.33, generation: 13.8604[sec], evaluation: 0.0000[sec]
2025-05-29 19:47:05,902 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:47:05,988 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/34500.ckpt
2025-05-29 19:47:05,994 - INFO - joeynmt.training - Example #0
2025-05-29 19:47:05,994 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:47:05,994 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:47:05,994 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'mich', 'f@@', '<unk>', 'r', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'und', 'ich', 'sag@@', 'te,', '"@@', 'Ich', 'bin', 'ein', 'paar', 'Jahre', 'al@@', 'te', 'F@@', '<unk>', 'hr@@', 'ungs@@', 'k@@', 'ra@@', 'ft', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:47:05,994 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:47:05,994 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:47:05,994 - INFO - joeynmt.training - 	Hypothesis: Und ich habe mich f<unk> r die M<unk> glichkeit und ich sagte, "Ich bin ein paar Jahre alte F<unk> hrungskraft und die M<unk> glichkeiten zu erreichen.
2025-05-29 19:47:05,994 - INFO - joeynmt.training - Example #1
2025-05-29 19:47:05,994 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:47:05,994 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:47:05,994 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'die', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'die', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'die', 'wir', 'nicht', 'in', 'der', 'L@@', 'age', 'sind,', 'die', 'wir', 'nicht', 'in', 'der', 'L@@', 'age', 'der', 'Welt', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:47:05,995 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:47:05,995 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:47:05,995 - INFO - joeynmt.training - 	Hypothesis: Und das ist die K<unk> rper, die die M<unk> glichkeit der K<unk> rper, die wir nicht in der Lage sind, die wir nicht in der Lage der Welt ver<unk> ndern.
2025-05-29 19:47:05,995 - INFO - joeynmt.training - Example #2
2025-05-29 19:47:05,995 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:47:05,995 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:47:05,995 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'er@@', 'ste', 'Frag@@', 'e', 'ist', 'die', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'die', 'wir', 'in', 'der', 'L@@', 'age', 'der', 'Welt', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:47:05,995 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:47:05,995 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:47:05,995 - INFO - joeynmt.training - 	Hypothesis: Die erste Frage ist die K<unk> rper, die wir in der Lage der Welt ver<unk> ndern.
2025-05-29 19:47:05,995 - INFO - joeynmt.training - Example #3
2025-05-29 19:47:05,995 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:47:05,995 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:47:05,995 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'gibt', 'eine', 'M@@', 'en@@', 'ge', 'S@@', 'ach@@', 'e,', 'die', 'sich', 'in', 'der', 'L@@', 'u@@', 'ft', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:47:05,995 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:47:05,995 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:47:05,995 - INFO - joeynmt.training - 	Hypothesis: Es gibt eine Menge Sache, die sich in der Luft zu ver<unk> ndern.
2025-05-29 19:47:05,995 - INFO - joeynmt.training - Example #4
2025-05-29 19:47:05,995 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:47:05,995 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:47:05,995 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'er@@', 'ste', 'Frag@@', 'e', 'ist', 'die', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'die', 'wir', 'in', 'der', 'L@@', 'age', 'f@@', '<unk>', 'r', 'die', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'die', 'ich', 'Ihnen', 'zeig@@', 'en', 'wer@@', 'f@@', 'en.', '</s>']
2025-05-29 19:47:05,996 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:47:05,996 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:47:05,996 - INFO - joeynmt.training - 	Hypothesis: Die erste Frage ist die K<unk> rper, die wir in der Lage f<unk> r die K<unk> rper, die ich Ihnen zeigen werfen.
2025-05-29 19:47:08,032 - INFO - joeynmt.training - Epoch   7, Step:    37100, Batch Loss:     2.238100, Batch Acc: 0.308881, Tokens per Sec:    32818, Lr: 0.000300
2025-05-29 19:47:10,090 - INFO - joeynmt.training - Epoch   7, Step:    37200, Batch Loss:     2.247264, Batch Acc: 0.314147, Tokens per Sec:    33876, Lr: 0.000300
2025-05-29 19:47:12,301 - INFO - joeynmt.training - Epoch   7, Step:    37300, Batch Loss:     2.176132, Batch Acc: 0.316853, Tokens per Sec:    31124, Lr: 0.000300
2025-05-29 19:47:14,388 - INFO - joeynmt.training - Epoch   7, Step:    37400, Batch Loss:     2.197296, Batch Acc: 0.312474, Tokens per Sec:    33712, Lr: 0.000300
2025-05-29 19:47:14,806 - INFO - joeynmt.training - Epoch   7: total training loss 11917.92
2025-05-29 19:47:14,806 - INFO - joeynmt.training - EPOCH 8
2025-05-29 19:47:16,532 - INFO - joeynmt.training - Epoch   8, Step:    37500, Batch Loss:     2.061800, Batch Acc: 0.326463, Tokens per Sec:    32218, Lr: 0.000300
2025-05-29 19:47:16,533 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:47:16,533 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:47:31,571 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.22, ppl:   9.24, acc:   0.33, generation: 15.0266[sec], evaluation: 0.0000[sec]
2025-05-29 19:47:31,650 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/35000.ckpt
2025-05-29 19:47:31,656 - INFO - joeynmt.training - Example #0
2025-05-29 19:47:31,656 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:47:31,656 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:47:31,656 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'mich', 'ge@@', 'frag@@', 't,', 'was', 'ich', 'sag@@', 'te,', '"@@', 'Ich', 'habe', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'von', 'der', 'K@@', 'ont@@', 'in@@', 'ent', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'dass', 'die', 'S@@', 'ache', 'in', 'den', 'U@@', 'S@@', 'A', 'und', 'der', 'S@@', 'tra@@', '<unk>', 'e', 'in', 'der', 'Welt', 'ver@@', '<unk>', 'n@@', 'der@@', 'n', 'k@@', '<unk>', 'n@@', 'n@@', 'en.', '</s>']
2025-05-29 19:47:31,656 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:47:31,656 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:47:31,656 - INFO - joeynmt.training - 	Hypothesis: Ich habe mich gefragt, was ich sagte, "Ich habe die M<unk> glichkeit von der Kontinent zu verwenden, dass die Sache in den USA und der Stra<unk> e in der Welt ver<unk> ndern k<unk> nnen.
2025-05-29 19:47:31,656 - INFO - joeynmt.training - Example #1
2025-05-29 19:47:31,656 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:47:31,656 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:47:31,656 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Das', 'ist', 'die', 'An@@', 't@@', 'w@@', 'ort', 'auf', 'die', 'S@@', 'ei@@', 'te', 'der', 'S@@', 'ei@@', 'te', 'der', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'und', 'das', 'ist', 'nicht', 'nur', 'ein', 'paar', 'W@@', 'o@@', 'chen', 'der', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', 'w@@', 'end@@', 'en.', '</s>']
2025-05-29 19:47:31,656 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:47:31,656 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:47:31,656 - INFO - joeynmt.training - 	Hypothesis: Das ist die Antwort auf die Seite der Seite der K<unk> rper und die M<unk> glichkeit der K<unk> rper zu verwenden, und das ist nicht nur ein paar Wochen der K<unk> rper zu verwenden.
2025-05-29 19:47:31,657 - INFO - joeynmt.training - Example #2
2025-05-29 19:47:31,657 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:47:31,657 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:47:31,657 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Das', 'ist', 'ein', 'sehr', 'sch@@', 'wi@@', 'er@@', 'ig@@', 'es', 'Bei@@', 'spi@@', 'el', 'der', 'S@@', 'tra@@', '<unk>', 'e', 'von', 'der', 'S@@', 'tra@@', '<unk>', 'e', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'und', 'das', 'ist', 'eine', 'sehr', 'wichtig@@', 'e', 'S@@', 'ach@@', 'e,', 'die', 'wir', 'in', 'der', 'Welt', 'ver@@', '<unk>', 'n@@', 'der@@', 'n', 'und', 'die', 'M@@', 'at@@', 'h@@', 'em@@', 'ati@@', 'k@@', 'er', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'und', 'das', 'ist', 'eine', 'M@@', 'en@@', 'ge', 'S@@', 'ach@@', 'e,', 'die', 'wir', 'in', 'der', 'Welt', 'ver@@', '<unk>', 'n@@', 'der@@', 'n', 'und', 'die', 'M@@', 'at@@', 'h@@', 'em@@', 'ati@@', 'k@@', 'er', 'zu', 'ver@@', 'w@@', 'end@@', 'en.', '</s>']
2025-05-29 19:47:31,657 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:47:31,657 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:47:31,657 - INFO - joeynmt.training - 	Hypothesis: Das ist ein sehr schwieriges Beispiel der Stra<unk> e von der Stra<unk> e zu verwenden, und das ist eine sehr wichtige Sache, die wir in der Welt ver<unk> ndern und die Mathematiker zu verwenden, und das ist eine Menge Sache, die wir in der Welt ver<unk> ndern und die Mathematiker zu verwenden.
2025-05-29 19:47:31,657 - INFO - joeynmt.training - Example #3
2025-05-29 19:47:31,657 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:47:31,657 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:47:31,657 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'ein', 'sehr', 'sch@@', 'wi@@', 'er@@', 'ig@@', 'es', 'M@@', '<unk>', 'd@@', 'chen', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'und', 'das', 'ist', 'eine', 'M@@', 'en@@', 'ge', 'S@@', 'ach@@', 'e.', '</s>']
2025-05-29 19:47:31,657 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:47:31,657 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:47:31,657 - INFO - joeynmt.training - 	Hypothesis: Es ist ein sehr schwieriges M<unk> dchen und die M<unk> glichkeit der K<unk> rper zu verwenden, und das ist eine Menge Sache.
2025-05-29 19:47:31,657 - INFO - joeynmt.training - Example #4
2025-05-29 19:47:31,657 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:47:31,657 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:47:31,657 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'An@@', 't@@', 'w@@', 'ort', 'ist', 'eine', 'sehr', 'wichtig@@', 'e', 'S@@', 'ache', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'die', 'wir', 'in', 'der', 'L@@', 'age', 'f@@', '<unk>', 'r', 'die', 'K@@', 'ar@@', 'te', 'von', 'S@@', 'o@@', 'zi@@', 'al@@', '.', '</s>']
2025-05-29 19:47:31,657 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:47:31,658 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:47:31,658 - INFO - joeynmt.training - 	Hypothesis: Die Antwort ist eine sehr wichtige Sache zu verwenden, die wir in der Lage f<unk> r die Karte von Sozial.
2025-05-29 19:47:33,705 - INFO - joeynmt.training - Epoch   8, Step:    37600, Batch Loss:     2.187275, Batch Acc: 0.324439, Tokens per Sec:    33025, Lr: 0.000300
2025-05-29 19:47:35,540 - INFO - joeynmt.training - Epoch   8, Step:    37700, Batch Loss:     2.189220, Batch Acc: 0.324048, Tokens per Sec:    38439, Lr: 0.000300
2025-05-29 19:47:37,337 - INFO - joeynmt.training - Epoch   8, Step:    37800, Batch Loss:     2.201145, Batch Acc: 0.323091, Tokens per Sec:    40233, Lr: 0.000300
2025-05-29 19:47:39,314 - INFO - joeynmt.training - Epoch   8, Step:    37900, Batch Loss:     2.202725, Batch Acc: 0.320273, Tokens per Sec:    34707, Lr: 0.000300
2025-05-29 19:47:41,067 - INFO - joeynmt.training - Epoch   8, Step:    38000, Batch Loss:     2.214415, Batch Acc: 0.324555, Tokens per Sec:    40908, Lr: 0.000300
2025-05-29 19:47:41,067 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:47:41,068 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:47:54,432 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.23, ppl:   9.27, acc:   0.33, generation: 13.3558[sec], evaluation: 0.0000[sec]
2025-05-29 19:47:54,515 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/36000.ckpt
2025-05-29 19:47:54,521 - INFO - joeynmt.training - Example #0
2025-05-29 19:47:54,522 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:47:54,522 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:47:54,522 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'eine', 'M@@', 'en@@', 'ge', 'S@@', 'ach@@', 'e,', 'die', 'ich', 'mich', 'in', 'der', 'M@@', '<unk>', 'n@@', 'n@@', 'chen', '<unk>', '<unk>', 'ber', 'die', 'Welt', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:47:54,522 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:47:54,522 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:47:54,522 - INFO - joeynmt.training - 	Hypothesis: Ich habe eine Menge Sache, die ich mich in der M<unk> nnchen <unk> <unk> ber die Welt ver<unk> ndern.
2025-05-29 19:47:54,522 - INFO - joeynmt.training - Example #1
2025-05-29 19:47:54,522 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:47:54,522 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:47:54,522 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'M@@', '<unk>', 'n@@', 'n@@', 'er,', 'die', 'ich', 'nicht', 'nur', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:47:54,522 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:47:54,522 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:47:54,522 - INFO - joeynmt.training - 	Hypothesis: Und das ist die M<unk> glichkeit der M<unk> nner, die ich nicht nur die M<unk> glichkeit der K<unk> rper zu ver<unk> ndern.
2025-05-29 19:47:54,522 - INFO - joeynmt.training - Example #2
2025-05-29 19:47:54,523 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:47:54,523 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:47:54,523 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'M@@', '<unk>', 'n@@', 'n@@', 'er,', 'die', 'ich', 'in', 'der', 'H@@', '<unk>', 'h@@', 'e', 'von', 'der', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:47:54,523 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:47:54,523 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:47:54,523 - INFO - joeynmt.training - 	Hypothesis: Und das ist die M<unk> glichkeit der M<unk> nner, die ich in der H<unk> he von der K<unk> rper zu ver<unk> ndern.
2025-05-29 19:47:54,523 - INFO - joeynmt.training - Example #3
2025-05-29 19:47:54,523 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:47:54,523 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:47:54,523 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'die', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'die', 'ich', 'f@@', '<unk>', 'r', 'mich', 'zu', 'er@@', 'kl@@', '<unk>', 'r@@', 'en,', 'dass', 'ich', 'es', 'nicht', 'nur', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'und', 'ich', 'm@@', '<unk>', 'chte', 'mich', 'zu', 'er@@', 'kl@@', '<unk>', 'r@@', 'en,', 'dass', 'ich', 'es', 'nicht', 'nur', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 't,', 'die', 'wir', 'in', 'der', 'Welt', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:47:54,523 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:47:54,523 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:47:54,523 - INFO - joeynmt.training - 	Hypothesis: Und das ist die K<unk> rper, die ich f<unk> r mich zu erkl<unk> ren, dass ich es nicht nur ein paar Minuten und ich m<unk> chte mich zu erkl<unk> ren, dass ich es nicht nur ein paar Minuten und die M<unk> glichkeit, die wir in der Welt ver<unk> ndern.
2025-05-29 19:47:54,523 - INFO - joeynmt.training - Example #4
2025-05-29 19:47:54,524 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:47:54,524 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:47:54,524 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'er,', 'die', 'ich', 'Ihnen', 'zeig@@', 'en', 'm@@', '<unk>', 'ss@@', 'en,', 'dass', 'ich', 'es', 'nicht', 'nur', 'ein', 'paar', 'Bei@@', 'spiel@@', 'e', 'f@@', '<unk>', 'r', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:47:54,524 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:47:54,524 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:47:54,524 - INFO - joeynmt.training - 	Hypothesis: Und das ist die M<unk> nner, die ich Ihnen zeigen m<unk> ssen, dass ich es nicht nur ein paar Beispiele f<unk> r die K<unk> rper zu ver<unk> ndern.
2025-05-29 19:47:56,548 - INFO - joeynmt.training - Epoch   8, Step:    38100, Batch Loss:     2.193082, Batch Acc: 0.320822, Tokens per Sec:    33956, Lr: 0.000300
2025-05-29 19:47:58,636 - INFO - joeynmt.training - Epoch   8, Step:    38200, Batch Loss:     2.294641, Batch Acc: 0.316541, Tokens per Sec:    34052, Lr: 0.000300
2025-05-29 19:48:00,766 - INFO - joeynmt.training - Epoch   8, Step:    38300, Batch Loss:     2.164691, Batch Acc: 0.319390, Tokens per Sec:    32257, Lr: 0.000300
2025-05-29 19:48:03,859 - INFO - joeynmt.training - Epoch   8, Step:    38400, Batch Loss:     2.112297, Batch Acc: 0.322659, Tokens per Sec:    22439, Lr: 0.000300
2025-05-29 19:48:05,959 - INFO - joeynmt.training - Epoch   8, Step:    38500, Batch Loss:     2.144278, Batch Acc: 0.321671, Tokens per Sec:    33625, Lr: 0.000300
2025-05-29 19:48:05,959 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:48:05,959 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:48:17,595 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.23, ppl:   9.26, acc:   0.33, generation: 11.6282[sec], evaluation: 0.0000[sec]
2025-05-29 19:48:17,677 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/35500.ckpt
2025-05-29 19:48:17,683 - INFO - joeynmt.training - Example #0
2025-05-29 19:48:17,683 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:48:17,684 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:48:17,684 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'Ihnen', 'einen', 'W@@', 'eg', 'ge@@', 'fun@@', 'den,', 'um', 'die', 'ich', 'Ihnen', 'zeig@@', 'en,', 'wie', 'ich', 'das', 'H@@', 'aus', 'und', 'der', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'Fr@@', 'auen', 'in', 'den', 'letz@@', 'ten', '1@@', '0@@', '0@@', 'ern', 'in', 'der', 'Welt', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:48:17,684 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:48:17,684 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:48:17,684 - INFO - joeynmt.training - 	Hypothesis: Ich habe Ihnen einen Weg gefunden, um die ich Ihnen zeigen, wie ich das Haus und der M<unk> nner und Frauen in den letzten 100ern in der Welt zu erreichen.
2025-05-29 19:48:17,684 - INFO - joeynmt.training - Example #1
2025-05-29 19:48:17,684 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:48:17,684 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:48:17,684 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'die', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'die', 'ich', 'in', 'der', 'L@@', 'age', 'f@@', '<unk>', 'r', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'Welt', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:48:17,684 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:48:17,684 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:48:17,684 - INFO - joeynmt.training - 	Hypothesis: Und das ist die K<unk> rper, die ich in der Lage f<unk> r die M<unk> glichkeit der Welt zu ver<unk> ndern.
2025-05-29 19:48:17,684 - INFO - joeynmt.training - Example #2
2025-05-29 19:48:17,684 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:48:17,684 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:48:17,684 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Das', 'ist', 'ein', 'g@@', 'ro@@', '<unk>', 'es', 'Pro@@', 'bl@@', 'em', 'in', 'der', 'L@@', 'age', 'der', 'S@@', 'tra@@', '<unk>', 'e', 'der', 'K@@', 'li@@', 'ma@@', 'w@@', 'andel@@', '.', '</s>']
2025-05-29 19:48:17,685 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:48:17,685 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:48:17,685 - INFO - joeynmt.training - 	Hypothesis: Das ist ein gro<unk> es Problem in der Lage der Stra<unk> e der Klimawandel.
2025-05-29 19:48:17,685 - INFO - joeynmt.training - Example #3
2025-05-29 19:48:17,685 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:48:17,685 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:48:17,685 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'ein', 'sehr', 'sch@@', '<unk>', 'n@@', 'er', 'M@@', '<unk>', 'n@@', 'n@@', 'er,', 'der', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:48:17,685 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:48:17,685 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:48:17,685 - INFO - joeynmt.training - 	Hypothesis: Es ist ein sehr sch<unk> ner M<unk> nner, der die K<unk> rper zu ver<unk> ndern.
2025-05-29 19:48:17,685 - INFO - joeynmt.training - Example #4
2025-05-29 19:48:17,685 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:48:17,685 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:48:17,685 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Das', 'ist', 'die', 'An@@', 't@@', 'w@@', 'ort', 'auf', 'die', 'S@@', 'ei@@', 'te', 'der', 'Welt', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:48:17,685 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:48:17,685 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:48:17,685 - INFO - joeynmt.training - 	Hypothesis: Das ist die Antwort auf die Seite der Welt zu ver<unk> ndern.
2025-05-29 19:48:19,839 - INFO - joeynmt.training - Epoch   8, Step:    38600, Batch Loss:     2.265811, Batch Acc: 0.320281, Tokens per Sec:    31317, Lr: 0.000300
2025-05-29 19:48:21,962 - INFO - joeynmt.training - Epoch   8, Step:    38700, Batch Loss:     2.174566, Batch Acc: 0.322900, Tokens per Sec:    33196, Lr: 0.000300
2025-05-29 19:48:24,018 - INFO - joeynmt.training - Epoch   8, Step:    38800, Batch Loss:     2.106843, Batch Acc: 0.320845, Tokens per Sec:    35413, Lr: 0.000300
2025-05-29 19:48:25,987 - INFO - joeynmt.training - Epoch   8, Step:    38900, Batch Loss:     2.028931, Batch Acc: 0.324736, Tokens per Sec:    35826, Lr: 0.000300
2025-05-29 19:48:27,869 - INFO - joeynmt.training - Epoch   8, Step:    39000, Batch Loss:     2.196009, Batch Acc: 0.320009, Tokens per Sec:    36700, Lr: 0.000300
2025-05-29 19:48:27,869 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:48:27,869 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:48:42,530 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.22, ppl:   9.20, acc:   0.33, generation: 14.6500[sec], evaluation: 0.0000[sec]
2025-05-29 19:48:42,531 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:48:42,612 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/36500.ckpt
2025-05-29 19:48:42,618 - INFO - joeynmt.training - Example #0
2025-05-29 19:48:42,618 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:48:42,618 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:48:42,618 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'eine', 'M@@', 'en@@', 'ge', 'S@@', 'ach@@', 'e,', 'die', 'ich', 'in', 'den', 'letz@@', 'ten', '1@@', '0@@', 'ern', 'und', 'd@@', 'an@@', 'k', 'der', 'S@@', 'tra@@', '<unk>', 'e', 'der', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'F@@', '<unk>', 'h@@', 'ig@@', 'kei@@', 'ten', 'in', 'den', 'U@@', 'S@@', 'A', 'und', 'der', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'von', 'den', 'F@@', '<unk>', 'h@@', 'ig@@', 'kei@@', 'ten', 'der', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'in', 'den', 'U@@', 'S@@', 'A', 'und', 'die', 'W@@', 'ahr@@', 'heit', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'und', 'die', 'F@@', '<unk>', 'h@@', 'ig@@', 'kei@@', 'ten', 'der', 'S@@', 'tra@@', '<unk>', 'en']
2025-05-29 19:48:42,618 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:48:42,618 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:48:42,618 - INFO - joeynmt.training - 	Hypothesis: Ich habe eine Menge Sache, die ich in den letzten 10ern und dank der Stra<unk> e der K<unk> rper und die F<unk> higkeiten in den USA und der K<unk> rper und die M<unk> glichkeit von den F<unk> higkeiten der K<unk> rper und die M<unk> glichkeit der M<unk> glichkeiten in den USA und die Wahrheit und die M<unk> glichkeiten und die F<unk> higkeiten der Stra<unk> en
2025-05-29 19:48:42,618 - INFO - joeynmt.training - Example #1
2025-05-29 19:48:42,618 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:48:42,618 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:48:42,618 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:48:42,618 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:48:42,619 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:48:42,619 - INFO - joeynmt.training - 	Hypothesis: Und das ist die K<unk> rper und die M<unk> glichkeit der K<unk> rper und die M<unk> glichkeit der K<unk> rper zu erreichen.
2025-05-29 19:48:42,619 - INFO - joeynmt.training - Example #2
2025-05-29 19:48:42,619 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:48:42,619 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:48:42,619 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'mei@@', 'sten', 'von', 'uns', 'haben', 'die', 'F@@', '<unk>', 'h@@', 'ig@@', 'kei@@', 'ten', 'in', 'der', 'L@@', 'u@@', 'ft', 'der', 'S@@', 'tra@@', '<unk>', 'e', 'der', 'K@@', 'li@@', 'ma@@', 'w@@', 'andel@@', ',', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'K@@', 'li@@', 'ma@@', 'w@@', 'andel@@', ',', 'die', 'wir', 'in', 'der', 'Welt', 'ver@@', '<unk>', 'n@@', 'der@@', 't', 'und', 'die', 'K@@', 'li@@', 'ma@@', 'w@@', 'andel@@', ',', 'die', 'wir', 'in', 'der', 'Welt', 'ver@@', '<unk>', 'n@@', 'der@@', 't', 'haben.', '</s>']
2025-05-29 19:48:42,619 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:48:42,619 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:48:42,619 - INFO - joeynmt.training - 	Hypothesis: Die meisten von uns haben die F<unk> higkeiten in der Luft der Stra<unk> e der Klimawandel, und die M<unk> glichkeit der Klimawandel, die wir in der Welt ver<unk> ndert und die Klimawandel, die wir in der Welt ver<unk> ndert haben.
2025-05-29 19:48:42,619 - INFO - joeynmt.training - Example #3
2025-05-29 19:48:42,619 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:48:42,619 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:48:42,619 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'ein', 'g@@', 'ro@@', '<unk>', 'es', 'Bei@@', 'spi@@', 'el', 'der', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', 'ar@@', 'te', 'der', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n', 'und', 'die', 'K@@', 'ar@@', 'te', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:48:42,619 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:48:42,619 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:48:42,619 - INFO - joeynmt.training - 	Hypothesis: Es ist ein gro<unk> es Beispiel der K<unk> rper und die Karte der K<unk> rper und die K<unk> rper zu ver<unk> ndern und die Karte zu erreichen.
2025-05-29 19:48:42,619 - INFO - joeynmt.training - Example #4
2025-05-29 19:48:42,620 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:48:42,620 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:48:42,620 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'mei@@', 'sten', 'Leute', 'k@@', '<unk>', 'n@@', 'nen', 'sich', 'die', 'S@@', 'tra@@', '<unk>', 'e', 'der', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:48:42,620 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:48:42,620 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:48:42,620 - INFO - joeynmt.training - 	Hypothesis: Die meisten Leute k<unk> nnen sich die Stra<unk> e der K<unk> rper und die M<unk> glichkeit der K<unk> rper und die M<unk> glichkeit der K<unk> rper zu erreichen.
2025-05-29 19:48:44,691 - INFO - joeynmt.training - Epoch   8, Step:    39100, Batch Loss:     2.214734, Batch Acc: 0.321697, Tokens per Sec:    33650, Lr: 0.000300
2025-05-29 19:48:46,728 - INFO - joeynmt.training - Epoch   8, Step:    39200, Batch Loss:     2.262883, Batch Acc: 0.321238, Tokens per Sec:    35784, Lr: 0.000300
2025-05-29 19:48:48,744 - INFO - joeynmt.training - Epoch   8, Step:    39300, Batch Loss:     2.136657, Batch Acc: 0.322317, Tokens per Sec:    34477, Lr: 0.000300
2025-05-29 19:48:50,745 - INFO - joeynmt.training - Epoch   8, Step:    39400, Batch Loss:     2.296907, Batch Acc: 0.321742, Tokens per Sec:    34381, Lr: 0.000300
2025-05-29 19:48:52,738 - INFO - joeynmt.training - Epoch   8, Step:    39500, Batch Loss:     2.251969, Batch Acc: 0.319464, Tokens per Sec:    34891, Lr: 0.000300
2025-05-29 19:48:52,738 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:48:52,738 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:49:06,900 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.22, ppl:   9.20, acc:   0.33, generation: 14.1504[sec], evaluation: 0.0000[sec]
2025-05-29 19:49:06,982 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/38000.ckpt
2025-05-29 19:49:06,988 - INFO - joeynmt.training - Example #0
2025-05-29 19:49:06,988 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:49:06,988 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:49:06,988 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'mich', 'ge@@', 'fun@@', 'den,', 'dass', 'ich', 'die', 'K@@', '<unk>', 'r@@', 'z@@', 'te', 'und', 'ich', 'habe', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'von', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'von', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'von', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'in', 'der', 'L@@', 'u@@', 'ft', 'in', 'die', 'L@@', 'u@@', 'ft', 'in', 'die', 'L@@', 'u@@', 'ft', 'in', 'die', 'L@@', 'u@@', 'ft', 'in', 'die', 'L@@', 'u@@', 'ft', 'in', 'die', 'L@@', 'u@@', 'ft', 'der', 'in', 'den', 'U@@', 'S@@', 'A', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'F@@', '<unk>', 'h@@', 'ig@@']
2025-05-29 19:49:06,989 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:49:06,989 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:49:06,989 - INFO - joeynmt.training - 	Hypothesis: Ich habe mich gefunden, dass ich die K<unk> rzte und ich habe die M<unk> glichkeit von M<unk> nnern und die K<unk> rper und die M<unk> glichkeit von M<unk> nnern und die K<unk> rper und die M<unk> glichkeit von M<unk> nnern in der Luft in die Luft in die Luft in die Luft in die Luft in die Luft der in den USA und die K<unk> rper und die F<unk> hig
2025-05-29 19:49:06,989 - INFO - joeynmt.training - Example #1
2025-05-29 19:49:06,989 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:49:06,989 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:49:06,989 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'die', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'die', 'wir', 'in', 'der', 'L@@', 'u@@', 'ft', 'der', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', 'w@@', 'andel@@', 'n.', '</s>']
2025-05-29 19:49:06,989 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:49:06,989 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:49:06,989 - INFO - joeynmt.training - 	Hypothesis: Und das ist die K<unk> rper, die wir in der Luft der K<unk> rper und die K<unk> rper und die K<unk> rper zu verwandeln.
2025-05-29 19:49:06,989 - INFO - joeynmt.training - Example #2
2025-05-29 19:49:06,989 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:49:06,989 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:49:06,989 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'K@@', 'li@@', 'ma@@', 'w@@', 'andel@@', ',', 'die', 'ich', 'in', 'einem', 'L@@', 'and', 'in', 'einem', 'K@@', 'li@@', 'ma@@', 'w@@', 'andel@@', ',', 'der', 'die', 'K@@', 'li@@', 'ma@@', 'w@@', 'andel@@', ',', 'die', 'wir', 'in', 'der', 'L@@', 'age', 'sein,', 'die', 'wir', 'in', 'der', 'L@@', 'age', 'sein,', 'die', 'wir', 'in', 'der', 'L@@', 'age', 'sein,', 'die', 'wir', 'in', 'der', 'K@@', 'li@@', 'ma@@', 'w@@', 'andel@@', 'n,', 'die', 'wir', 'in', 'der', 'L@@', 'age', 'sein,', 'die', 'wir', 'in', 'der', 'L@@', 'u@@', 'ft', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:49:06,990 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:49:06,990 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:49:06,990 - INFO - joeynmt.training - 	Hypothesis: Die Klimawandel, die ich in einem Land in einem Klimawandel, der die Klimawandel, die wir in der Lage sein, die wir in der Lage sein, die wir in der Lage sein, die wir in der Klimawandeln, die wir in der Lage sein, die wir in der Luft ver<unk> ndern.
2025-05-29 19:49:06,990 - INFO - joeynmt.training - Example #3
2025-05-29 19:49:06,990 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:49:06,990 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:49:06,990 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'eine', 'sehr', 'sch@@', 'wi@@', 'er@@', 'ig@@', ',', 'die', 'wir', 'in', 'der', 'L@@', 'u@@', 'ft', 'zu', 'mach@@', 'en.', '</s>']
2025-05-29 19:49:06,990 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:49:06,990 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:49:06,990 - INFO - joeynmt.training - 	Hypothesis: Es ist eine sehr schwierig, die wir in der Luft zu machen.
2025-05-29 19:49:06,990 - INFO - joeynmt.training - Example #4
2025-05-29 19:49:06,990 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:49:06,990 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:49:06,990 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'K@@', '<unk>', 'r@@', 'z@@', 'te', 'ist', 'die', 'K@@', '<unk>', 'r@@', 'z@@', 'lich', 'der', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:49:06,990 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:49:06,990 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:49:06,990 - INFO - joeynmt.training - 	Hypothesis: Die K<unk> rzte ist die K<unk> rzlich der K<unk> rper und die K<unk> rper und die K<unk> rper und die K<unk> rper zu ver<unk> ndern.
2025-05-29 19:49:10,170 - INFO - joeynmt.training - Epoch   8, Step:    39600, Batch Loss:     2.159387, Batch Acc: 0.318395, Tokens per Sec:    20612, Lr: 0.000300
2025-05-29 19:49:12,260 - INFO - joeynmt.training - Epoch   8, Step:    39700, Batch Loss:     2.137530, Batch Acc: 0.319130, Tokens per Sec:    34638, Lr: 0.000300
2025-05-29 19:49:14,433 - INFO - joeynmt.training - Epoch   8, Step:    39800, Batch Loss:     2.236889, Batch Acc: 0.320689, Tokens per Sec:    33046, Lr: 0.000300
2025-05-29 19:49:16,495 - INFO - joeynmt.training - Epoch   8, Step:    39900, Batch Loss:     2.266951, Batch Acc: 0.319942, Tokens per Sec:    34875, Lr: 0.000300
2025-05-29 19:49:18,571 - INFO - joeynmt.training - Epoch   8, Step:    40000, Batch Loss:     2.149107, Batch Acc: 0.321226, Tokens per Sec:    32818, Lr: 0.000300
2025-05-29 19:49:18,571 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:49:18,572 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:49:33,708 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.22, ppl:   9.20, acc:   0.33, generation: 15.1205[sec], evaluation: 0.0000[sec]
2025-05-29 19:49:33,709 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:49:33,791 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/38500.ckpt
2025-05-29 19:49:33,797 - INFO - joeynmt.training - Example #0
2025-05-29 19:49:33,797 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:49:33,797 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:49:33,797 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'eine', 'M@@', 'en@@', 'ge', 'von', 'der', 'M@@', '<unk>', 'glich@@', 'kei@@', 't,', 'die', 'ich', 'mit', 'der', 'F@@', 'ami@@', 'li@@', 'e', 'von', 'der', 'M@@', '<unk>', 'glich@@', 'kei@@', 't,', 'die', 'ich', 'in', 'den', '19@@', '8@@', '0@@', 'ern', 'in', 'der', 'L@@', 'age', 'in', 'der', 'L@@', 'age', 'in', 'der', 'L@@', 'age', 'in', 'der', 'L@@', 'age', 'in', 'der', 'L@@', 'age', 'in', 'der', 'L@@', 'age', 'in', 'den', '19@@', '8@@', '0@@', 'ern', 'in', 'der', 'L@@', 'age', 'in', 'den', '19@@', '8@@', '0@@', 'ern', 'und', 'der', 'M@@', 'itt@@', 'el@@', ',', 'die', 'die', 'in', 'den', '19@@', '8@@', '0@@', 'ern', 'und', '1@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', ',', 'die', 'ich', 'in']
2025-05-29 19:49:33,797 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:49:33,797 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:49:33,797 - INFO - joeynmt.training - 	Hypothesis: Ich habe eine Menge von der M<unk> glichkeit, die ich mit der Familie von der M<unk> glichkeit, die ich in den 1980ern in der Lage in der Lage in der Lage in der Lage in der Lage in der Lage in den 1980ern in der Lage in den 1980ern und der Mittel, die die in den 1980ern und 10000000000000000, die ich in
2025-05-29 19:49:33,797 - INFO - joeynmt.training - Example #1
2025-05-29 19:49:33,798 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:49:33,798 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:49:33,798 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'eine', 'M@@', 'en@@', 'ge', 'von', 'der', 'M@@', '<unk>', 'n@@', 'n@@', 'er,', 'die', 'ich', 'nicht', 'so', 'viel', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:49:33,798 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:49:33,798 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:49:33,798 - INFO - joeynmt.training - 	Hypothesis: Und ich habe eine Menge von der M<unk> nner, die ich nicht so viel zu ver<unk> ndern.
2025-05-29 19:49:33,798 - INFO - joeynmt.training - Example #2
2025-05-29 19:49:33,798 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:49:33,798 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:49:33,798 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'eine', 'M@@', 'en@@', 'ge', 'an', 'der', 'S@@', 'tra@@', '<unk>', 'e', 'in', 'der', 'L@@', 'age', 'ges@@', 'am@@', 'te', 'und', 'ich', 'habe', 'eine', 'M@@', 'en@@', 'ge', 'von', 'der', 'K@@', 'li@@', 'ma@@', 'w@@', 'an@@', 'del', 'in', 'der', 'L@@', 'age', 'f@@', '<unk>', 'r', 'die', 'K@@', 'li@@', 'ma@@', 'w@@', 'andel@@', ',', 'die', 'ich', 'in', 'der', 'K@@', 'li@@', 'ma@@', 'w@@', 'an@@', 'del', 'in', 'der', 'L@@', 'age', 'f@@', '<unk>', 'r', 'die', 'K@@', 'li@@', 'ma@@', 'w@@', 'an@@', 'del', 'zu', 'er@@', 'm@@', '<unk>', 'glich@@', 'en.', '</s>']
2025-05-29 19:49:33,798 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:49:33,798 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:49:33,798 - INFO - joeynmt.training - 	Hypothesis: Und ich habe eine Menge an der Stra<unk> e in der Lage gesamte und ich habe eine Menge von der Klimawandel in der Lage f<unk> r die Klimawandel, die ich in der Klimawandel in der Lage f<unk> r die Klimawandel zu erm<unk> glichen.
2025-05-29 19:49:33,798 - INFO - joeynmt.training - Example #3
2025-05-29 19:49:33,798 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:49:33,798 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:49:33,798 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'eine', 'der', 'K@@', '<unk>', 'h@@', 'l@@', 'ung', 'und', 'die', 'K@@', '<unk>', 'n@@', 'st@@', 'l@@', 'er@@', 'in', 'und', 'die', 'K@@', 'rank@@', 'heit', 'und', 'die', 'K@@', 'rank@@', 'heit', 'der', 'K@@', '<unk>', 'h@@', 'l@@', 'er@@', 'in', 'und', 'die', 'K@@', 'rank@@', 'hei@@', 'ten', 'und', 'die', 'K@@', 'rank@@', 'heit', 'der', 'K@@', 'op@@', 'f@@', '.', '</s>']
2025-05-29 19:49:33,799 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:49:33,799 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:49:33,799 - INFO - joeynmt.training - 	Hypothesis: Es ist eine der K<unk> hlung und die K<unk> nstlerin und die Krankheit und die Krankheit der K<unk> hlerin und die Krankheiten und die Krankheit der Kopf.
2025-05-29 19:49:33,799 - INFO - joeynmt.training - Example #4
2025-05-29 19:49:33,799 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:49:33,799 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:49:33,799 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'S@@', 'ache', 'ist', 'also', 'die', 'K@@', '<unk>', 'n@@', 'st@@', 'ler', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 't,', 'die', 'ich', 'in', 'der', 'L@@', 'age', 'in', 'den', 'letz@@', 'ten', '1@@', '5', 'Jahr@@', 'e.', '</s>']
2025-05-29 19:49:33,799 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:49:33,799 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:49:33,799 - INFO - joeynmt.training - 	Hypothesis: Die Sache ist also die K<unk> nstler und die M<unk> glichkeit, die ich in der Lage in den letzten 15 Jahre.
2025-05-29 19:49:35,920 - INFO - joeynmt.training - Epoch   8, Step:    40100, Batch Loss:     2.153064, Batch Acc: 0.317718, Tokens per Sec:    31082, Lr: 0.000300
2025-05-29 19:49:37,773 - INFO - joeynmt.training - Epoch   8, Step:    40200, Batch Loss:     2.316011, Batch Acc: 0.316871, Tokens per Sec:    37797, Lr: 0.000300
2025-05-29 19:49:39,547 - INFO - joeynmt.training - Epoch   8, Step:    40300, Batch Loss:     2.056553, Batch Acc: 0.320730, Tokens per Sec:    39637, Lr: 0.000300
2025-05-29 19:49:41,557 - INFO - joeynmt.training - Epoch   8, Step:    40400, Batch Loss:     2.296942, Batch Acc: 0.319963, Tokens per Sec:    34363, Lr: 0.000300
2025-05-29 19:49:44,705 - INFO - joeynmt.training - Epoch   8, Step:    40500, Batch Loss:     2.259269, Batch Acc: 0.319365, Tokens per Sec:    22638, Lr: 0.000300
2025-05-29 19:49:44,705 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:49:44,705 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:49:58,825 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.22, ppl:   9.18, acc:   0.33, generation: 14.1077[sec], evaluation: 0.0000[sec]
2025-05-29 19:49:58,825 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:49:58,907 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/37500.ckpt
2025-05-29 19:49:58,912 - INFO - joeynmt.training - Example #0
2025-05-29 19:49:58,913 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:49:58,913 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:49:58,913 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'mich', 'ge@@', 'frag@@', 't,', 'ob', 'ich', 'es', 'mit', 'den', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 't,', 'die', 'ich', 'Ihnen', 'zeig@@', 'en,', 'wie', 'ich', 'das', 'er@@', 'ste', 'M@@', 'al', 'in', 'den', '19@@', '7@@', '0@@', 'ern', 'in', 'der', 'L@@', 'age', 'sein,', 'die', 'in', 'den', '19@@', '7@@', '0@@', 'ern', 'in', 'der', 'L@@', 'age', 'ist.', '</s>']
2025-05-29 19:49:58,913 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:49:58,913 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:49:58,913 - INFO - joeynmt.training - 	Hypothesis: Ich habe mich gefragt, ob ich es mit den M<unk> nnern und die M<unk> glichkeit, die ich Ihnen zeigen, wie ich das erste Mal in den 1970ern in der Lage sein, die in den 1970ern in der Lage ist.
2025-05-29 19:49:58,913 - INFO - joeynmt.training - Example #1
2025-05-29 19:49:58,913 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:49:58,913 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:49:58,913 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'die', 'K@@', 'un@@', 'st', 'der', 'M@@', 'itt@@', 'el@@', 'm@@', '<unk>', '<unk>', 'i@@', 'g', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:49:58,913 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:49:58,913 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:49:58,913 - INFO - joeynmt.training - 	Hypothesis: Und das ist die Kunst der Mittelm<unk> <unk> ig zu erreichen.
2025-05-29 19:49:58,913 - INFO - joeynmt.training - Example #2
2025-05-29 19:49:58,913 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:49:58,913 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:49:58,913 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'er@@', 'ste', 'ist', 'die', 'K@@', 'un@@', 'st', 'in', 'der', 'L@@', 'age', 'f@@', '<unk>', 'r', 'die', 'K@@', 'l@@', 'ein@@', 'k@@', '<unk>', 'n@@', 'nen', 'und', 'die', 'M@@', 'at@@', 'h@@', 'em@@', 'ati@@', 'k', 'ver@@', 'st@@', '<unk>', 'n@@', 'd@@', 'lich@@', '.', '</s>']
2025-05-29 19:49:58,914 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:49:58,914 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:49:58,914 - INFO - joeynmt.training - 	Hypothesis: Die erste ist die Kunst in der Lage f<unk> r die Kleink<unk> nnen und die Mathematik verst<unk> ndlich.
2025-05-29 19:49:58,914 - INFO - joeynmt.training - Example #3
2025-05-29 19:49:58,914 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:49:58,914 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:49:58,914 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'ein', 'kl@@', 'eines', 'T@@', 'ag@@', 'es', 'und', 'das', 'ist', 'ein', 'M@@', '<unk>', 'd@@', 'chen', 'in', 'der', 'L@@', 'age', 'f@@', '<unk>', 'r', 'die', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'die', 'ich', 'in', 'der', 'L@@', 'age', 'sp@@', '<unk>', 'ter', 'zu', 'ver@@', 'w@@', 'end@@', 'en.', '</s>']
2025-05-29 19:49:58,914 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:49:58,914 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:49:58,914 - INFO - joeynmt.training - 	Hypothesis: Es ist ein kleines Tages und das ist ein M<unk> dchen in der Lage f<unk> r die K<unk> rper, die ich in der Lage sp<unk> ter zu verwenden.
2025-05-29 19:49:58,914 - INFO - joeynmt.training - Example #4
2025-05-29 19:49:58,914 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:49:58,914 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:49:58,914 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'er@@', 'ste', 'ist', 'die', 'K@@', '<unk>', 'n@@', 'st@@', 'ler', 'der', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'die', 'ich', 'in', 'der', 'L@@', 'age', 'f@@', '<unk>', 'r', 'die', 'K@@', '<unk>', 'n@@', 'st@@', 'ler', 'der', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'die', 'ich', 'in', 'der', 'L@@', 'age', 'f@@', '<unk>', 'r', 'die', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'die', 'ich', 'er@@', 'm@@', '<unk>', 'glich@@', 'e,', 'dass', 'ich', 'nicht', 'nur', 'ein', 'paar', 'T@@', 'ag@@', 'en', 'der', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'die', 'ich', 'er@@', 'm@@', '<unk>', 'glich@@', 'e,', 'dass', 'ich', 'nicht', 'nur', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'in', 'der', 'L@@', 'age', 'ist.', '</s>']
2025-05-29 19:49:58,914 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:49:58,914 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:49:58,914 - INFO - joeynmt.training - 	Hypothesis: Die erste ist die K<unk> nstler der K<unk> rper, die ich in der Lage f<unk> r die K<unk> nstler der K<unk> rper, die ich in der Lage f<unk> r die K<unk> rper, die ich erm<unk> gliche, dass ich nicht nur ein paar Tagen der K<unk> rper, die ich erm<unk> gliche, dass ich nicht nur ein paar Minuten in der Lage ist.
2025-05-29 19:50:01,050 - INFO - joeynmt.training - Epoch   8, Step:    40600, Batch Loss:     2.325788, Batch Acc: 0.316519, Tokens per Sec:    30369, Lr: 0.000300
2025-05-29 19:50:02,880 - INFO - joeynmt.training - Epoch   8, Step:    40700, Batch Loss:     2.270704, Batch Acc: 0.322672, Tokens per Sec:    39150, Lr: 0.000300
2025-05-29 19:50:04,627 - INFO - joeynmt.training - Epoch   8, Step:    40800, Batch Loss:     2.132342, Batch Acc: 0.318591, Tokens per Sec:    38408, Lr: 0.000300
2025-05-29 19:50:06,441 - INFO - joeynmt.training - Epoch   8, Step:    40900, Batch Loss:     2.271592, Batch Acc: 0.318947, Tokens per Sec:    38085, Lr: 0.000300
2025-05-29 19:50:08,246 - INFO - joeynmt.training - Epoch   8, Step:    41000, Batch Loss:     2.221179, Batch Acc: 0.319664, Tokens per Sec:    39353, Lr: 0.000300
2025-05-29 19:50:08,246 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:50:08,246 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:50:23,879 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.22, ppl:   9.16, acc:   0.33, generation: 15.6212[sec], evaluation: 0.0000[sec]
2025-05-29 19:50:23,880 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:50:23,957 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/37000.ckpt
2025-05-29 19:50:23,963 - INFO - joeynmt.training - Example #0
2025-05-29 19:50:23,963 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:50:23,963 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:50:23,963 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'mei@@', 'sten', 'von', 'uns', 'haben', 'wir', 'die', 'F@@', '<unk>', 'h@@', 'ig@@', 'kei@@', 'ten', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'und', 'die', 'F@@', '<unk>', 'h@@', 'ig@@', 'keit', 'der', 'K@@', 'reb@@', 's', 'in', 'den', 'letz@@', 'ten', '1@@', '5', 'Jahren', 'in', 'den', 'letz@@', 'ten', '3@@', '0', 'Jahren', 'in', 'der', 'L@@', 'age', 'in', 'den', 'letz@@', 'ten', '3@@', '0@@', 'ern', 'und', '1@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '-@@', 'j@@', '<unk>', 'h@@', 'ri@@', 'ge', 'S@@', 'ei@@', 'te', 'der', 'K@@', 'reb@@', 's', 'in', 'den', 'U@@', 'S@@', 'A', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'zu', 'er@@', 'schaff@@', 'en,', 'die', 'in', 'der', 'L@@', 'u@@', 'f@@', 't.', '</s>']
2025-05-29 19:50:23,963 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:50:23,963 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:50:23,963 - INFO - joeynmt.training - 	Hypothesis: Die meisten von uns haben wir die F<unk> higkeiten und die M<unk> glichkeiten und die F<unk> higkeit der Krebs in den letzten 15 Jahren in den letzten 30 Jahren in der Lage in den letzten 30ern und 100000000-j<unk> hrige Seite der Krebs in den USA und die M<unk> glichkeiten zu erschaffen, die in der Luft.
2025-05-29 19:50:23,963 - INFO - joeynmt.training - Example #1
2025-05-29 19:50:23,964 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:50:23,964 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:50:23,964 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'm@@', '<unk>', 'chte', 'Ihnen', 'die', 'F@@', '<unk>', 'h@@', 'ig@@', 'kei@@', 'ten', 'der', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'er@@', 'schaff@@', 'en,', 'die', 'wir', 'nicht', 'nur', 'die', 'K@@', '<unk>', 'r@@', 'per', 'nicht', 'nur', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'er@@', 'schaff@@', 'en,', 'aber', 'es', 'ist', 'nicht', 'nur', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', 'w@@', 'end@@', 'en.', '</s>']
2025-05-29 19:50:23,964 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:50:23,964 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:50:23,964 - INFO - joeynmt.training - 	Hypothesis: Und ich m<unk> chte Ihnen die F<unk> higkeiten der K<unk> rper zu erschaffen, die wir nicht nur die K<unk> rper nicht nur die K<unk> rper zu erschaffen, aber es ist nicht nur ein paar Minuten und die K<unk> rper zu verwenden.
2025-05-29 19:50:23,964 - INFO - joeynmt.training - Example #2
2025-05-29 19:50:23,964 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:50:23,964 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:50:23,964 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'K@@', '<unk>', 'r@@', 'per', 'ist', 'nicht', 'der', 'K@@', '<unk>', 'r@@', 'per', 'in', 'der', 'L@@', 'u@@', 'ft', 'der', 'K@@', 'li@@', 'ma@@', 'w@@', 'an@@', 'del', 'in', 'der', 'L@@', 'u@@', 'ft', 'der', 'K@@', 'li@@', 'ma@@', 'w@@', 'an@@', 'del', 'zu', 'er@@', 'schaff@@', 'en.', '</s>']
2025-05-29 19:50:23,964 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:50:23,964 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:50:23,964 - INFO - joeynmt.training - 	Hypothesis: Die K<unk> rper ist nicht der K<unk> rper in der Luft der Klimawandel in der Luft der Klimawandel zu erschaffen.
2025-05-29 19:50:23,964 - INFO - joeynmt.training - Example #3
2025-05-29 19:50:23,964 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:50:23,964 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:50:23,964 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'ein', 'kl@@', 'eines', 'T@@', 'ag@@', 'es', 'in', 'der', 'L@@', 'u@@', 'f@@', 'ig@@', 'keit', 'der', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'und', 'es', 'ist', 'ein', 'sehr', 'sch@@', 'wi@@', 'er@@', 'ig@@', ',', 'das', 'ist', 'ein', 'M@@', '<unk>', 'd@@', 'chen', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', 'k@@', 'auf@@', 'en.', '</s>']
2025-05-29 19:50:23,964 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:50:23,965 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:50:23,965 - INFO - joeynmt.training - 	Hypothesis: Es ist ein kleines Tages in der Lufigkeit der K<unk> rper und die K<unk> rper zu verwenden, und es ist ein sehr schwierig, das ist ein M<unk> dchen und die K<unk> rper zu verkaufen.
2025-05-29 19:50:23,965 - INFO - joeynmt.training - Example #4
2025-05-29 19:50:23,965 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:50:23,965 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:50:23,965 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'mei@@', 'sten', 'von', 'Ihnen', 'k@@', 'ur@@', 'z', 'von', 'Ihnen', 'k@@', 'einen', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'er@@', 'schaff@@', 'en,', 'die', 'ich', 'Ihnen', 'zeig@@', 'en,', 'wie', 'ich', 'das', 'hier', 'in', 'der', 'Welt', 'zu', 'er@@', 'schaff@@', 'en,', 'und', 'ich', 'habe', 'das', 'nicht', 'gen@@', 'u@@', 'g', '<unk>', 'ber', 'die', 'Welt', 'der', 'K@@', '<unk>', 'r@@', 'per@@', 's', 'zu', 'er@@', 'schaff@@', 'en.', '</s>']
2025-05-29 19:50:23,965 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:50:23,965 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:50:23,965 - INFO - joeynmt.training - 	Hypothesis: Die meisten von Ihnen kurz von Ihnen keinen K<unk> rper zu erschaffen, die ich Ihnen zeigen, wie ich das hier in der Welt zu erschaffen, und ich habe das nicht genug <unk> ber die Welt der K<unk> rpers zu erschaffen.
2025-05-29 19:50:25,977 - INFO - joeynmt.training - Epoch   8, Step:    41100, Batch Loss:     2.239186, Batch Acc: 0.318665, Tokens per Sec:    34072, Lr: 0.000300
2025-05-29 19:50:27,913 - INFO - joeynmt.training - Epoch   8, Step:    41200, Batch Loss:     2.250942, Batch Acc: 0.318985, Tokens per Sec:    35909, Lr: 0.000300
2025-05-29 19:50:29,983 - INFO - joeynmt.training - Epoch   8, Step:    41300, Batch Loss:     2.227603, Batch Acc: 0.316095, Tokens per Sec:    32340, Lr: 0.000300
2025-05-29 19:50:31,892 - INFO - joeynmt.training - Epoch   8, Step:    41400, Batch Loss:     2.233380, Batch Acc: 0.316974, Tokens per Sec:    37822, Lr: 0.000300
2025-05-29 19:50:33,967 - INFO - joeynmt.training - Epoch   8, Step:    41500, Batch Loss:     2.162366, Batch Acc: 0.318381, Tokens per Sec:    34262, Lr: 0.000300
2025-05-29 19:50:33,967 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:50:33,967 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:50:47,750 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.22, ppl:   9.20, acc:   0.33, generation: 13.7723[sec], evaluation: 0.0000[sec]
2025-05-29 19:50:47,825 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/39500.ckpt
2025-05-29 19:50:47,830 - INFO - joeynmt.training - Example #0
2025-05-29 19:50:47,831 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:50:47,831 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:50:47,831 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Das', 'ist', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'der', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'zu', 'ver@@', 'w@@', 'end@@', 'en.', '</s>']
2025-05-29 19:50:47,831 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:50:47,831 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:50:47,831 - INFO - joeynmt.training - 	Hypothesis: Das ist die M<unk> glichkeiten und die M<unk> glichkeiten und die M<unk> glichkeiten der K<unk> rper und die M<unk> glichkeiten zu verwenden.
2025-05-29 19:50:47,831 - INFO - joeynmt.training - Example #1
2025-05-29 19:50:47,831 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:50:47,831 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:50:47,831 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Das', 'ist', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'der', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'der', 'Welt', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:50:47,831 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:50:47,831 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:50:47,831 - INFO - joeynmt.training - 	Hypothesis: Das ist die M<unk> glichkeiten der K<unk> rper und die M<unk> glichkeiten der Welt zu ver<unk> ndern.
2025-05-29 19:50:47,831 - INFO - joeynmt.training - Example #2
2025-05-29 19:50:47,832 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:50:47,832 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:50:47,832 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Das', 'ist', 'ein', 'sehr', 'sch@@', 'wi@@', 'er@@', 'ig@@', 'es', 'Pro@@', 'bl@@', 'em', 'ist', 'ein', 'sehr', 'sch@@', 'wi@@', 'er@@', 'ig@@', '.', '</s>']
2025-05-29 19:50:47,832 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:50:47,832 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:50:47,832 - INFO - joeynmt.training - 	Hypothesis: Das ist ein sehr schwieriges Problem ist ein sehr schwierig.
2025-05-29 19:50:47,832 - INFO - joeynmt.training - Example #3
2025-05-29 19:50:47,832 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:50:47,832 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:50:47,832 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'eine', 'der', 'K@@', 'un@@', 'st@@', 'wer@@', 'k@@', 'e', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'M@@', 'it@@', 'te', 'der', 'M@@', 'it@@', 'te', 'der', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'M@@', 'it@@', 'te', 'der']
2025-05-29 19:50:47,832 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:50:47,832 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:50:47,832 - INFO - joeynmt.training - 	Hypothesis: Es ist eine der Kunstwerke und die M<unk> glichkeiten und die M<unk> glichkeiten und die M<unk> glichkeiten und die M<unk> glichkeiten und die M<unk> glichkeiten und die M<unk> glichkeiten und die M<unk> glichkeiten und die M<unk> glichkeiten und die M<unk> glichkeiten und die M<unk> glichkeiten und die M<unk> glichkeiten und die M<unk> glichkeit der Mitte der Mitte der K<unk> rper und die Mitte der
2025-05-29 19:50:47,832 - INFO - joeynmt.training - Example #4
2025-05-29 19:50:47,832 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:50:47,832 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:50:47,832 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Das', 'ist', 'eine', 'der', 'gr@@', '<unk>', '<unk>', 'te', 'S@@', 'ache', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'die', 'ich', 'in', 'der', 'M@@', 'it@@', 'te', 'der', 'Welt', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:50:47,833 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:50:47,833 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:50:47,833 - INFO - joeynmt.training - 	Hypothesis: Das ist eine der gr<unk> <unk> te Sache zu verwenden, die ich in der Mitte der Welt zu ver<unk> ndern.
2025-05-29 19:50:50,996 - INFO - joeynmt.training - Epoch   8, Step:    41600, Batch Loss:     2.132875, Batch Acc: 0.327042, Tokens per Sec:    22540, Lr: 0.000300
2025-05-29 19:50:53,058 - INFO - joeynmt.training - Epoch   8, Step:    41700, Batch Loss:     2.320213, Batch Acc: 0.318999, Tokens per Sec:    34295, Lr: 0.000300
2025-05-29 19:50:55,142 - INFO - joeynmt.training - Epoch   8, Step:    41800, Batch Loss:     2.144750, Batch Acc: 0.319207, Tokens per Sec:    34593, Lr: 0.000300
2025-05-29 19:50:57,217 - INFO - joeynmt.training - Epoch   8, Step:    41900, Batch Loss:     2.109984, Batch Acc: 0.322398, Tokens per Sec:    33360, Lr: 0.000300
2025-05-29 19:50:59,275 - INFO - joeynmt.training - Epoch   8, Step:    42000, Batch Loss:     2.206069, Batch Acc: 0.319122, Tokens per Sec:    34022, Lr: 0.000300
2025-05-29 19:50:59,275 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:50:59,275 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:51:10,720 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.21, ppl:   9.11, acc:   0.33, generation: 11.4364[sec], evaluation: 0.0000[sec]
2025-05-29 19:51:10,721 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:51:10,806 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/41500.ckpt
2025-05-29 19:51:10,812 - INFO - joeynmt.training - Example #0
2025-05-29 19:51:10,813 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:51:10,813 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:51:10,813 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'mei@@', 'sten', 'von', 'uns', 'haben', 'in', 'den', 'letz@@', 'ten', '1@@', '0@@', '0@@', '0@@', 'ern', 'und', 'der', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'Wel@@', 't.', '</s>']
2025-05-29 19:51:10,813 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:51:10,813 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:51:10,813 - INFO - joeynmt.training - 	Hypothesis: Die meisten von uns haben in den letzten 1000ern und der M<unk> nner und die M<unk> glichkeit der Welt.
2025-05-29 19:51:10,813 - INFO - joeynmt.training - Example #1
2025-05-29 19:51:10,813 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:51:10,813 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:51:10,813 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'm@@', '<unk>', 'chte', 'mich', 'in', 'der', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'ich', 'war', 'nicht', 'nur', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'f@@', '<unk>', 'r', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:51:10,813 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:51:10,814 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:51:10,814 - INFO - joeynmt.training - 	Hypothesis: Und ich m<unk> chte mich in der M<unk> nner und ich war nicht nur ein paar Minuten f<unk> r die M<unk> glichkeiten zu erreichen.
2025-05-29 19:51:10,814 - INFO - joeynmt.training - Example #2
2025-05-29 19:51:10,814 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:51:10,814 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:51:10,814 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'S@@', 'ei@@', 'te', 'der', 'S@@', 'tra@@', '<unk>', 'e', 'ist', 'ein', 'M@@', '<unk>', 'r@@', 'k@@', 'er@@', '-@@', 'K@@', 'ri@@', 'eg@@', 's@@', '-@@', 'K@@', 'ri@@', 'eg@@', 's@@', '-@@', 'K@@', 'li@@', 'ma@@', 'w@@', 'andel@@', '.', '</s>']
2025-05-29 19:51:10,814 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:51:10,814 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:51:10,814 - INFO - joeynmt.training - 	Hypothesis: Die Seite der Stra<unk> e ist ein M<unk> rker-Kriegs-Kriegs-Klimawandel.
2025-05-29 19:51:10,814 - INFO - joeynmt.training - Example #3
2025-05-29 19:51:10,814 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:51:10,814 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:51:10,814 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'ein', 'sehr', 'sch@@', 'wi@@', 'er@@', 'ig@@', 'es', 'M@@', '<unk>', 'n@@', 'n@@', 'er.', '</s>']
2025-05-29 19:51:10,814 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:51:10,814 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:51:10,814 - INFO - joeynmt.training - 	Hypothesis: Es ist ein sehr schwieriges M<unk> nner.
2025-05-29 19:51:10,815 - INFO - joeynmt.training - Example #4
2025-05-29 19:51:10,815 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:51:10,815 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:51:10,815 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'mei@@', 'sten', 'von', 'uns', 'haben', 'eine', 'M@@', 'en@@', 'ge', 'S@@', 'ach@@', 'e.', '</s>']
2025-05-29 19:51:10,815 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:51:10,815 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:51:10,815 - INFO - joeynmt.training - 	Hypothesis: Die meisten von uns haben eine Menge Sache.
2025-05-29 19:51:12,893 - INFO - joeynmt.training - Epoch   8, Step:    42100, Batch Loss:     2.222541, Batch Acc: 0.318525, Tokens per Sec:    31405, Lr: 0.000300
2025-05-29 19:51:15,094 - INFO - joeynmt.training - Epoch   8, Step:    42200, Batch Loss:     2.155541, Batch Acc: 0.319966, Tokens per Sec:    32618, Lr: 0.000300
2025-05-29 19:51:17,016 - INFO - joeynmt.training - Epoch   8, Step:    42300, Batch Loss:     2.129827, Batch Acc: 0.319604, Tokens per Sec:    37436, Lr: 0.000300
2025-05-29 19:51:18,903 - INFO - joeynmt.training - Epoch   8, Step:    42400, Batch Loss:     2.260530, Batch Acc: 0.321841, Tokens per Sec:    37640, Lr: 0.000300
2025-05-29 19:51:20,689 - INFO - joeynmt.training - Epoch   8, Step:    42500, Batch Loss:     2.229061, Batch Acc: 0.319751, Tokens per Sec:    40448, Lr: 0.000300
2025-05-29 19:51:20,690 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:51:20,690 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:51:36,157 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.21, ppl:   9.10, acc:   0.33, generation: 15.4528[sec], evaluation: 0.0000[sec]
2025-05-29 19:51:36,158 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:51:36,239 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/39000.ckpt
2025-05-29 19:51:36,244 - INFO - joeynmt.training - Example #0
2025-05-29 19:51:36,244 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:51:36,244 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:51:36,244 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Sie', 'haben', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'S@@', 'tra@@', '<unk>', 'e', 'der', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'Ver@@', 'ein@@', 'ig@@', 'ten', 'St@@', 'a@@', 'aten', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'Ver@@', 'ein@@', 'ig@@', 'ten', 'St@@', 'a@@', 'aten', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'Ver@@', 'gan@@', 'gen@@', 'heit', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'Ver@@', 'ein@@', 'ig@@', 'ten', 'St@@', 'a@@', 'aten', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'Ver@@', 'ein@@', 'ig@@', 'ten', 'St@@', 'a@@', 'aten', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit']
2025-05-29 19:51:36,245 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:51:36,245 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:51:36,245 - INFO - joeynmt.training - 	Hypothesis: Sie haben die M<unk> glichkeit und die M<unk> glichkeit der K<unk> rper und die M<unk> glichkeit der Stra<unk> e der K<unk> rper und die M<unk> glichkeit der Vereinigten Staaten und die M<unk> glichkeit der Vereinigten Staaten und die M<unk> glichkeit der M<unk> glichkeit der Vergangenheit und die M<unk> glichkeit der Vereinigten Staaten und die M<unk> glichkeit der Vereinigten Staaten und die M<unk> glichkeit
2025-05-29 19:51:36,245 - INFO - joeynmt.training - Example #1
2025-05-29 19:51:36,245 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:51:36,245 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:51:36,245 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'S@@', 'tra@@', '<unk>', 'e', 'der', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'Wel@@', 't.', '</s>']
2025-05-29 19:51:36,245 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:51:36,245 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:51:36,245 - INFO - joeynmt.training - 	Hypothesis: Und das ist die M<unk> glichkeit der Stra<unk> e der K<unk> rper und die M<unk> glichkeit der Welt.
2025-05-29 19:51:36,245 - INFO - joeynmt.training - Example #2
2025-05-29 19:51:36,245 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:51:36,245 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:51:36,245 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'ein', 'M@@', 'at@@', 'eri@@', 'al@@', ',', 'der', 'die', 'M@@', 'at@@', 'er@@', 'ie', 'der', 'M@@', 'at@@', 'eri@@', 'al@@', ',', 'der', 'die', 'K@@', 'li@@', 'ma@@', 'w@@', 'an@@', 'del', 'und', 'die', 'M@@', 'at@@', 'er@@', 'ie', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'die', 'die', 'wir', 'in', 'der', 'Welt', 'ver@@', '<unk>', 'n@@', 'der@@', 'n', 'k@@', '<unk>', 'n@@', 'n@@', 'en.', '</s>']
2025-05-29 19:51:36,245 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:51:36,245 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:51:36,245 - INFO - joeynmt.training - 	Hypothesis: Und das ist ein Material, der die Materie der Material, der die Klimawandel und die Materie zu verwenden, die die wir in der Welt ver<unk> ndern k<unk> nnen.
2025-05-29 19:51:36,246 - INFO - joeynmt.training - Example #3
2025-05-29 19:51:36,246 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:51:36,246 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:51:36,246 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'ein', 'sehr', 'sch@@', '<unk>', 'n@@', 'es', 'Bei@@', 'spi@@', 'el', 'f@@', '<unk>', 'r', 'die', 'K@@', '<unk>', 'r@@', 'per@@', 't@@', 'es', 'M@@', '<unk>', 'd@@', 'chen', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'B@@', '<unk>', 'h@@', 'ne', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'Ver@@', 'ein@@', 'ig@@', 'ten', 'St@@', 'a@@', 'at@@', ',', 'die', 'die', 'in', 'der', 'L@@', 'age', 'der', 'Welt', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:51:36,246 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:51:36,246 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:51:36,246 - INFO - joeynmt.training - 	Hypothesis: Es ist ein sehr sch<unk> nes Beispiel f<unk> r die K<unk> rpertes M<unk> dchen und die M<unk> glichkeit der B<unk> hne und die M<unk> glichkeit der Vereinigten Staat, die die in der Lage der Welt zu ver<unk> ndern.
2025-05-29 19:51:36,246 - INFO - joeynmt.training - Example #4
2025-05-29 19:51:36,246 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:51:36,246 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:51:36,246 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'ein', 'M@@', '<unk>', 'd@@', 'chen', 'von', 'der', 'S@@', 'tra@@', '<unk>', 'e', 'der', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'S@@', 'tra@@', '<unk>', 'e', 'der', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'Ver@@', 'ein@@', 'ig@@', 'ten', 'St@@', 'a@@', 'aten', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'Ver@@', 'ein@@', 'ig@@', 'ten', 'St@@', 'a@@', 'aten', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', 'w@@', 'end@@', 'en.', '</s>']
2025-05-29 19:51:36,246 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:51:36,246 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:51:36,246 - INFO - joeynmt.training - 	Hypothesis: Und das ist ein M<unk> dchen von der Stra<unk> e der K<unk> rper und die M<unk> glichkeit der Stra<unk> e der K<unk> rper und die M<unk> glichkeit der Vereinigten Staaten und die M<unk> glichkeit der Vereinigten Staaten und die M<unk> glichkeit der K<unk> rper zu verwenden.
2025-05-29 19:51:38,309 - INFO - joeynmt.training - Epoch   8, Step:    42600, Batch Loss:     2.314070, Batch Acc: 0.317908, Tokens per Sec:    33228, Lr: 0.000300
2025-05-29 19:51:40,401 - INFO - joeynmt.training - Epoch   8, Step:    42700, Batch Loss:     2.183715, Batch Acc: 0.321022, Tokens per Sec:    35225, Lr: 0.000300
2025-05-29 19:51:41,818 - INFO - joeynmt.training - Epoch   8: total training loss 11806.20
2025-05-29 19:51:41,818 - INFO - joeynmt.training - EPOCH 9
2025-05-29 19:51:42,468 - INFO - joeynmt.training - Epoch   9, Step:    42800, Batch Loss:     2.143055, Batch Acc: 0.328533, Tokens per Sec:    36259, Lr: 0.000300
2025-05-29 19:51:44,555 - INFO - joeynmt.training - Epoch   9, Step:    42900, Batch Loss:     2.209149, Batch Acc: 0.330296, Tokens per Sec:    33555, Lr: 0.000300
2025-05-29 19:51:46,599 - INFO - joeynmt.training - Epoch   9, Step:    43000, Batch Loss:     2.040483, Batch Acc: 0.324246, Tokens per Sec:    35208, Lr: 0.000300
2025-05-29 19:51:46,599 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:51:46,599 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:52:02,124 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.21, ppl:   9.08, acc:   0.33, generation: 15.5105[sec], evaluation: 0.0000[sec]
2025-05-29 19:52:02,125 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:52:02,207 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/40000.ckpt
2025-05-29 19:52:02,213 - INFO - joeynmt.training - Example #0
2025-05-29 19:52:02,213 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:52:02,213 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:52:02,213 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'ein', 'paar', 'Jahre', 'al@@', 't', 'und', 'ich', 'habe', 'es', 'in', 'der', 'H@@', '<unk>', 'h@@', 'e', 'zu', 'be@@', 'komm@@', 'en,', 'um', 'die', 'K@@', 'rank@@', 'heit', 'zu', 'h@@', '<unk>', 'r@@', 'en,', 'um', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', 'li@@', 'er@@', 'en.', '</s>']
2025-05-29 19:52:02,214 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:52:02,214 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:52:02,214 - INFO - joeynmt.training - 	Hypothesis: Und ich habe ein paar Jahre alt und ich habe es in der H<unk> he zu bekommen, um die Krankheit zu h<unk> ren, um die K<unk> rper zu verlieren.
2025-05-29 19:52:02,214 - INFO - joeynmt.training - Example #1
2025-05-29 19:52:02,214 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:52:02,214 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:52:02,214 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 't,', 'die', 'wir', 'nicht', 'nur', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 't,', 'die', 'nicht', 'nur', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 't,', 'die', 'wir', 'in', 'der', 'F@@', '<unk>', 'h@@', 'ig@@', 'keit', 'von', 'der', 'S@@', '<unk>', 'd@@', 'w@@', 'est@@', 'ung', 'der', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 't,', 'die', 'wir', 'uns', 'ver@@', 'm@@', 'ut@@', 'lich', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:52:02,214 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:52:02,214 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:52:02,214 - INFO - joeynmt.training - 	Hypothesis: Und das ist die K<unk> rper und die M<unk> glichkeit, die wir nicht nur die M<unk> glichkeit, die nicht nur die K<unk> rper und die M<unk> glichkeit, die wir in der F<unk> higkeit von der S<unk> dwestung der K<unk> rper und die M<unk> glichkeit, die wir uns vermutlich ver<unk> ndern.
2025-05-29 19:52:02,214 - INFO - joeynmt.training - Example #2
2025-05-29 19:52:02,214 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:52:02,214 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:52:02,214 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'S@@', 'ache', 'ist', 'die', 'K@@', 'li@@', 'ma@@', 'w@@', 'andel@@', ',', 'die', 'ich', 'in', 'der', 'H@@', '<unk>', 'h@@', 'e', 'zu', 'mach@@', 'en.', '</s>']
2025-05-29 19:52:02,214 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:52:02,215 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:52:02,215 - INFO - joeynmt.training - 	Hypothesis: Die Sache ist die Klimawandel, die ich in der H<unk> he zu machen.
2025-05-29 19:52:02,215 - INFO - joeynmt.training - Example #3
2025-05-29 19:52:02,215 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:52:02,215 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:52:02,215 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Sie', 'haben', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 't,', 'die', 'wir', 'in', 'der', 'F@@', '<unk>', 'h@@', 'ig@@', 'keit', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 't,', 'die', 'wir', 'in', 'der', 'F@@', '<unk>', 'h@@', 'ig@@', 'keit', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 't,', 'die', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'und', 'sie', 'sind', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 't,', 'die', 'sie', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'die', 'sie', 'in']
2025-05-29 19:52:02,215 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:52:02,215 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:52:02,215 - INFO - joeynmt.training - 	Hypothesis: Sie haben die M<unk> glichkeit, die wir in der F<unk> higkeit und die M<unk> glichkeiten und die M<unk> glichkeiten und die M<unk> glichkeit, die wir in der F<unk> higkeit und die M<unk> glichkeiten und die M<unk> glichkeiten und die M<unk> glichkeiten und die M<unk> glichkeit, die die M<unk> glichkeit zu verwenden, und sie sind die M<unk> glichkeiten und die M<unk> glichkeit, die sie zu verwenden, die sie in
2025-05-29 19:52:02,215 - INFO - joeynmt.training - Example #4
2025-05-29 19:52:02,215 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:52:02,215 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:52:02,215 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'mei@@', 'sten', 'von', 'uns', 'k@@', '<unk>', 'n@@', 'nen', 'wir', 'die', 'H@@', '<unk>', 'l@@', 'f@@', 'te', 'und', 'die', 'H@@', '<unk>', 'l@@', 'le', 'und', 'die', 'H@@', '<unk>', 'l@@', 'f@@', 'te', 'der', 'Welt', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:52:02,215 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:52:02,216 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:52:02,216 - INFO - joeynmt.training - 	Hypothesis: Die meisten von uns k<unk> nnen wir die H<unk> lfte und die H<unk> lle und die H<unk> lfte der Welt ver<unk> ndern.
2025-05-29 19:52:04,255 - INFO - joeynmt.training - Epoch   9, Step:    43100, Batch Loss:     2.261385, Batch Acc: 0.330900, Tokens per Sec:    33299, Lr: 0.000300
2025-05-29 19:52:06,296 - INFO - joeynmt.training - Epoch   9, Step:    43200, Batch Loss:     2.298985, Batch Acc: 0.332060, Tokens per Sec:    34517, Lr: 0.000300
2025-05-29 19:52:08,248 - INFO - joeynmt.training - Epoch   9, Step:    43300, Batch Loss:     2.067914, Batch Acc: 0.327872, Tokens per Sec:    35796, Lr: 0.000300
2025-05-29 19:52:10,217 - INFO - joeynmt.training - Epoch   9, Step:    43400, Batch Loss:     2.273247, Batch Acc: 0.327904, Tokens per Sec:    34378, Lr: 0.000300
2025-05-29 19:52:12,197 - INFO - joeynmt.training - Epoch   9, Step:    43500, Batch Loss:     2.317292, Batch Acc: 0.327791, Tokens per Sec:    34569, Lr: 0.000300
2025-05-29 19:52:12,197 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:52:12,197 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:52:23,861 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.21, ppl:   9.15, acc:   0.33, generation: 11.6545[sec], evaluation: 0.0000[sec]
2025-05-29 19:52:23,942 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/40500.ckpt
2025-05-29 19:52:23,948 - INFO - joeynmt.training - Example #0
2025-05-29 19:52:23,948 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:52:23,948 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:52:23,948 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'mich', 'ge@@', 'frag@@', 't,', 'ob', 'ich', 'es', 'in', 'm@@', 'einem', 'K@@', 'ont@@', 'ex@@', 't', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:52:23,948 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:52:23,948 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:52:23,948 - INFO - joeynmt.training - 	Hypothesis: Ich habe mich gefragt, ob ich es in meinem Kontext und die M<unk> glichkeiten zu ver<unk> ndern.
2025-05-29 19:52:23,948 - INFO - joeynmt.training - Example #1
2025-05-29 19:52:23,948 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:52:23,948 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:52:23,948 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'die', 'K@@', 'rank@@', 'hei@@', 'ten', 'der', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', 'rank@@', 'hei@@', 'ten', 'und', 'die', 'K@@', 'rank@@', 'hei@@', 'ten', 'zu', 'er@@', 'halt@@', 'en.', '</s>']
2025-05-29 19:52:23,949 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:52:23,949 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:52:23,949 - INFO - joeynmt.training - 	Hypothesis: Und das ist die Krankheiten der K<unk> rper und die Krankheiten und die Krankheiten zu erhalten.
2025-05-29 19:52:23,949 - INFO - joeynmt.training - Example #2
2025-05-29 19:52:23,949 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:52:23,949 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:52:23,949 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'K@@', 'li@@', 'ma@@', 'w@@', 'andel@@', ',', 'die', 'ich', 'in', 'einem', 'K@@', 'li@@', 'ma@@', 'w@@', 'andel@@', ',', 'der', 'die', 'K@@', 'li@@', 'ma@@', 'w@@', 'andel@@', ',', 'die', 'ich', 'in', 'der', 'L@@', 'u@@', 'ft', 'in', 'der', 'L@@', 'u@@', 'ft', 'in', 'der', 'L@@', 'u@@', 'ft', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:52:23,949 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:52:23,949 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:52:23,949 - INFO - joeynmt.training - 	Hypothesis: Die Klimawandel, die ich in einem Klimawandel, der die Klimawandel, die ich in der Luft in der Luft in der Luft zu ver<unk> ndern.
2025-05-29 19:52:23,949 - INFO - joeynmt.training - Example #3
2025-05-29 19:52:23,949 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:52:23,949 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:52:23,949 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'ein', 'g@@', 'ro@@', '<unk>', 'es', 'Pro@@', 'jek@@', 't', 'und', 'die', 'K@@', 'rank@@', 'hei@@', 'ten', 'und', 'die', 'K@@', 'rank@@', 'hei@@', 'ten', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:52:23,949 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:52:23,949 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:52:23,949 - INFO - joeynmt.training - 	Hypothesis: Es ist ein gro<unk> es Projekt und die Krankheiten und die Krankheiten zu ver<unk> ndern.
2025-05-29 19:52:23,950 - INFO - joeynmt.training - Example #4
2025-05-29 19:52:23,950 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:52:23,950 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:52:23,950 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'mei@@', 'sten', 'von', 'uns', 'haben', 'wir', 'die', 'letz@@', 'ten', '1@@', '5', 'Jahren', 'in', 'den', 'letz@@', 'ten', '1@@', '5', 'Jahren', 'in', 'den', 'letz@@', 'ten', '1@@', '5', 'Jahren', 'in', 'den', 'letz@@', 'ten', '1@@', '5', 'Jahren', 'in', 'den', 'letz@@', 'ten', '1@@', '5', 'Jahren', 'in', 'den', 'letz@@', 'ten', '1@@', '5', 'Jahren', 'in', 'den', 'letz@@', 'ten', '1@@', '5', 'Jahren', 'in', 'den', 'letz@@', 'ten', '1@@', '5', 'Jahren', 'in', 'den', 'letz@@', 'ten', '1@@', '5', 'Jahren', 'in', 'den', 'letz@@', 'ten', '1@@', '5', 'Jahren', 'ver@@', '<unk>', 'n@@', 'der@@', 'n', 'k@@', '<unk>', 'n@@', 'n@@', 'en.', '</s>']
2025-05-29 19:52:23,950 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:52:23,950 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:52:23,950 - INFO - joeynmt.training - 	Hypothesis: Die meisten von uns haben wir die letzten 15 Jahren in den letzten 15 Jahren in den letzten 15 Jahren in den letzten 15 Jahren in den letzten 15 Jahren in den letzten 15 Jahren in den letzten 15 Jahren in den letzten 15 Jahren in den letzten 15 Jahren in den letzten 15 Jahren ver<unk> ndern k<unk> nnen.
2025-05-29 19:52:25,885 - INFO - joeynmt.training - Epoch   9, Step:    43600, Batch Loss:     2.174033, Batch Acc: 0.324529, Tokens per Sec:    33679, Lr: 0.000300
2025-05-29 19:52:27,827 - INFO - joeynmt.training - Epoch   9, Step:    43700, Batch Loss:     2.105766, Batch Acc: 0.324084, Tokens per Sec:    35258, Lr: 0.000300
2025-05-29 19:52:30,690 - INFO - joeynmt.training - Epoch   9, Step:    43800, Batch Loss:     2.260713, Batch Acc: 0.325955, Tokens per Sec:    23988, Lr: 0.000300
2025-05-29 19:52:32,758 - INFO - joeynmt.training - Epoch   9, Step:    43900, Batch Loss:     2.179696, Batch Acc: 0.330434, Tokens per Sec:    33180, Lr: 0.000300
2025-05-29 19:52:34,775 - INFO - joeynmt.training - Epoch   9, Step:    44000, Batch Loss:     2.133717, Batch Acc: 0.328097, Tokens per Sec:    36028, Lr: 0.000300
2025-05-29 19:52:34,775 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:52:34,775 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:52:48,624 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.21, ppl:   9.08, acc:   0.33, generation: 13.8380[sec], evaluation: 0.0000[sec]
2025-05-29 19:52:48,624 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:52:48,705 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/41000.ckpt
2025-05-29 19:52:48,711 - INFO - joeynmt.training - Example #0
2025-05-29 19:52:48,711 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:52:48,711 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:52:48,711 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'von', 'der', 'M@@', '<unk>', 'n@@', 'n@@', 'chen', 'in', 'der', 'L@@', 'u@@', 'ft', 'in', 'die', 'L@@', 'u@@', 'ft', 'der', 'L@@', 'u@@', 'ft', 'der', 'S@@', 'pr@@', 'ach@@', 'e,', 'die', 'wir', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Milli@@', 'onen', 'D@@', 'oll@@', 'ar', 'f@@', '<unk>', 'r', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'von', 'den', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'von', 'den', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'Ver@@', 'gan@@', 'gen@@', 'heit', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'in', 'den', 'U@@', 'S@@', 'A', 'und', 'der', 'K@@', 'ont@@', 'ak@@', 't', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'die', 'in']
2025-05-29 19:52:48,711 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:52:48,711 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:52:48,711 - INFO - joeynmt.training - 	Hypothesis: Ich habe die M<unk> glichkeit von der M<unk> nnchen in der Luft in die Luft der Luft der Sprache, die wir in den letzten 25 Millionen Dollar f<unk> r die M<unk> glichkeiten von den M<unk> nnern und die M<unk> glichkeiten von den M<unk> nnern und die M<unk> glichkeit der Vergangenheit und die M<unk> glichkeiten in den USA und der Kontakt zu verwenden, die in
2025-05-29 19:52:48,711 - INFO - joeynmt.training - Example #1
2025-05-29 19:52:48,711 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:52:48,711 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:52:48,711 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Das', 'ist', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'der', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'und', 'das', 'ist', 'nicht', 'nur', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'zu', 'ver@@', 'w@@', 'end@@', 'en.', '</s>']
2025-05-29 19:52:48,712 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:52:48,712 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:52:48,712 - INFO - joeynmt.training - 	Hypothesis: Das ist die K<unk> rper und die M<unk> glichkeiten der K<unk> rper zu verwenden, und das ist nicht nur ein paar Minuten und die M<unk> glichkeiten zu verwenden.
2025-05-29 19:52:48,712 - INFO - joeynmt.training - Example #2
2025-05-29 19:52:48,712 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:52:48,712 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:52:48,712 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Das', 'ist', 'ein', 'M@@', 'ann', 'der', 'K@@', 'li@@', 'ma@@', 'w@@', 'andel@@', ',', 'der', 'die', 'K@@', 'li@@', 'ma@@', 'w@@', 'andel@@', ',', 'die', 'wir', 'in', 'der', 'L@@', 'age', 'sein,', 'die', 'wir', 'in', 'der', 'Welt', 'ver@@', '<unk>', 'n@@', 'der@@', 'n', 'k@@', '<unk>', 'n@@', 'n@@', 'en.', '</s>']
2025-05-29 19:52:48,712 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:52:48,712 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:52:48,712 - INFO - joeynmt.training - 	Hypothesis: Das ist ein Mann der Klimawandel, der die Klimawandel, die wir in der Lage sein, die wir in der Welt ver<unk> ndern k<unk> nnen.
2025-05-29 19:52:48,712 - INFO - joeynmt.training - Example #3
2025-05-29 19:52:48,712 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:52:48,712 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:52:48,712 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Sie', 'haben', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'und', 'die', 'M@@', '<unk>', 'n@@', 'n@@', 'ch@@', 'tig@@', 'e', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'die', 'sich', '<unk>', 'ber', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'mach@@', 'en.', '</s>']
2025-05-29 19:52:48,712 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:52:48,712 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:52:48,713 - INFO - joeynmt.training - 	Hypothesis: Sie haben die M<unk> glichkeiten und die M<unk> nnchtige K<unk> rper, die sich <unk> ber die K<unk> rper zu machen.
2025-05-29 19:52:48,713 - INFO - joeynmt.training - Example #4
2025-05-29 19:52:48,713 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:52:48,713 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:52:48,713 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Das', 'ist', 'ein', 'g@@', 'ro@@', '<unk>', 'es', 'M@@', '<unk>', 'glich@@', 'k@@', 'eit@@', 'en,', 'die', 'ich', 'in', 'der', 'H@@', '<unk>', 'h@@', 'e', 'zu', 'mach@@', 'en.', '</s>']
2025-05-29 19:52:48,713 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:52:48,713 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:52:48,713 - INFO - joeynmt.training - 	Hypothesis: Das ist ein gro<unk> es M<unk> glichkeiten, die ich in der H<unk> he zu machen.
2025-05-29 19:52:50,773 - INFO - joeynmt.training - Epoch   9, Step:    44100, Batch Loss:     2.075591, Batch Acc: 0.325462, Tokens per Sec:    33672, Lr: 0.000300
2025-05-29 19:52:52,845 - INFO - joeynmt.training - Epoch   9, Step:    44200, Batch Loss:     2.269011, Batch Acc: 0.327660, Tokens per Sec:    35238, Lr: 0.000300
2025-05-29 19:52:54,946 - INFO - joeynmt.training - Epoch   9, Step:    44300, Batch Loss:     2.140797, Batch Acc: 0.325905, Tokens per Sec:    33825, Lr: 0.000300
2025-05-29 19:52:56,879 - INFO - joeynmt.training - Epoch   9, Step:    44400, Batch Loss:     2.110312, Batch Acc: 0.325384, Tokens per Sec:    37036, Lr: 0.000300
2025-05-29 19:52:58,670 - INFO - joeynmt.training - Epoch   9, Step:    44500, Batch Loss:     2.155433, Batch Acc: 0.327490, Tokens per Sec:    41384, Lr: 0.000300
2025-05-29 19:52:58,670 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:52:58,670 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:53:12,251 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.20, ppl:   9.05, acc:   0.33, generation: 13.5696[sec], evaluation: 0.0000[sec]
2025-05-29 19:53:12,251 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:53:12,335 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/43500.ckpt
2025-05-29 19:53:12,341 - INFO - joeynmt.training - Example #0
2025-05-29 19:53:12,341 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:53:12,341 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:53:12,341 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'eine', 'M@@', 'en@@', 'ge', 'M@@', 'en@@', 'ge', 'und', 'ich', 'habe', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 't,', 'die', 'ich', 'in', 'den', 'letz@@', 'ten', '20', 'Milli@@', 'onen', 'Menschen', 'in', 'den', 'letz@@', 'ten', '20', 'Milli@@', 'onen', 'Menschen', 'in', 'die', 'L@@', 'u@@', 'ft', 'in', 'den', 'letz@@', 'ten', '20', 'Jahren', 'in', 'den', 'letz@@', 'ten', '20', 'Jahren', 'in', 'den', 'letz@@', 'ten', '20', 'Milli@@', 'onen', 'Menschen', 'in', 'die', 'L@@', 'age', 'sp@@', '<unk>', 'ter', 'in', 'den', 'letz@@', 'ten', '20', 'Jahren', 'in', 'den', 'letz@@', 'ten', '20', 'Jahren', 'in', 'den', 'letz@@', 'ten', '20', 'Jahren', 'in', 'der', 'Welt', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:53:12,341 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:53:12,341 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:53:12,341 - INFO - joeynmt.training - 	Hypothesis: Ich habe eine Menge Menge und ich habe die M<unk> glichkeit, die ich in den letzten 20 Millionen Menschen in den letzten 20 Millionen Menschen in die Luft in den letzten 20 Jahren in den letzten 20 Jahren in den letzten 20 Millionen Menschen in die Lage sp<unk> ter in den letzten 20 Jahren in den letzten 20 Jahren in den letzten 20 Jahren in der Welt zu ver<unk> ndern.
2025-05-29 19:53:12,341 - INFO - joeynmt.training - Example #1
2025-05-29 19:53:12,341 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:53:12,341 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:53:12,341 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'm@@', '<unk>', 'chte', 'Ihnen', 'ein', 'Bei@@', 'spi@@', 'el', 'zeig@@', 'en,', 'wie', 'wir', 'es', 'in', 'der', 'L@@', 'age', 'sein,', 'die', 'wir', 'nicht', 'nur', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 't,', 'die', 'wir', 'in', 'der', 'Welt', 'ver@@', '<unk>', 'n@@', 'der@@', 'n', 'k@@', '<unk>', 'n@@', 'n@@', 'en.', '</s>']
2025-05-29 19:53:12,342 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:53:12,342 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:53:12,342 - INFO - joeynmt.training - 	Hypothesis: Und ich m<unk> chte Ihnen ein Beispiel zeigen, wie wir es in der Lage sein, die wir nicht nur die K<unk> rper und die M<unk> glichkeit, die wir in der Welt ver<unk> ndern k<unk> nnen.
2025-05-29 19:53:12,342 - INFO - joeynmt.training - Example #2
2025-05-29 19:53:12,342 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:53:12,342 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:53:12,342 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'M@@', '<unk>', 'n@@', 'n@@', 'chen', 'ist', 'eine', 'M@@', 'en@@', 'ge', 'S@@', 'ach@@', 'e,', 'die', 'wir', 'in', 'der', 'Welt', 'ver@@', '<unk>', 'n@@', 'der@@', 'n', 'k@@', '<unk>', 'n@@', 'n@@', 'en.', '</s>']
2025-05-29 19:53:12,342 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:53:12,342 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:53:12,342 - INFO - joeynmt.training - 	Hypothesis: Die M<unk> nnchen ist eine Menge Sache, die wir in der Welt ver<unk> ndern k<unk> nnen.
2025-05-29 19:53:12,342 - INFO - joeynmt.training - Example #3
2025-05-29 19:53:12,342 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:53:12,342 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:53:12,342 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'eine', 'sehr', 'einf@@', 'ach@@', 'e,', 'die', 'wir', 'in', 'der', 'L@@', 'age', 'sein,', 'die', 'wir', 'in', 'der', 'Welt', 'ver@@', '<unk>', 'n@@', 'der@@', 'n', 'k@@', '<unk>', 'n@@', 'n@@', 'en.', '</s>']
2025-05-29 19:53:12,343 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:53:12,343 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:53:12,343 - INFO - joeynmt.training - 	Hypothesis: Es ist eine sehr einfache, die wir in der Lage sein, die wir in der Welt ver<unk> ndern k<unk> nnen.
2025-05-29 19:53:12,343 - INFO - joeynmt.training - Example #4
2025-05-29 19:53:12,343 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:53:12,343 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:53:12,343 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'mei@@', 'sten', 'von', 'uns', 'haben', 'wir', 'die', 'Welt', 'ver@@', '<unk>', 'n@@', 'der@@', 'n', 'k@@', '<unk>', 'n@@', 'n@@', 'en.', '</s>']
2025-05-29 19:53:12,343 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:53:12,343 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:53:12,343 - INFO - joeynmt.training - 	Hypothesis: Die meisten von uns haben wir die Welt ver<unk> ndern k<unk> nnen.
2025-05-29 19:53:14,306 - INFO - joeynmt.training - Epoch   9, Step:    44600, Batch Loss:     2.193159, Batch Acc: 0.324403, Tokens per Sec:    34544, Lr: 0.000300
2025-05-29 19:53:16,127 - INFO - joeynmt.training - Epoch   9, Step:    44700, Batch Loss:     2.130465, Batch Acc: 0.326208, Tokens per Sec:    38063, Lr: 0.000300
2025-05-29 19:53:18,135 - INFO - joeynmt.training - Epoch   9, Step:    44800, Batch Loss:     2.224050, Batch Acc: 0.325472, Tokens per Sec:    35560, Lr: 0.000300
2025-05-29 19:53:20,136 - INFO - joeynmt.training - Epoch   9, Step:    44900, Batch Loss:     2.175591, Batch Acc: 0.321866, Tokens per Sec:    34635, Lr: 0.000300
2025-05-29 19:53:22,537 - INFO - joeynmt.training - Epoch   9, Step:    45000, Batch Loss:     2.258722, Batch Acc: 0.325010, Tokens per Sec:    30130, Lr: 0.000300
2025-05-29 19:53:22,537 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:53:22,537 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:53:37,525 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.20, ppl:   9.06, acc:   0.33, generation: 14.9769[sec], evaluation: 0.0000[sec]
2025-05-29 19:53:37,609 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/42000.ckpt
2025-05-29 19:53:37,615 - INFO - joeynmt.training - Example #0
2025-05-29 19:53:37,616 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:53:37,616 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:53:37,616 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'von', 'den', 'F@@', '<unk>', 'h@@', 'ig@@', 'kei@@', 'ten', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'S@@', 'tra@@', '<unk>', 'en@@', 'r@@', '<unk>', 'um@@', 'e', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:53:37,616 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:53:37,616 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:53:37,616 - INFO - joeynmt.training - 	Hypothesis: Ich habe die M<unk> glichkeit von den F<unk> higkeiten und die M<unk> glichkeit der Stra<unk> enr<unk> ume zu ver<unk> ndern.
2025-05-29 19:53:37,616 - INFO - joeynmt.training - Example #1
2025-05-29 19:53:37,616 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:53:37,616 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:53:37,616 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 't,', 'die', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', 'w@@', 'end@@', 'en.', '</s>']
2025-05-29 19:53:37,616 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:53:37,616 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:53:37,616 - INFO - joeynmt.training - 	Hypothesis: Und das ist die M<unk> glichkeit, die die M<unk> glichkeit der K<unk> rper zu verwenden.
2025-05-29 19:53:37,616 - INFO - joeynmt.training - Example #2
2025-05-29 19:53:37,617 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:53:37,617 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:53:37,617 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'ein', 'M@@', 'ann@@', ',', 'das', 'ist', 'ein', 'sehr', 'gut@@', 'er', 'W@@', 'ort', '"@@', 'H@@', 'e@@', 'y,', 'ich', 'habe', 'mich', 'ge@@', 'frag@@', 't,', 'ob', 'ich', 'es', 'nicht', 'nur', 'ein', 'paar', 'M@@', 'et@@', 'ho@@', 'de', 'ver@@', '<unk>', 'n@@', 'der@@', 't.', '</s>']
2025-05-29 19:53:37,617 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:53:37,617 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:53:37,617 - INFO - joeynmt.training - 	Hypothesis: Und das ist ein Mann, das ist ein sehr guter Wort "Hey, ich habe mich gefragt, ob ich es nicht nur ein paar Methode ver<unk> ndert.
2025-05-29 19:53:37,617 - INFO - joeynmt.training - Example #3
2025-05-29 19:53:37,617 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:53:37,617 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:53:37,617 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'ein', 'sehr', 'sch@@', 'wi@@', 'er@@', 'ig@@', '.', '</s>']
2025-05-29 19:53:37,617 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:53:37,617 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:53:37,617 - INFO - joeynmt.training - 	Hypothesis: Es ist ein sehr schwierig.
2025-05-29 19:53:37,617 - INFO - joeynmt.training - Example #4
2025-05-29 19:53:37,617 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:53:37,617 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:53:37,617 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'mei@@', 'sten', 'von', 'uns', 'haben', 'die', 'er@@', 'ste', 'Zeit', 'in', 'der', 'Welt', 'ver@@', 'bring@@', 'en.', '</s>']
2025-05-29 19:53:37,618 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:53:37,618 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:53:37,618 - INFO - joeynmt.training - 	Hypothesis: Die meisten von uns haben die erste Zeit in der Welt verbringen.
2025-05-29 19:53:39,684 - INFO - joeynmt.training - Epoch   9, Step:    45100, Batch Loss:     2.235753, Batch Acc: 0.325308, Tokens per Sec:    33087, Lr: 0.000300
2025-05-29 19:53:41,568 - INFO - joeynmt.training - Epoch   9, Step:    45200, Batch Loss:     2.139433, Batch Acc: 0.327847, Tokens per Sec:    37854, Lr: 0.000300
2025-05-29 19:53:43,504 - INFO - joeynmt.training - Epoch   9, Step:    45300, Batch Loss:     2.112460, Batch Acc: 0.327447, Tokens per Sec:    37419, Lr: 0.000300
2025-05-29 19:53:45,445 - INFO - joeynmt.training - Epoch   9, Step:    45400, Batch Loss:     2.272325, Batch Acc: 0.327758, Tokens per Sec:    35817, Lr: 0.000300
2025-05-29 19:53:47,325 - INFO - joeynmt.training - Epoch   9, Step:    45500, Batch Loss:     2.264967, Batch Acc: 0.324460, Tokens per Sec:    37299, Lr: 0.000300
2025-05-29 19:53:47,325 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:53:47,325 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:54:01,681 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.21, ppl:   9.07, acc:   0.33, generation: 14.3445[sec], evaluation: 0.0000[sec]
2025-05-29 19:54:01,763 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/42500.ckpt
2025-05-29 19:54:01,769 - INFO - joeynmt.training - Example #0
2025-05-29 19:54:01,769 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:54:01,769 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:54:01,769 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Das', 'ist', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'L@@', '<unk>', 's@@', 'ung', 'der', 'Welt', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:54:01,769 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:54:01,769 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:54:01,769 - INFO - joeynmt.training - 	Hypothesis: Das ist die M<unk> glichkeit und die M<unk> glichkeit und die M<unk> glichkeit der L<unk> sung der Welt zu ver<unk> ndern.
2025-05-29 19:54:01,770 - INFO - joeynmt.training - Example #1
2025-05-29 19:54:01,770 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:54:01,770 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:54:01,770 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'Wel@@', 't.', '</s>']
2025-05-29 19:54:01,770 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:54:01,770 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:54:01,770 - INFO - joeynmt.training - 	Hypothesis: Und das ist die M<unk> glichkeit der K<unk> rper und die M<unk> glichkeit der K<unk> rper und die M<unk> glichkeit der Welt.
2025-05-29 19:54:01,770 - INFO - joeynmt.training - Example #2
2025-05-29 19:54:01,770 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:54:01,770 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:54:01,770 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'S@@', 'on@@', 'ne', 'ist', 'in', 'einem', 'H@@', 'aus', 'in', 'einem', 'H@@', 'aus', 'in', 'einem', 'H@@', 'aus', 'und', 'der', 'L@@', 'and@@', 'wir@@', 't@@', 'schaf@@', 't,', 'die', 'wir', 'in', 'einem', 'H@@', 'aus', 'und', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'L@@', '<unk>', 's@@', 'ung', 'der', 'Welt', 'ver@@', '<unk>', 'n@@', 'der@@', 't.', '</s>']
2025-05-29 19:54:01,770 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:54:01,770 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:54:01,770 - INFO - joeynmt.training - 	Hypothesis: Die Sonne ist in einem Haus in einem Haus in einem Haus und der Landwirtschaft, die wir in einem Haus und und die M<unk> glichkeit der L<unk> sung der Welt ver<unk> ndert.
2025-05-29 19:54:01,770 - INFO - joeynmt.training - Example #3
2025-05-29 19:54:01,770 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:54:01,770 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:54:01,770 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'eine', 'M@@', 'en@@', 'ge', 'von', 'den', 'K@@', '<unk>', 'n@@', 'st@@', 'ler', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'und', 'das', 'ist', 'eine', 'M@@', 'en@@', 'ge', 'von', 'H@@', 'au@@', 'pt@@', 'st@@', 'ad@@', 't', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', 'w@@', 'and@@', 'eln', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', 'w@@', 'end@@', 'en.', '</s>']
2025-05-29 19:54:01,771 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:54:01,771 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:54:01,771 - INFO - joeynmt.training - 	Hypothesis: Es ist eine Menge von den K<unk> nstler und die M<unk> glichkeit zu verwenden, und das ist eine Menge von Hauptstadt und die K<unk> rper und die K<unk> rper zu verwandeln und die K<unk> rper zu verwenden.
2025-05-29 19:54:01,771 - INFO - joeynmt.training - Example #4
2025-05-29 19:54:01,771 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:54:01,771 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:54:01,771 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'mei@@', 'sten', 'von', 'uns', 'haben', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'M@@', '<unk>', 'glich@@', 'kei@@', 't,', 'die', 'wir', 'in', 'der', 'Welt', 'ver@@', '<unk>', 'n@@', 'der@@', 'n', 'k@@', '<unk>', 'n@@', 'n@@', 'en.', '</s>']
2025-05-29 19:54:01,771 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:54:01,771 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:54:01,771 - INFO - joeynmt.training - 	Hypothesis: Die meisten von uns haben die M<unk> glichkeit und die M<unk> glichkeit der M<unk> glichkeit, die wir in der Welt ver<unk> ndern k<unk> nnen.
2025-05-29 19:54:03,874 - INFO - joeynmt.training - Epoch   9, Step:    45600, Batch Loss:     2.198474, Batch Acc: 0.324820, Tokens per Sec:    31882, Lr: 0.000300
2025-05-29 19:54:05,927 - INFO - joeynmt.training - Epoch   9, Step:    45700, Batch Loss:     2.245214, Batch Acc: 0.325558, Tokens per Sec:    33655, Lr: 0.000300
2025-05-29 19:54:08,981 - INFO - joeynmt.training - Epoch   9, Step:    45800, Batch Loss:     2.275389, Batch Acc: 0.324683, Tokens per Sec:    22867, Lr: 0.000300
2025-05-29 19:54:11,072 - INFO - joeynmt.training - Epoch   9, Step:    45900, Batch Loss:     2.205245, Batch Acc: 0.321409, Tokens per Sec:    33378, Lr: 0.000300
2025-05-29 19:54:12,976 - INFO - joeynmt.training - Epoch   9, Step:    46000, Batch Loss:     2.344712, Batch Acc: 0.322353, Tokens per Sec:    38793, Lr: 0.000300
2025-05-29 19:54:12,976 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:54:12,977 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:54:23,772 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.20, ppl:   9.01, acc:   0.34, generation: 10.7870[sec], evaluation: 0.0000[sec]
2025-05-29 19:54:23,772 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:54:23,856 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/43000.ckpt
2025-05-29 19:54:23,861 - INFO - joeynmt.training - Example #0
2025-05-29 19:54:23,862 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:54:23,862 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:54:23,862 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'die', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'Fr@@', 'auen', 'in', 'den', 'U@@', 'S@@', 'A', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'K@@', 'ont@@', 'ak@@', 't', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'die', 'die', 'in', 'den', 'U@@', 'S@@', 'A', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'die', 'in', 'den', 'U@@', 'S@@', 'A', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'die', 'in', 'den', 'U@@', 'S@@', 'A', 'zu', 'ver@@', 'br@@', 'eit@@', 'en.', '</s>']
2025-05-29 19:54:23,862 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:54:23,862 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:54:23,862 - INFO - joeynmt.training - 	Hypothesis: Ich habe die M<unk> nner und Frauen in den USA und die M<unk> glichkeit der Kontakt zu verwenden, die die in den USA zu verwenden, die in den USA zu verwenden, die in den USA zu verbreiten.
2025-05-29 19:54:23,862 - INFO - joeynmt.training - Example #1
2025-05-29 19:54:23,862 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:54:23,862 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:54:23,862 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'die', 'M@@', '<unk>', 'n@@', 'ner', 'der', 'er@@', 'sten', 'S@@', 'k@@', 'ul@@', 'p@@', 'tur@@', 'en', 'der', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:54:23,862 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:54:23,862 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:54:23,862 - INFO - joeynmt.training - 	Hypothesis: Und das ist die M<unk> nner der ersten Skulpturen der K<unk> rper zu ver<unk> ndern.
2025-05-29 19:54:23,862 - INFO - joeynmt.training - Example #2
2025-05-29 19:54:23,862 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:54:23,862 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:54:23,862 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'K@@', 'li@@', 'ma@@', 'w@@', 'andel@@', ',', 'die', 'wir', 'in', 'der', 'L@@', 'u@@', 'ft', 'in', 'der', 'L@@', 'age', 'sind,', 'die', 'wir', 'in', 'der', 'L@@', 'age', 'sind,', 'die', 'wir', 'in', 'der', 'L@@', 'u@@', 'ft', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:54:23,863 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:54:23,863 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:54:23,863 - INFO - joeynmt.training - 	Hypothesis: Die Klimawandel, die wir in der Luft in der Lage sind, die wir in der Lage sind, die wir in der Luft zu erreichen.
2025-05-29 19:54:23,863 - INFO - joeynmt.training - Example #3
2025-05-29 19:54:23,863 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:54:23,863 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:54:23,863 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'eine', 'sehr', 'wichtig@@', 'e', 'F@@', 'ra@@', 'u', 'und', 'es', 'ist', 'eine', 'sehr', 'wichtig@@', 'e', 'F@@', '<unk>', 'h@@', 'ig@@', 'kei@@', 't,', 'die', 'sich', 'in', 'der', 'L@@', 'age', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:54:23,863 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:54:23,863 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:54:23,863 - INFO - joeynmt.training - 	Hypothesis: Es ist eine sehr wichtige Frau und es ist eine sehr wichtige F<unk> higkeit, die sich in der Lage zu erreichen.
2025-05-29 19:54:23,863 - INFO - joeynmt.training - Example #4
2025-05-29 19:54:23,863 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:54:23,863 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:54:23,863 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'mei@@', 'sten', 'von', 'Ihnen', 'k@@', 'ur@@', 'z', 'vor@@', 'stell@@', 'en,', 'dass', 'es', 'nicht', 'nur', 'ein', 'paar', 'M@@', '<unk>', 'n@@', 'n@@', 'er,', 'sondern', 'auch', 'die', 'K@@', 'ar@@', 'ten', 'von', 'der', 'N@@', '<unk>', 'h@@', 'e', 'der', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', 'w@@', 'end@@', 'en.', '</s>']
2025-05-29 19:54:23,863 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:54:23,863 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:54:23,863 - INFO - joeynmt.training - 	Hypothesis: Die meisten von Ihnen kurz vorstellen, dass es nicht nur ein paar M<unk> nner, sondern auch die Karten von der N<unk> he der K<unk> rper zu verwenden.
2025-05-29 19:54:25,849 - INFO - joeynmt.training - Epoch   9, Step:    46100, Batch Loss:     2.284467, Batch Acc: 0.325519, Tokens per Sec:    35400, Lr: 0.000300
2025-05-29 19:54:27,798 - INFO - joeynmt.training - Epoch   9, Step:    46200, Batch Loss:     2.159715, Batch Acc: 0.323203, Tokens per Sec:    35964, Lr: 0.000300
2025-05-29 19:54:29,696 - INFO - joeynmt.training - Epoch   9, Step:    46300, Batch Loss:     2.413389, Batch Acc: 0.322971, Tokens per Sec:    36609, Lr: 0.000300
2025-05-29 19:54:31,576 - INFO - joeynmt.training - Epoch   9, Step:    46400, Batch Loss:     2.137019, Batch Acc: 0.326095, Tokens per Sec:    37905, Lr: 0.000300
2025-05-29 19:54:33,555 - INFO - joeynmt.training - Epoch   9, Step:    46500, Batch Loss:     2.239852, Batch Acc: 0.322743, Tokens per Sec:    35103, Lr: 0.000300
2025-05-29 19:54:33,555 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:54:33,555 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:54:48,629 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.20, ppl:   9.05, acc:   0.33, generation: 15.0646[sec], evaluation: 0.0000[sec]
2025-05-29 19:54:48,713 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/44000.ckpt
2025-05-29 19:54:48,719 - INFO - joeynmt.training - Example #0
2025-05-29 19:54:48,719 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:54:48,719 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:54:48,719 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'mich', 'ge@@', 'frag@@', 't,', 'ob', 'ich', 'es', 'nicht', 'nur', 'die', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'die', 'ich', 'Ihnen', 'zeig@@', 'en,', 'wie', 'ich', 'das', 'er@@', 'ste', 'M@@', 'al', 'in', 'den', 'U@@', 'S@@', 'A', 'und', 'der', 'M@@', '<unk>', 'glich@@', 'kei@@', 't,', 'die', 'ich', 'Ihnen', 'zeig@@', 'en,', 'wie', 'ich', 'das', 'er@@', 'ste', 'M@@', 'al', 'in', 'den', 'U@@', 'S@@', 'A', 'und', 'der', 'M@@', 'itt@@', 'el@@', 'pun@@', 'k@@', 'te', 'der', 'K@@', 'ont@@', 'in@@', 'ent@@', ',', 'die', 'in', 'den', 'U@@', 'S@@', 'A', 'und', 'der', 'M@@', 'itt@@', 'el@@', 'pun@@', 'k@@', 'te', 'und', 'der', 'M@@', '<unk>', 'glich@@', 'kei@@', 't,', 'die', 'wir', 'in', 'den', 'letz@@', 'ten', '1@@', '0@@', '0@@', '0@@', '0@@', 'ern', 'und', 'der', 'M@@', 'itt@@', 'el@@', 'pun@@']
2025-05-29 19:54:48,720 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:54:48,720 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:54:48,720 - INFO - joeynmt.training - 	Hypothesis: Und ich habe mich gefragt, ob ich es nicht nur die K<unk> rper, die ich Ihnen zeigen, wie ich das erste Mal in den USA und der M<unk> glichkeit, die ich Ihnen zeigen, wie ich das erste Mal in den USA und der Mittelpunkte der Kontinent, die in den USA und der Mittelpunkte und der M<unk> glichkeit, die wir in den letzten 10000ern und der Mittelpun
2025-05-29 19:54:48,720 - INFO - joeynmt.training - Example #1
2025-05-29 19:54:48,720 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:54:48,720 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:54:48,720 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'die', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'die', 'wir', 'in', 'der', 'Welt', 'der', 'Welt', 'der', 'Welt', 'ver@@', '<unk>', 'n@@', 'der@@', 'n', 'k@@', '<unk>', 'n@@', 'n@@', 'en.', '</s>']
2025-05-29 19:54:48,720 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:54:48,720 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:54:48,720 - INFO - joeynmt.training - 	Hypothesis: Und das ist die K<unk> rper, die wir in der Welt der Welt der Welt ver<unk> ndern k<unk> nnen.
2025-05-29 19:54:48,720 - INFO - joeynmt.training - Example #2
2025-05-29 19:54:48,720 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:54:48,720 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:54:48,720 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'ein', 'g@@', 'ro@@', '<unk>', 'er', 'K@@', 'li@@', 'ma@@', 'w@@', 'andel@@', ',', 'der', 'in', 'der', 'L@@', 'age', 'der', 'Welt', 'der', 'Welt', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:54:48,720 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:54:48,721 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:54:48,721 - INFO - joeynmt.training - 	Hypothesis: Und das ist ein gro<unk> er Klimawandel, der in der Lage der Welt der Welt zu erreichen.
2025-05-29 19:54:48,721 - INFO - joeynmt.training - Example #3
2025-05-29 19:54:48,721 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:54:48,721 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:54:48,721 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'ein', 'kl@@', 'eines', 'T@@', 'ag@@', 'es', 'und', 'das', 'ist', 'eine', 'M@@', 'en@@', 'ge', 'K@@', '<unk>', 'n@@', 'st@@', 'l@@', 'er@@', 's', 'und', 'der', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'der', 'in', 'der', 'wir', 'uns', 'in', 'die', 'Welt', 'ver@@', '<unk>', 'n@@', 'der@@', 'n', 'k@@', '<unk>', 'n@@', 'n@@', 'en.', '</s>']
2025-05-29 19:54:48,721 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:54:48,721 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:54:48,721 - INFO - joeynmt.training - 	Hypothesis: Es ist ein kleines Tages und das ist eine Menge K<unk> nstlers und der K<unk> rper, der in der wir uns in die Welt ver<unk> ndern k<unk> nnen.
2025-05-29 19:54:48,721 - INFO - joeynmt.training - Example #4
2025-05-29 19:54:48,721 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:54:48,721 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:54:48,721 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'eine', 'der', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'die', 'ich', 'Ihnen', 'zeig@@', 'en,', 'wie', 'ich', 'das', 'hier', 'in', 'der', 'Welt', 'der', 'Welt', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:54:48,721 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:54:48,721 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:54:48,721 - INFO - joeynmt.training - 	Hypothesis: Und das ist eine der K<unk> rper, die ich Ihnen zeigen, wie ich das hier in der Welt der Welt zu erreichen.
2025-05-29 19:54:50,809 - INFO - joeynmt.training - Epoch   9, Step:    46600, Batch Loss:     2.232393, Batch Acc: 0.324924, Tokens per Sec:    32212, Lr: 0.000300
2025-05-29 19:54:52,906 - INFO - joeynmt.training - Epoch   9, Step:    46700, Batch Loss:     2.317529, Batch Acc: 0.319448, Tokens per Sec:    33742, Lr: 0.000300
2025-05-29 19:54:54,846 - INFO - joeynmt.training - Epoch   9, Step:    46800, Batch Loss:     2.079588, Batch Acc: 0.325168, Tokens per Sec:    35358, Lr: 0.000300
2025-05-29 19:54:56,872 - INFO - joeynmt.training - Epoch   9, Step:    46900, Batch Loss:     2.232344, Batch Acc: 0.324971, Tokens per Sec:    33499, Lr: 0.000300
2025-05-29 19:54:58,722 - INFO - joeynmt.training - Epoch   9, Step:    47000, Batch Loss:     2.203085, Batch Acc: 0.325259, Tokens per Sec:    37764, Lr: 0.000300
2025-05-29 19:54:58,722 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:54:58,722 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:55:12,568 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.20, ppl:   9.00, acc:   0.34, generation: 13.8344[sec], evaluation: 0.0000[sec]
2025-05-29 19:55:12,568 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:55:12,651 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/45500.ckpt
2025-05-29 19:55:12,658 - INFO - joeynmt.training - Example #0
2025-05-29 19:55:12,658 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:55:12,658 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:55:12,658 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'diese', 'W@@', 'er@@', 'b@@', 'ung', 'und', 'ich', 'habe', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'K@@', 'ont@@', 'in@@', 'ent', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'K@@', 'ont@@', 'in@@', 'ent@@', '.', '</s>']
2025-05-29 19:55:12,658 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:55:12,658 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:55:12,658 - INFO - joeynmt.training - 	Hypothesis: Ich habe diese Werbung und ich habe die M<unk> glichkeiten und die M<unk> glichkeiten und die M<unk> glichkeit der Kontinent zu ver<unk> ndern und die M<unk> glichkeit der Kontinent.
2025-05-29 19:55:12,658 - INFO - joeynmt.training - Example #1
2025-05-29 19:55:12,659 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:55:12,659 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:55:12,659 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'm@@', '<unk>', 'chte', 'Ihnen', 'ein', 'paar', 'Bei@@', 'spiel@@', 'e', 'von', 'der', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'weil', 'ich', 'nicht', 'nur', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', 'w@@', 'end@@', 'en.', '</s>']
2025-05-29 19:55:12,659 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:55:12,659 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:55:12,659 - INFO - joeynmt.training - 	Hypothesis: Und ich m<unk> chte Ihnen ein paar Beispiele von der M<unk> glichkeiten zu verwenden, weil ich nicht nur die K<unk> rper zu verwenden.
2025-05-29 19:55:12,659 - INFO - joeynmt.training - Example #2
2025-05-29 19:55:12,659 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:55:12,659 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:55:12,659 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'S@@', 'o@@', 'zi@@', 'al@@', 'ist@@', 'en', 'in', 'der', 'L@@', 'age', 'ist,', 'dass', 'die', 'K@@', 'li@@', 'ma@@', 'w@@', 'andel@@', ',', 'die', 'wir', 'in', 'der', 'Welt', 'ver@@', '<unk>', 'n@@', 'der@@', 'n', 'k@@', '<unk>', 'n@@', 'n@@', 'en.', '</s>']
2025-05-29 19:55:12,659 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:55:12,659 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:55:12,659 - INFO - joeynmt.training - 	Hypothesis: Die Sozialisten in der Lage ist, dass die Klimawandel, die wir in der Welt ver<unk> ndern k<unk> nnen.
2025-05-29 19:55:12,659 - INFO - joeynmt.training - Example #3
2025-05-29 19:55:12,660 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:55:12,660 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:55:12,660 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'ein', 'g@@', 'ro@@', '<unk>', 'es', 'Pro@@', 'bl@@', 'em', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'zu', 'ver@@', 'w@@', 'end@@', 'en.', '</s>']
2025-05-29 19:55:12,660 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:55:12,660 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:55:12,660 - INFO - joeynmt.training - 	Hypothesis: Es ist ein gro<unk> es Problem und die M<unk> glichkeiten und die M<unk> glichkeiten zu verwenden.
2025-05-29 19:55:12,660 - INFO - joeynmt.training - Example #4
2025-05-29 19:55:12,660 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:55:12,660 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:55:12,660 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'K@@', 'ar@@', 'te', 'ist', 'eine', 'der', 'K@@', 'ar@@', 'te', 'der', 'K@@', 'ar@@', 'te', 'der', 'K@@', 'ar@@', 'te', 'der', 'K@@', 'ar@@', 'ten', 'von', '1@@', '5', 'M@@', 'in@@', 'ut@@', 'en', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'zu', 'ver@@', 'w@@', 'end@@', 'en.', '</s>']
2025-05-29 19:55:12,660 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:55:12,660 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:55:12,660 - INFO - joeynmt.training - 	Hypothesis: Die Karte ist eine der Karte der Karte der Karte der Karten von 15 Minuten und die M<unk> glichkeiten zu verwenden.
2025-05-29 19:55:15,734 - INFO - joeynmt.training - Epoch   9, Step:    47100, Batch Loss:     2.166671, Batch Acc: 0.322784, Tokens per Sec:    22407, Lr: 0.000300
2025-05-29 19:55:17,864 - INFO - joeynmt.training - Epoch   9, Step:    47200, Batch Loss:     2.228660, Batch Acc: 0.322429, Tokens per Sec:    32745, Lr: 0.000300
2025-05-29 19:55:19,968 - INFO - joeynmt.training - Epoch   9, Step:    47300, Batch Loss:     2.332961, Batch Acc: 0.324954, Tokens per Sec:    34440, Lr: 0.000300
2025-05-29 19:55:22,016 - INFO - joeynmt.training - Epoch   9, Step:    47400, Batch Loss:     2.203926, Batch Acc: 0.319680, Tokens per Sec:    34583, Lr: 0.000300
2025-05-29 19:55:24,102 - INFO - joeynmt.training - Epoch   9, Step:    47500, Batch Loss:     2.243322, Batch Acc: 0.322147, Tokens per Sec:    33778, Lr: 0.000300
2025-05-29 19:55:24,102 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:55:24,102 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:55:37,032 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.20, ppl:   9.01, acc:   0.33, generation: 12.9205[sec], evaluation: 0.0000[sec]
2025-05-29 19:55:37,114 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/45000.ckpt
2025-05-29 19:55:37,120 - INFO - joeynmt.training - Example #0
2025-05-29 19:55:37,120 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:55:37,120 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:55:37,120 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'von', 'der', 'S@@', 'on@@', 'ne', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'W@@', '<unk>', 'r@@', 'ter@@', ',', 'die', 'wir', 'in', 'den', 'letz@@', 'ten', '20', 'Jahren', 'in', 'den', 'U@@', 'S@@', 'A', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'S@@', 'tra@@', '<unk>', 'e', 'in', 'den', 'U@@', 'S@@', 'A', '<unk>', 'ber@@', 'zeu@@', 'g@@', 't', 'und', 'die', 'S@@', 'pr@@', 'ache', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:55:37,121 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:55:37,121 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:55:37,121 - INFO - joeynmt.training - 	Hypothesis: Und ich habe die M<unk> glichkeit von der Sonne und die M<unk> glichkeit der W<unk> rter, die wir in den letzten 20 Jahren in den USA und die M<unk> glichkeit der Stra<unk> e in den USA <unk> berzeugt und die Sprache zu erreichen.
2025-05-29 19:55:37,121 - INFO - joeynmt.training - Example #1
2025-05-29 19:55:37,121 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:55:37,121 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:55:37,121 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'm@@', '<unk>', 'chte', 'Ihnen', 'ein', 'paar', 'Bei@@', 'spiel@@', 'e', 'von', 'der', 'S@@', 'o@@', 'ft@@', 'w@@', 'are', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:55:37,121 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:55:37,121 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:55:37,121 - INFO - joeynmt.training - 	Hypothesis: Und ich m<unk> chte Ihnen ein paar Beispiele von der Software zu erreichen.
2025-05-29 19:55:37,121 - INFO - joeynmt.training - Example #2
2025-05-29 19:55:37,121 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:55:37,121 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:55:37,121 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Das', 'ist', 'ein', 'g@@', 'ro@@', '<unk>', 'ar@@', 'tig@@', 'es', 'Pro@@', 'bl@@', 'em', 'auf', 'der', 'S@@', 'tra@@', '<unk>', 'e', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'und', 'das', 'ist', 'ein', 'sehr', 'gut@@', 'es', 'Leben', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:55:37,121 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:55:37,121 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:55:37,121 - INFO - joeynmt.training - 	Hypothesis: Das ist ein gro<unk> artiges Problem auf der Stra<unk> e zu verwenden, und das ist ein sehr gutes Leben zu ver<unk> ndern.
2025-05-29 19:55:37,122 - INFO - joeynmt.training - Example #3
2025-05-29 19:55:37,122 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:55:37,122 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:55:37,122 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'ein', 'sehr', 'sch@@', '<unk>', 'n@@', 'es', 'Bei@@', 'spiel@@', ',', 'die', 'wir', 'in', 'der', 'Welt', 'ver@@', '<unk>', 'n@@', 'der@@', 'n', 'k@@', '<unk>', 'n@@', 'n@@', 'en.', '</s>']
2025-05-29 19:55:37,122 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:55:37,122 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:55:37,122 - INFO - joeynmt.training - 	Hypothesis: Es ist ein sehr sch<unk> nes Beispiel, die wir in der Welt ver<unk> ndern k<unk> nnen.
2025-05-29 19:55:37,122 - INFO - joeynmt.training - Example #4
2025-05-29 19:55:37,122 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:55:37,122 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:55:37,122 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'mei@@', 'sten', 'Leute', 'haben', 'die', 'mei@@', 'sten', 'Menschen', 'in', 'der', 'L@@', 'age', 'in', 'der', 'Welt', 'ver@@', '<unk>', 'n@@', 'der@@', 'n', 'k@@', '<unk>', 'n@@', 'n@@', 'en.', '</s>']
2025-05-29 19:55:37,122 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:55:37,122 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:55:37,122 - INFO - joeynmt.training - 	Hypothesis: Die meisten Leute haben die meisten Menschen in der Lage in der Welt ver<unk> ndern k<unk> nnen.
2025-05-29 19:55:39,336 - INFO - joeynmt.training - Epoch   9, Step:    47600, Batch Loss:     2.200054, Batch Acc: 0.322272, Tokens per Sec:    30019, Lr: 0.000300
2025-05-29 19:55:41,550 - INFO - joeynmt.training - Epoch   9, Step:    47700, Batch Loss:     2.206747, Batch Acc: 0.324251, Tokens per Sec:    31941, Lr: 0.000300
2025-05-29 19:55:43,376 - INFO - joeynmt.training - Epoch   9, Step:    47800, Batch Loss:     2.153037, Batch Acc: 0.323721, Tokens per Sec:    38261, Lr: 0.000300
2025-05-29 19:55:45,401 - INFO - joeynmt.training - Epoch   9, Step:    47900, Batch Loss:     2.186816, Batch Acc: 0.325200, Tokens per Sec:    35562, Lr: 0.000300
2025-05-29 19:55:47,358 - INFO - joeynmt.training - Epoch   9, Step:    48000, Batch Loss:     2.175765, Batch Acc: 0.321337, Tokens per Sec:    36634, Lr: 0.000300
2025-05-29 19:55:47,358 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:55:47,358 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:56:03,200 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.20, ppl:   8.99, acc:   0.34, generation: 15.8301[sec], evaluation: 0.0000[sec]
2025-05-29 19:56:03,201 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:56:03,281 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/44500.ckpt
2025-05-29 19:56:03,287 - INFO - joeynmt.training - Example #0
2025-05-29 19:56:03,287 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:56:03,287 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:56:03,287 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'ein', 'sehr', 'sch@@', 'wi@@', 'er@@', 'ig@@', 'es', 'W@@', 'ach@@', 'st@@', 'um@@', 's@@', 'k@@', 'ra@@', 'ft', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'K@@', '<unk>', 'r@@', 'per', 'f@@', '<unk>', 'r', 'die', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'die', 'in', 'den', '19@@', '8@@', '0@@', 'ern@@', ',', 'die', 'in', 'den', '19@@', '8@@', '0@@', 'ern@@', ',', 'die', 'in', 'den', '19@@', '8@@', '0@@', 'ern@@', ',', 'die', 'in', 'den', '19@@', '8@@', '0@@', 'ern@@', ',', 'die', 'sich', 'in', 'den', '19@@', '8@@', '0@@', 'ern@@', ',', 'die', 'sich', 'in', 'den', '19@@', '8@@', '0@@', 'ern@@', ',', 'die', 'in', 'den', 'U@@', 'S@@', 'A', 'und', 'der', 'M@@', '<unk>', 'glich@@', 'keit', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per@@', 't@@', 'ei@@', 'le', 'der', 'K@@', 'ont@@']
2025-05-29 19:56:03,287 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:56:03,287 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:56:03,287 - INFO - joeynmt.training - 	Hypothesis: Und das ist ein sehr schwieriges Wachstumskraft und die M<unk> glichkeit der K<unk> rper f<unk> r die K<unk> rper, die in den 1980ern, die in den 1980ern, die in den 1980ern, die in den 1980ern, die sich in den 1980ern, die sich in den 1980ern, die in den USA und der M<unk> glichkeit und die K<unk> rperteile der Kont
2025-05-29 19:56:03,287 - INFO - joeynmt.training - Example #1
2025-05-29 19:56:03,288 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:56:03,288 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:56:03,288 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'die', 'K@@', 'un@@', 'st@@', 'st@@', 'wer@@', 'k@@', 'e', 'der', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'weil', 'es', 'nicht', 'nur', 'die', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'sondern', 'auch', 'nicht', 'nur', 'die', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'die', 'sich', 'selbst', 'ver@@', 'st@@', '<unk>', 'n@@', 'd@@', 'lich', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:56:03,288 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:56:03,288 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:56:03,288 - INFO - joeynmt.training - 	Hypothesis: Und das ist die Kunststwerke der K<unk> rper, weil es nicht nur die K<unk> rper, sondern auch nicht nur die K<unk> rper, die sich selbst verst<unk> ndlich zu erreichen.
2025-05-29 19:56:03,288 - INFO - joeynmt.training - Example #2
2025-05-29 19:56:03,288 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:56:03,288 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:56:03,288 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'S@@', 'ache', 'ist', 'die', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'die', 'ich', 'in', 'einem', 'K@@', 'li@@', 'ma@@', 'w@@', 'an@@', 'del', 'f@@', '<unk>', 'r', 'die', 'K@@', 'li@@', 'ma@@', 'w@@', 'an@@', 'del', 'zu', 'er@@', 'for@@', 'sch@@', 'en.', '</s>']
2025-05-29 19:56:03,288 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:56:03,288 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:56:03,288 - INFO - joeynmt.training - 	Hypothesis: Die Sache ist die K<unk> rper, die ich in einem Klimawandel f<unk> r die Klimawandel zu erforschen.
2025-05-29 19:56:03,288 - INFO - joeynmt.training - Example #3
2025-05-29 19:56:03,288 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:56:03,288 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:56:03,288 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Sie', 'haben', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'von', 'der', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'die', 'sich', 'selbst', 'ver@@', '<unk>', 'n@@', 'der@@', 'n', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'die', 'sich', 'selbst', 'ver@@', '<unk>', 'n@@', 'der@@', 't', 'und', 'die', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'die', 'sich', 'selbst', 'ver@@', '<unk>', 'n@@', 'der@@', 't', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'des', 'K@@', '<unk>', 'r@@', 'per@@', 's', 'zu', 'ver@@', 'w@@', 'end@@', 'en.', '</s>']
2025-05-29 19:56:03,288 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:56:03,289 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:56:03,289 - INFO - joeynmt.training - 	Hypothesis: Sie haben die M<unk> glichkeit von der K<unk> rper, die sich selbst ver<unk> ndern und die K<unk> rper, die sich selbst ver<unk> ndert und die K<unk> rper, die sich selbst ver<unk> ndert und die M<unk> glichkeit des K<unk> rpers zu verwenden.
2025-05-29 19:56:03,289 - INFO - joeynmt.training - Example #4
2025-05-29 19:56:03,289 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:56:03,289 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:56:03,289 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'mei@@', 'sten', 'von', 'uns', 'k@@', 'ur@@', 'z@@', 'en', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'Welt', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:56:03,289 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:56:03,289 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:56:03,289 - INFO - joeynmt.training - 	Hypothesis: Die meisten von uns kurzen M<unk> nnern und die M<unk> glichkeit der Welt zu ver<unk> ndern.
2025-05-29 19:56:05,324 - INFO - joeynmt.training - Epoch   9, Step:    48100, Batch Loss:     2.243876, Batch Acc: 0.323569, Tokens per Sec:    32420, Lr: 0.000300
2025-05-29 19:56:05,653 - INFO - joeynmt.training - Epoch   9: total training loss 11711.22
2025-05-29 19:56:05,653 - INFO - joeynmt.training - EPOCH 10
2025-05-29 19:56:07,336 - INFO - joeynmt.training - Epoch  10, Step:    48200, Batch Loss:     2.207812, Batch Acc: 0.329361, Tokens per Sec:    35958, Lr: 0.000300
2025-05-29 19:56:09,207 - INFO - joeynmt.training - Epoch  10, Step:    48300, Batch Loss:     2.024273, Batch Acc: 0.334767, Tokens per Sec:    38296, Lr: 0.000300
2025-05-29 19:56:11,199 - INFO - joeynmt.training - Epoch  10, Step:    48400, Batch Loss:     2.163428, Batch Acc: 0.332691, Tokens per Sec:    35443, Lr: 0.000300
2025-05-29 19:56:13,060 - INFO - joeynmt.training - Epoch  10, Step:    48500, Batch Loss:     2.220239, Batch Acc: 0.331458, Tokens per Sec:    37731, Lr: 0.000300
2025-05-29 19:56:13,060 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:56:13,060 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:56:27,066 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.20, ppl:   9.00, acc:   0.34, generation: 13.9962[sec], evaluation: 0.0000[sec]
2025-05-29 19:56:27,151 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/46500.ckpt
2025-05-29 19:56:27,157 - INFO - joeynmt.training - Example #0
2025-05-29 19:56:27,157 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:56:27,157 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:56:27,157 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'von', 'der', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'die', 'ich', 'Ihnen', 'zeig@@', 'en', 'wer@@', 'de,', 'wie', 'die', 'S@@', 'ache', 'in', 'den', '19@@', '7@@', '0@@', 'ern', 'in', 'den', '19@@', '7@@', '0@@', 'ern', 'in', 'den', '19@@', '7@@', '0@@', 'ern', 'in', 'den', 'U@@', 'S@@', 'A', 'und', 'der', 'K@@', 'ont@@', 'in@@', 'ent@@', '.', '</s>']
2025-05-29 19:56:27,157 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:56:27,158 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:56:27,158 - INFO - joeynmt.training - 	Hypothesis: Ich habe die M<unk> glichkeit von der M<unk> glichkeiten und die M<unk> glichkeit der K<unk> rper, die ich Ihnen zeigen werde, wie die Sache in den 1970ern in den 1970ern in den 1970ern in den USA und der Kontinent.
2025-05-29 19:56:27,158 - INFO - joeynmt.training - Example #1
2025-05-29 19:56:27,158 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:56:27,158 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:56:27,158 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'm@@', '<unk>', 'chte', 'Ihnen', 'ein', 'paar', 'Bei@@', 'spiel@@', 'e', 'von', 'der', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:56:27,158 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:56:27,158 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:56:27,158 - INFO - joeynmt.training - 	Hypothesis: Und ich m<unk> chte Ihnen ein paar Beispiele von der M<unk> glichkeiten zu erreichen.
2025-05-29 19:56:27,158 - INFO - joeynmt.training - Example #2
2025-05-29 19:56:27,158 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:56:27,158 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:56:27,158 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Das', 'ist', 'ein', 'g@@', 'ro@@', '<unk>', 'es', 'Pro@@', 'bl@@', 'em', 'der', 'K@@', 'li@@', 'ma@@', 'w@@', 'andel@@', ',', 'der', 'sich', 'in', 'den', 'U@@', 'S@@', 'A', 'und', 'der', 'K@@', 'li@@', 'ma@@', 'w@@', 'andel@@', ',', 'und', 'es', 'ist', 'ein', 'g@@', 'ro@@', '<unk>', 'er', 'K@@', 'li@@', 'ma@@', 'w@@', 'andel@@', '.', '</s>']
2025-05-29 19:56:27,158 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:56:27,158 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:56:27,158 - INFO - joeynmt.training - 	Hypothesis: Das ist ein gro<unk> es Problem der Klimawandel, der sich in den USA und der Klimawandel, und es ist ein gro<unk> er Klimawandel.
2025-05-29 19:56:27,158 - INFO - joeynmt.training - Example #3
2025-05-29 19:56:27,159 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:56:27,159 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:56:27,159 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'ein', 'kl@@', 'eines', 'T@@', 'ag@@', 'es', 'und', 'das', 'ist', 'ein', 'sehr', 'sch@@', 'wi@@', 'eri@@', 'g', 'zu', 'er@@', 'kl@@', '<unk>', 'r@@', 'en.', '</s>']
2025-05-29 19:56:27,159 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:56:27,159 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:56:27,159 - INFO - joeynmt.training - 	Hypothesis: Es ist ein kleines Tages und das ist ein sehr schwierig zu erkl<unk> ren.
2025-05-29 19:56:27,159 - INFO - joeynmt.training - Example #4
2025-05-29 19:56:27,159 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:56:27,159 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:56:27,159 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'M@@', '<unk>', 'glich@@', 'keit', 'ist', 'eine', 'der', 'K@@', 'ar@@', 'te', 'der', 'K@@', 'ar@@', 'te', 'der', 'K@@', 'ar@@', 'te', 'der', 'K@@', 'ar@@', 'te', 'in', 'der', 'Welt', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:56:27,159 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:56:27,159 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:56:27,159 - INFO - joeynmt.training - 	Hypothesis: Die M<unk> glichkeit ist eine der Karte der Karte der Karte der Karte in der Welt zu erreichen.
2025-05-29 19:56:29,179 - INFO - joeynmt.training - Epoch  10, Step:    48600, Batch Loss:     2.170934, Batch Acc: 0.330975, Tokens per Sec:    32920, Lr: 0.000300
2025-05-29 19:56:31,142 - INFO - joeynmt.training - Epoch  10, Step:    48700, Batch Loss:     2.147280, Batch Acc: 0.334178, Tokens per Sec:    35996, Lr: 0.000300
2025-05-29 19:56:33,109 - INFO - joeynmt.training - Epoch  10, Step:    48800, Batch Loss:     2.132192, Batch Acc: 0.338005, Tokens per Sec:    35566, Lr: 0.000300
2025-05-29 19:56:35,082 - INFO - joeynmt.training - Epoch  10, Step:    48900, Batch Loss:     2.145841, Batch Acc: 0.329488, Tokens per Sec:    36157, Lr: 0.000300
2025-05-29 19:56:36,911 - INFO - joeynmt.training - Epoch  10, Step:    49000, Batch Loss:     2.240895, Batch Acc: 0.331486, Tokens per Sec:    38385, Lr: 0.000300
2025-05-29 19:56:36,911 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:56:36,912 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:56:50,525 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.20, ppl:   9.00, acc:   0.34, generation: 13.6026[sec], evaluation: 0.0000[sec]
2025-05-29 19:56:50,607 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/47500.ckpt
2025-05-29 19:56:50,613 - INFO - joeynmt.training - Example #0
2025-05-29 19:56:50,613 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:56:50,613 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:56:50,613 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'von', 'der', 'Ver@@', 'gan@@', 'gen@@', 'heit', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'K@@', 'ont@@', 'ex@@', 't', 'der', 'K@@', 'ont@@', 'ex@@', 't', 'der', 'K@@', 'ont@@', 'ex@@', 't', 'der', 'K@@', 'ont@@', 'ex@@', 't', 'der', 'K@@', 'ont@@', 'ex@@', 't', 'der', 'K@@', 'ont@@', 'ex@@', 't', 'der', 'K@@', 'ont@@', 'ex@@', 't', 'der', 'K@@', 'ont@@', 'ex@@', 't', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'von', 'den', 'F@@', '<unk>', 'h@@', 'ig@@', 'kei@@', 'ten', 'der', 'K@@', 'ont@@', 'ex@@', 't', 'der', 'K@@', 'ont@@', 'ex@@', 't', 'der', 'K@@', 'ont@@', 'ex@@', 't', 'der', 'K@@', 'ont@@', 'ex@@', 't', 'der', 'K@@', 'ont@@', 'ex@@', 't', 'der', 'K@@', 'ont@@', 'ex@@', 't', 'in', 'den', 'U@@', 'S@@', 'A', 'zu', 'ver@@', 'w@@', 'end@@']
2025-05-29 19:56:50,614 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:56:50,614 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:56:50,614 - INFO - joeynmt.training - 	Hypothesis: Ich habe die M<unk> glichkeit von der Vergangenheit und die M<unk> glichkeit der Kontext der Kontext der Kontext der Kontext der Kontext der Kontext der Kontext der Kontext und die M<unk> glichkeit von den F<unk> higkeiten der Kontext der Kontext der Kontext der Kontext der Kontext der Kontext in den USA zu verwend
2025-05-29 19:56:50,614 - INFO - joeynmt.training - Example #1
2025-05-29 19:56:50,614 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:56:50,614 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:56:50,614 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'sag@@', 'te', 'ich', 'mi@@', 'r,', 'dass', 'ich', 'das', 'nicht', 'nur', 'die', 'Welt', 'der', 'Welt', 'nicht', 'mehr', 'so', 'viel', 'wie', 'ich', 'das', 'nicht', 'ver@@', '<unk>', 'n@@', 'der@@', 'n', 'k@@', '<unk>', 'n@@', 'n@@', 'en.', '</s>']
2025-05-29 19:56:50,614 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:56:50,614 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:56:50,614 - INFO - joeynmt.training - 	Hypothesis: Und ich sagte ich mir, dass ich das nicht nur die Welt der Welt nicht mehr so viel wie ich das nicht ver<unk> ndern k<unk> nnen.
2025-05-29 19:56:50,614 - INFO - joeynmt.training - Example #2
2025-05-29 19:56:50,614 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:56:50,614 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:56:50,614 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Das', 'ist', 'ein', 'g@@', 'ro@@', '<unk>', 'es', 'Pro@@', 'bl@@', 'em', 'der', 'K@@', '<unk>', 'r@@', 'per', 'und', 'die', 'M@@', '<unk>', 'n@@', 'ner', 'in', 'der', 'L@@', 'age', 'der', 'Welt', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:56:50,614 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:56:50,614 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:56:50,614 - INFO - joeynmt.training - 	Hypothesis: Das ist ein gro<unk> es Problem der K<unk> rper und die M<unk> nner in der Lage der Welt zu ver<unk> ndern.
2025-05-29 19:56:50,614 - INFO - joeynmt.training - Example #3
2025-05-29 19:56:50,615 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:56:50,615 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:56:50,615 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'ein', 'sehr', 'sch@@', 'wi@@', 'er@@', 'ig@@', ',', 'das', 'ist', 'eine', 'M@@', 'en@@', 'ge', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'Fr@@', 'auen', 'und', 'der', 'K@@', 'om@@', 'pl@@', 'ex@@', 'it@@', '<unk>', 't', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'und', 'das', 'ist', 'eine', 'M@@', 'en@@', 'ge', 'M@@', '<unk>', 'n@@', 'ner', 'und', 'Fr@@', 'auen', 'und', 'K@@', 'om@@', 'pl@@', 'ex@@', 'it@@', '<unk>', 't', 'zu', 'ver@@', 'w@@', 'end@@', 'en.', '</s>']
2025-05-29 19:56:50,615 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:56:50,615 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:56:50,615 - INFO - joeynmt.training - 	Hypothesis: Es ist ein sehr schwierig, das ist eine Menge M<unk> nner und Frauen und der Komplexit<unk> t zu verwenden, und das ist eine Menge M<unk> nner und Frauen und Komplexit<unk> t zu verwenden.
2025-05-29 19:56:50,615 - INFO - joeynmt.training - Example #4
2025-05-29 19:56:50,615 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:56:50,615 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:56:50,615 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'mei@@', 'sten', 'Menschen', 'sind', 'die', '<unk>', 'ber@@', 'ra@@', 'sch@@', 'end@@', ',', 'dass', 'wir', 'uns', 'in', 'den', 'letz@@', 'ten', '1@@', '5', 'Jahren', 'in', 'den', 'letz@@', 'ten', '1@@', '5', 'Jahren', 'er@@', 'for@@', 'der@@', 't.', '</s>']
2025-05-29 19:56:50,615 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:56:50,615 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:56:50,615 - INFO - joeynmt.training - 	Hypothesis: Die meisten Menschen sind die <unk> berraschend, dass wir uns in den letzten 15 Jahren in den letzten 15 Jahren erfordert.
2025-05-29 19:56:52,637 - INFO - joeynmt.training - Epoch  10, Step:    49100, Batch Loss:     2.245116, Batch Acc: 0.330036, Tokens per Sec:    33601, Lr: 0.000300
2025-05-29 19:56:55,750 - INFO - joeynmt.training - Epoch  10, Step:    49200, Batch Loss:     2.204436, Batch Acc: 0.329645, Tokens per Sec:    22821, Lr: 0.000300
2025-05-29 19:56:57,938 - INFO - joeynmt.training - Epoch  10, Step:    49300, Batch Loss:     2.198257, Batch Acc: 0.328976, Tokens per Sec:    31929, Lr: 0.000300
2025-05-29 19:57:00,072 - INFO - joeynmt.training - Epoch  10, Step:    49400, Batch Loss:     2.255006, Batch Acc: 0.328525, Tokens per Sec:    33948, Lr: 0.000300
2025-05-29 19:57:02,119 - INFO - joeynmt.training - Epoch  10, Step:    49500, Batch Loss:     2.166633, Batch Acc: 0.333480, Tokens per Sec:    34461, Lr: 0.000300
2025-05-29 19:57:02,119 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:57:02,119 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:57:14,108 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.20, ppl:   9.01, acc:   0.34, generation: 11.9814[sec], evaluation: 0.0000[sec]
2025-05-29 19:57:14,108 - INFO - joeynmt.training - Example #0
2025-05-29 19:57:14,109 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:57:14,109 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:57:14,109 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'mich', 'in', 'der', 'L@@', 'age', 'f@@', '<unk>', 'r', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:57:14,109 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:57:14,109 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:57:14,109 - INFO - joeynmt.training - 	Hypothesis: Ich habe mich in der Lage f<unk> r die M<unk> glichkeiten und die M<unk> glichkeiten zu ver<unk> ndern.
2025-05-29 19:57:14,109 - INFO - joeynmt.training - Example #1
2025-05-29 19:57:14,109 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:57:14,109 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:57:14,109 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'm@@', '<unk>', 'chte', 'Ihnen', 'sag@@', 'en,', 'dass', 'es', 'eine', 'M@@', 'en@@', 'ge', 'F@@', 'ra@@', 'u', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'weil', 'ich', 'das', 'nicht', 'ver@@', 'w@@', 'end@@', 'en,', 'weil', 'ich', 'das', 'nicht', 'ver@@', 'st@@', '<unk>', 'n@@', 'd@@', 'lich', 'ist.', '</s>']
2025-05-29 19:57:14,109 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:57:14,110 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:57:14,110 - INFO - joeynmt.training - 	Hypothesis: Und ich m<unk> chte Ihnen sagen, dass es eine Menge Frau zu verwenden, weil ich das nicht verwenden, weil ich das nicht verst<unk> ndlich ist.
2025-05-29 19:57:14,110 - INFO - joeynmt.training - Example #2
2025-05-29 19:57:14,110 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:57:14,110 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:57:14,110 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Das', 'ist', 'ein', 'g@@', 'ro@@', '<unk>', 'es', 'Pro@@', 'bl@@', 'em', 'der', 'K@@', 'li@@', 'ma@@', 'w@@', 'andel@@', ',', 'und', 'das', 'ist', 'ein', 'sehr', 'sch@@', 'wi@@', 'eri@@', 'g', 'zu', 'f@@', '<unk>', 'hr@@', 'en.', '</s>']
2025-05-29 19:57:14,110 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:57:14,110 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:57:14,110 - INFO - joeynmt.training - 	Hypothesis: Das ist ein gro<unk> es Problem der Klimawandel, und das ist ein sehr schwierig zu f<unk> hren.
2025-05-29 19:57:14,110 - INFO - joeynmt.training - Example #3
2025-05-29 19:57:14,110 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:57:14,110 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:57:14,110 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'ein', 'sehr', 'sch@@', 'wi@@', 'er@@', 'ig@@', ',', 'das', 'ist', 'ein', 'sehr', 'sch@@', 'wi@@', 'er@@', 'ig@@', ',', 'das', 'wir', 'nicht', 'er@@', 'war@@', 'ten,', 'aber', 'das', 'ist', 'ein', 'bis@@', 'schen', 'wie', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', 'k@@', 'auf@@', 'en.', '</s>']
2025-05-29 19:57:14,110 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:57:14,110 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:57:14,110 - INFO - joeynmt.training - 	Hypothesis: Es ist ein sehr schwierig, das ist ein sehr schwierig, das wir nicht erwarten, aber das ist ein bisschen wie die K<unk> rper zu verkaufen.
2025-05-29 19:57:14,111 - INFO - joeynmt.training - Example #4
2025-05-29 19:57:14,111 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:57:14,111 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:57:14,111 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'mei@@', 'sten', 'von', 'uns', 'haben', 'eine', 'M@@', 'en@@', 'ge', 'S@@', 'ach@@', 'e.', '</s>']
2025-05-29 19:57:14,111 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:57:14,111 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:57:14,111 - INFO - joeynmt.training - 	Hypothesis: Die meisten von uns haben eine Menge Sache.
2025-05-29 19:57:16,121 - INFO - joeynmt.training - Epoch  10, Step:    49600, Batch Loss:     2.214012, Batch Acc: 0.326700, Tokens per Sec:    34858, Lr: 0.000300
2025-05-29 19:57:18,121 - INFO - joeynmt.training - Epoch  10, Step:    49700, Batch Loss:     2.222947, Batch Acc: 0.329918, Tokens per Sec:    36243, Lr: 0.000300
2025-05-29 19:57:20,217 - INFO - joeynmt.training - Epoch  10, Step:    49800, Batch Loss:     2.132434, Batch Acc: 0.330192, Tokens per Sec:    34380, Lr: 0.000300
2025-05-29 19:57:22,309 - INFO - joeynmt.training - Epoch  10, Step:    49900, Batch Loss:     2.128082, Batch Acc: 0.333220, Tokens per Sec:    33692, Lr: 0.000300
2025-05-29 19:57:24,367 - INFO - joeynmt.training - Epoch  10, Step:    50000, Batch Loss:     2.096088, Batch Acc: 0.328985, Tokens per Sec:    32674, Lr: 0.000300
2025-05-29 19:57:24,367 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:57:24,368 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:57:35,542 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.20, ppl:   9.04, acc:   0.33, generation: 11.1661[sec], evaluation: 0.0000[sec]
2025-05-29 19:57:35,542 - INFO - joeynmt.training - Example #0
2025-05-29 19:57:35,543 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:57:35,543 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:57:35,543 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'in', 'den', 'U@@', 'S@@', 'A', 'und', 'der', 'K@@', 'ont@@', 'in@@', 'ent', 'der', 'K@@', 'ont@@', 'in@@', 'ent', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:57:35,543 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:57:35,543 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:57:35,543 - INFO - joeynmt.training - 	Hypothesis: Und ich habe ein paar Minuten in den USA und der Kontinent der Kontinent zu erreichen.
2025-05-29 19:57:35,543 - INFO - joeynmt.training - Example #1
2025-05-29 19:57:35,543 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:57:35,543 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:57:35,543 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'S@@', 'pr@@', 'ache', 'ist', 'die', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:57:35,544 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:57:35,544 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:57:35,544 - INFO - joeynmt.training - 	Hypothesis: Und das ist die M<unk> glichkeit der Sprache ist die K<unk> rper zu ver<unk> ndern.
2025-05-29 19:57:35,544 - INFO - joeynmt.training - Example #2
2025-05-29 19:57:35,544 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:57:35,544 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:57:35,544 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'ein', 'M@@', '<unk>', 'd@@', 'chen', 'in', 'der', 'L@@', 'age', 'der', 'S@@', 'itu@@', 'ation', 'in', 'der', 'L@@', 'age', 'der', 'Welt', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n', 'und', 'das', 'ist', 'eine', 'M@@', '<unk>', 'glich@@', 'kei@@', 't,', 'die', 'wir', 'in', 'der', 'Welt', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:57:35,544 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:57:35,544 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:57:35,544 - INFO - joeynmt.training - 	Hypothesis: Und das ist ein M<unk> dchen in der Lage der Situation in der Lage der Welt zu ver<unk> ndern und das ist eine M<unk> glichkeit, die wir in der Welt zu ver<unk> ndern.
2025-05-29 19:57:35,544 - INFO - joeynmt.training - Example #3
2025-05-29 19:57:35,544 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:57:35,544 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:57:35,544 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'eine', 'M@@', 'en@@', 'ge', 'S@@', 'ach@@', 'e,', 'die', 'wir', 'in', 'der', 'L@@', 'age', 'sein,', 'die', 'wir', 'in', 'der', 'L@@', 'age', 'sein,', 'das', 'wir', 'nicht', 'nur', 'die', 'K@@', 'rank@@', 'heit', 'der', 'Welt', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:57:35,544 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:57:35,544 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:57:35,544 - INFO - joeynmt.training - 	Hypothesis: Es ist eine Menge Sache, die wir in der Lage sein, die wir in der Lage sein, das wir nicht nur die Krankheit der Welt zu ver<unk> ndern.
2025-05-29 19:57:35,545 - INFO - joeynmt.training - Example #4
2025-05-29 19:57:35,545 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:57:35,545 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:57:35,545 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'S@@', 'pr@@', 'ache', 'ist', 'also', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 't,', 'die', 'ich', 'in', 'den', 'letz@@', 'ten', '1@@', '5', 'Jahr@@', 'en.', '</s>']
2025-05-29 19:57:35,545 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:57:35,545 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:57:35,545 - INFO - joeynmt.training - 	Hypothesis: Die Sprache ist also ein paar Minuten und die M<unk> glichkeit, die ich in den letzten 15 Jahren.
2025-05-29 19:57:37,698 - INFO - joeynmt.training - Epoch  10, Step:    50100, Batch Loss:     2.303748, Batch Acc: 0.331379, Tokens per Sec:    31963, Lr: 0.000300
2025-05-29 19:57:39,774 - INFO - joeynmt.training - Epoch  10, Step:    50200, Batch Loss:     2.202878, Batch Acc: 0.331869, Tokens per Sec:    33994, Lr: 0.000300
2025-05-29 19:57:41,785 - INFO - joeynmt.training - Epoch  10, Step:    50300, Batch Loss:     2.056643, Batch Acc: 0.329339, Tokens per Sec:    34226, Lr: 0.000300
2025-05-29 19:57:43,737 - INFO - joeynmt.training - Epoch  10, Step:    50400, Batch Loss:     2.196814, Batch Acc: 0.324018, Tokens per Sec:    34386, Lr: 0.000300
2025-05-29 19:57:45,762 - INFO - joeynmt.training - Epoch  10, Step:    50500, Batch Loss:     2.195112, Batch Acc: 0.325653, Tokens per Sec:    35148, Lr: 0.000300
2025-05-29 19:57:45,762 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:57:45,762 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:57:55,467 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.19, ppl:   8.97, acc:   0.34, generation: 9.6957[sec], evaluation: 0.0000[sec]
2025-05-29 19:57:55,467 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:57:55,542 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/46000.ckpt
2025-05-29 19:57:55,548 - INFO - joeynmt.training - Example #0
2025-05-29 19:57:55,548 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:57:55,548 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:57:55,548 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'mei@@', 'sten', 'von', 'uns', 'haben', 'wir', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'zu', 'er@@', 'rei@@', 'chen,', 'um', 'die', 'Welt', 'zu', 'er@@', 'rei@@', 'chen,', 'die', 'wir', 'in', 'den', 'U@@', 'S@@', 'A', 'und', 'der', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'zu', 'er@@', 'rei@@', 'chen', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'des', 'M@@', '<unk>', 'd@@', 'chen', 'in', 'den', 'U@@', 'S@@', 'A', 'und', 'der', 'M@@', '<unk>', 'n@@', 'n@@', 'ern', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'des', 'M@@', '<unk>', 'd@@', 'chen', 'in', 'den', 'U@@', 'S@@', 'A', 'und', 'der', 'M@@', '<unk>', 'd@@', 'chen', 'in', 'den', 'U@@', 'S@@', 'A', 'und', 'der', 'M@@', '<unk>', 'n@@', 'n@@', 'chen', 'in', 'den', 'U@@', 'S@@', 'A', 'und', 'der', 'M@@']
2025-05-29 19:57:55,548 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:57:55,548 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:57:55,548 - INFO - joeynmt.training - 	Hypothesis: Die meisten von uns haben wir die M<unk> glichkeit zu erreichen, um die Welt zu erreichen, die wir in den USA und der M<unk> nnern und die M<unk> glichkeit zu erreichen und die M<unk> glichkeit des M<unk> dchen in den USA und der M<unk> nnern und die M<unk> glichkeit des M<unk> dchen in den USA und der M<unk> dchen in den USA und der M<unk> nnchen in den USA und der M
2025-05-29 19:57:55,548 - INFO - joeynmt.training - Example #1
2025-05-29 19:57:55,549 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:57:55,549 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:57:55,549 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Das', 'ist', 'der', 'Gr@@', 'und', 'da@@', 'f@@', '<unk>', 'r', 'ist', 'die', 'M@@', '<unk>', 'glich@@', 'kei@@', 't,', 'die', 'wir', 'nicht', 'ver@@', 'w@@', 'andel@@', 'n.', '</s>']
2025-05-29 19:57:55,549 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:57:55,549 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:57:55,549 - INFO - joeynmt.training - 	Hypothesis: Das ist der Grund daf<unk> r ist die M<unk> glichkeit, die wir nicht verwandeln.
2025-05-29 19:57:55,549 - INFO - joeynmt.training - Example #2
2025-05-29 19:57:55,549 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:57:55,549 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:57:55,549 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Das', 'ist', 'ein', 'M@@', '<unk>', 'd@@', 'chen', 'in', 'der', 'L@@', 'age', 'in', 'der', 'L@@', 'age', 'in', 'der', 'L@@', 'age', 'in', 'der', 'L@@', 'age', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'die', 'wir', 'in', 'der', 'L@@', 'age', 'sein,', 'die', 'wir', 'in', 'der', 'L@@', 'age', 'sein,', 'die', 'wir', 'in', 'der', 'L@@', 'age', 'sein,', 'die', 'wir', 'in', 'der', 'L@@', 'age', 'sein,', 'die', 'wir', 'in', 'der', 'Welt', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:57:55,549 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:57:55,549 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:57:55,549 - INFO - joeynmt.training - 	Hypothesis: Das ist ein M<unk> dchen in der Lage in der Lage in der Lage in der Lage zu verwenden, die wir in der Lage sein, die wir in der Lage sein, die wir in der Lage sein, die wir in der Lage sein, die wir in der Welt zu ver<unk> ndern.
2025-05-29 19:57:55,549 - INFO - joeynmt.training - Example #3
2025-05-29 19:57:55,549 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:57:55,549 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:57:55,549 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'ein', 'W@@', 'ort', '"@@', 'O@@', 'k@@', 'a@@', 'y,', 'das', 'ist', 'ein', 'M@@', '<unk>', 'd@@', 'chen', 'und', 'das', 'ist', 'ein', 'M@@', '<unk>', 'd@@', 'chen', 'und', 'das', 'ist', 'ein', 'M@@', '<unk>', 'd@@', 'chen', 'und', 'das', 'ist', 'eine', 'M@@', 'en@@', 'ge', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'der', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', 'w@@', 'andel@@', 'n.', '</s>']
2025-05-29 19:57:55,549 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:57:55,550 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:57:55,550 - INFO - joeynmt.training - 	Hypothesis: Es ist ein Wort "Okay, das ist ein M<unk> dchen und das ist ein M<unk> dchen und das ist ein M<unk> dchen und das ist eine Menge M<unk> glichkeiten der K<unk> rper zu verwandeln.
2025-05-29 19:57:55,550 - INFO - joeynmt.training - Example #4
2025-05-29 19:57:55,550 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:57:55,550 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:57:55,550 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'mei@@', 'sten', 'von', 'uns', 'haben', 'wir', 'die', 'Welt', 'ver@@', '<unk>', 'n@@', 'der@@', 'n', 'und', 'die', 'Welt', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:57:55,550 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:57:55,550 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:57:55,550 - INFO - joeynmt.training - 	Hypothesis: Die meisten von uns haben wir die Welt ver<unk> ndern und die Welt ver<unk> ndern.
2025-05-29 19:57:57,561 - INFO - joeynmt.training - Epoch  10, Step:    50600, Batch Loss:     2.254604, Batch Acc: 0.328231, Tokens per Sec:    34071, Lr: 0.000300
2025-05-29 19:57:59,333 - INFO - joeynmt.training - Epoch  10, Step:    50700, Batch Loss:     2.208454, Batch Acc: 0.327002, Tokens per Sec:    39464, Lr: 0.000300
2025-05-29 19:58:02,360 - INFO - joeynmt.training - Epoch  10, Step:    50800, Batch Loss:     2.148719, Batch Acc: 0.327415, Tokens per Sec:    23142, Lr: 0.000300
2025-05-29 19:58:04,448 - INFO - joeynmt.training - Epoch  10, Step:    50900, Batch Loss:     2.138616, Batch Acc: 0.330566, Tokens per Sec:    32672, Lr: 0.000300
2025-05-29 19:58:06,606 - INFO - joeynmt.training - Epoch  10, Step:    51000, Batch Loss:     2.184221, Batch Acc: 0.327512, Tokens per Sec:    31847, Lr: 0.000300
2025-05-29 19:58:06,606 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:58:06,606 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:58:19,768 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.19, ppl:   8.97, acc:   0.34, generation: 13.1533[sec], evaluation: 0.0000[sec]
2025-05-29 19:58:19,768 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:58:19,850 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/48500.ckpt
2025-05-29 19:58:19,856 - INFO - joeynmt.training - Example #0
2025-05-29 19:58:19,856 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:58:19,856 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:58:19,856 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'ein', 'paar', 'T@@', 'age', 'ges@@', 'ag@@', 't,', 'die', 'ich', 'Ihnen', 'sag@@', 'e', '<unk>', 'ber', 'die', 'S@@', 'ach@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e', 'Ihnen', 'die', 'Geschichte', 'erz@@', '<unk>', 'h@@', 'l@@', 'en,', 'dass', 'die', 'in', 'den', 'U@@', 'S@@', 'A', 'in', 'den', 'U@@', 'S@@', 'A', 'in', 'den', 'U@@', 'S@@', 'A', 'in', 'den', 'U@@', 'S@@', 'A', 'in', 'den', 'U@@', 'S@@', 'A', 'in', 'den', 'U@@', 'S@@', 'A', 'in', 'den', 'U@@', 'S@@', 'A', 'in', 'den', 'U@@', 'S@@', 'A', 'in', 'den', 'U@@', 'S@@', 'A', 'in', 'den', 'U@@', 'S@@', 'A', 'und', 'der', 'M@@', 'e@@', 'er', 'in', 'den', 'U@@', 'S@@', 'A', 'und', 'der', 'M@@', '<unk>', 'n@@', 'n@@', 'chen', 'in', 'den', 'U@@', 'S@@', 'A', 'und', 'der', 'M@@', '<unk>', 'n@@']
2025-05-29 19:58:19,856 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:58:19,856 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:58:19,856 - INFO - joeynmt.training - 	Hypothesis: Ich habe ein paar Tage gesagt, die ich Ihnen sage <unk> ber die Sache, die ich Ihnen zeige Ihnen die Geschichte erz<unk> hlen, dass die in den USA in den USA in den USA in den USA in den USA in den USA in den USA in den USA in den USA in den USA und der Meer in den USA und der M<unk> nnchen in den USA und der M<unk> n
2025-05-29 19:58:19,856 - INFO - joeynmt.training - Example #1
2025-05-29 19:58:19,856 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:58:19,856 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:58:19,856 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'die', 'S@@', 'ach@@', 'e,', 'die', 'die', 'wir', 'in', 'der', 'Welt', 'ver@@', '<unk>', 'n@@', 'der@@', 'n', 'k@@', '<unk>', 'n@@', 'n@@', 'te', 'der', 'K@@', '<unk>', 'ni@@', 'g', 'zu', 'ver@@', 'w@@', 'end@@', 'en.', '</s>']
2025-05-29 19:58:19,856 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:58:19,856 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:58:19,856 - INFO - joeynmt.training - 	Hypothesis: Und das ist die Sache, die die wir in der Welt ver<unk> ndern k<unk> nnte der K<unk> nig zu verwenden.
2025-05-29 19:58:19,857 - INFO - joeynmt.training - Example #2
2025-05-29 19:58:19,857 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:58:19,857 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:58:19,857 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'ein', 'W@@', 'ort', '"@@', 'W@@', 'oh@@', 'l@@', 'st@@', 'and', 'in', 'der', 'L@@', 'age', 'f@@', '<unk>', 'r', 'die', 'S@@', 'tra@@', '<unk>', 'e', 'der', 'K@@', 'li@@', 'ma@@', 'w@@', 'andel@@', ',', 'die', 'sie', 'in', 'der', 'L@@', 'age', 'zu', 'ver@@', 'w@@', 'end@@', 'en,', 'die', 'sie', 'in', 'der', 'S@@', '<unk>', 'd@@', 'amer@@', 'ik@@', 'an@@', 'ische', 'K@@', 'li@@', 'ma@@', 'w@@', 'an@@', 'del', 'zu', 'be@@', 'komm@@', 'en.', '</s>']
2025-05-29 19:58:19,857 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:58:19,857 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:58:19,857 - INFO - joeynmt.training - 	Hypothesis: Und das ist ein Wort "Wohlstand in der Lage f<unk> r die Stra<unk> e der Klimawandel, die sie in der Lage zu verwenden, die sie in der S<unk> damerikanische Klimawandel zu bekommen.
2025-05-29 19:58:19,857 - INFO - joeynmt.training - Example #3
2025-05-29 19:58:19,857 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:58:19,857 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:58:19,857 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'ein', 'sehr', 'sch@@', 'wi@@', 'er@@', 'ig@@', 'es', 'Pro@@', 'bl@@', 'em', 'zu', 'mach@@', 'en.', '</s>']
2025-05-29 19:58:19,857 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:58:19,857 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:58:19,857 - INFO - joeynmt.training - 	Hypothesis: Es ist ein sehr schwieriges Problem zu machen.
2025-05-29 19:58:19,857 - INFO - joeynmt.training - Example #4
2025-05-29 19:58:19,858 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:58:19,858 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:58:19,858 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'mei@@', 'sten', 'von', 'uns', 'haben', 'die', 'Welt', 'ein', 'paar', 'T@@', 'age', 'ver@@', '<unk>', 'n@@', 'der@@', 'n', 'und', 'die', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'er@@', 'h@@', '<unk>', 'h@@', 't', 'und', 'die', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'in', 'den', 'letz@@', 'ten', '1@@', '5', 'Jahren', 'er@@', 'h@@', '<unk>', 'h@@', 'n@@', 'lich', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:58:19,858 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:58:19,858 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:58:19,858 - INFO - joeynmt.training - 	Hypothesis: Die meisten von uns haben die Welt ein paar Tage ver<unk> ndern und die letzten 25 Jahren in den letzten 25 Jahren in den letzten 25 Jahren erh<unk> ht und die letzten 25 Jahren in den letzten 15 Jahren erh<unk> hnlich zu erreichen.
2025-05-29 19:58:21,945 - INFO - joeynmt.training - Epoch  10, Step:    51100, Batch Loss:     2.224014, Batch Acc: 0.327603, Tokens per Sec:    32622, Lr: 0.000300
2025-05-29 19:58:24,130 - INFO - joeynmt.training - Epoch  10, Step:    51200, Batch Loss:     2.208475, Batch Acc: 0.330648, Tokens per Sec:    32623, Lr: 0.000300
2025-05-29 19:58:26,316 - INFO - joeynmt.training - Epoch  10, Step:    51300, Batch Loss:     2.202680, Batch Acc: 0.330117, Tokens per Sec:    32940, Lr: 0.000300
2025-05-29 19:58:28,272 - INFO - joeynmt.training - Epoch  10, Step:    51400, Batch Loss:     2.093030, Batch Acc: 0.328496, Tokens per Sec:    36127, Lr: 0.000300
2025-05-29 19:58:30,237 - INFO - joeynmt.training - Epoch  10, Step:    51500, Batch Loss:     2.107823, Batch Acc: 0.329657, Tokens per Sec:    36449, Lr: 0.000300
2025-05-29 19:58:30,237 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:58:30,238 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:58:42,328 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.19, ppl:   8.96, acc:   0.34, generation: 12.0821[sec], evaluation: 0.0000[sec]
2025-05-29 19:58:42,328 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:58:42,411 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/49000.ckpt
2025-05-29 19:58:42,416 - INFO - joeynmt.training - Example #0
2025-05-29 19:58:42,416 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:58:42,416 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:58:42,417 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'mich', 'ge@@', 'frag@@', 't,', 'ob', 'ich', 'das', 'hier', 'war@@', '.', '</s>']
2025-05-29 19:58:42,417 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:58:42,417 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:58:42,417 - INFO - joeynmt.training - 	Hypothesis: Und ich habe mich gefragt, ob ich das hier war.
2025-05-29 19:58:42,417 - INFO - joeynmt.training - Example #1
2025-05-29 19:58:42,417 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:58:42,417 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:58:42,417 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'die', 'Ver@@', 'ein@@', 'ig@@', 'ten', 'der', 'K@@', '<unk>', 'r@@', 'per@@', 'ung', 'der', 'Er@@', 'de', 'der', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:58:42,417 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:58:42,417 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:58:42,417 - INFO - joeynmt.training - 	Hypothesis: Und das ist die Vereinigten der K<unk> rperung der Erde der K<unk> rper zu ver<unk> ndern.
2025-05-29 19:58:42,417 - INFO - joeynmt.training - Example #2
2025-05-29 19:58:42,417 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:58:42,417 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:58:42,417 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'das', 'Pro@@', 'bl@@', 'em', 'mit', 'einem', 'F@@', 'lu@@', 'g@@', 'zeu@@', 'g', 'zu', 'einem', 'F@@', 'all', 'der', 'Welt', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:58:42,417 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:58:42,418 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:58:42,418 - INFO - joeynmt.training - 	Hypothesis: Und ich habe das Problem mit einem Flugzeug zu einem Fall der Welt zu erreichen.
2025-05-29 19:58:42,418 - INFO - joeynmt.training - Example #3
2025-05-29 19:58:42,418 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:58:42,418 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:58:42,418 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'ein', 'wen@@', 'i@@', 'g', '<unk>', 'ber', 'die', 'H@@', '<unk>', 'h@@', 'l@@', 'en', 'und', 'die', 'F@@', '<unk>', 'h@@', 'ig@@', 'kei@@', 't,', 'die', 'wir', 'in', 'der', 'Welt', 'ver@@', '<unk>', 'n@@', 'der@@', 'n', 'k@@', '<unk>', 'n@@', 'n@@', 'en.', '</s>']
2025-05-29 19:58:42,418 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:58:42,418 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:58:42,418 - INFO - joeynmt.training - 	Hypothesis: Und das ist ein wenig <unk> ber die H<unk> hlen und die F<unk> higkeit, die wir in der Welt ver<unk> ndern k<unk> nnen.
2025-05-29 19:58:42,418 - INFO - joeynmt.training - Example #4
2025-05-29 19:58:42,418 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:58:42,418 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:58:42,418 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'm@@', '<unk>', 'chte', 'Ihnen', 'ein', 'paar', 'Bei@@', 'spiel@@', 'e', 'von', 'einem', 'F@@', 'o@@', 'to', 'von', 'der', 'F@@', 'ami@@', 'li@@', 'e', 'von', 'der', 'N@@', 'at@@', 'ur', 'der', 'K@@', 'ar@@', 'te', 'der', 'Welt', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:58:42,418 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:58:42,418 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:58:42,418 - INFO - joeynmt.training - 	Hypothesis: Und ich m<unk> chte Ihnen ein paar Beispiele von einem Foto von der Familie von der Natur der Karte der Welt zu erreichen.
2025-05-29 19:58:44,511 - INFO - joeynmt.training - Epoch  10, Step:    51600, Batch Loss:     2.163358, Batch Acc: 0.331120, Tokens per Sec:    31942, Lr: 0.000300
2025-05-29 19:58:46,458 - INFO - joeynmt.training - Epoch  10, Step:    51700, Batch Loss:     2.221357, Batch Acc: 0.329974, Tokens per Sec:    34817, Lr: 0.000300
2025-05-29 19:58:48,420 - INFO - joeynmt.training - Epoch  10, Step:    51800, Batch Loss:     2.176576, Batch Acc: 0.329903, Tokens per Sec:    35768, Lr: 0.000300
2025-05-29 19:58:50,455 - INFO - joeynmt.training - Epoch  10, Step:    51900, Batch Loss:     2.201956, Batch Acc: 0.330784, Tokens per Sec:    35276, Lr: 0.000300
2025-05-29 19:58:52,508 - INFO - joeynmt.training - Epoch  10, Step:    52000, Batch Loss:     2.270901, Batch Acc: 0.329569, Tokens per Sec:    34207, Lr: 0.000300
2025-05-29 19:58:52,509 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:58:52,509 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:59:05,027 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.19, ppl:   8.90, acc:   0.34, generation: 12.5087[sec], evaluation: 0.0000[sec]
2025-05-29 19:59:05,027 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:59:05,106 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/47000.ckpt
2025-05-29 19:59:05,111 - INFO - joeynmt.training - Example #0
2025-05-29 19:59:05,112 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:59:05,112 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:59:05,112 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'eine', 'M@@', 'en@@', 'ge', 'S@@', 'ach@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'en,', 'wie', 'ich', 'das', 'er@@', 'ste', 'M@@', 'al', 'in', 'den', 'U@@', 'S@@', 'A', 'und', 'der', 'K@@', '<unk>', 'r@@', 'per', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:59:05,112 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:59:05,112 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:59:05,112 - INFO - joeynmt.training - 	Hypothesis: Ich habe eine Menge Sache, die ich Ihnen zeigen, wie ich das erste Mal in den USA und der K<unk> rper zu ver<unk> ndern.
2025-05-29 19:59:05,112 - INFO - joeynmt.training - Example #1
2025-05-29 19:59:05,112 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:59:05,112 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:59:05,112 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'ein', 'kl@@', 'eines', 'T@@', 'ag@@', 'es', 'in', 'der', 'L@@', 'age', 'der', 'Welt', 'der', 'Welt', 'der', 'Welt', 'der', 'Welt', 'der', 'Welt', 'der', 'Welt', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:59:05,112 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:59:05,112 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:59:05,112 - INFO - joeynmt.training - 	Hypothesis: Es ist ein kleines Tages in der Lage der Welt der Welt der Welt der Welt der Welt der Welt zu erreichen.
2025-05-29 19:59:05,112 - INFO - joeynmt.training - Example #2
2025-05-29 19:59:05,113 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:59:05,113 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:59:05,113 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'mich', 'in', 'der', 'L@@', 'age', 'ges@@', 'ag@@', 't,', 'dass', 'ich', 'nicht', 'nur', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'in', 'einem', 'F@@', 'lu@@', 'g@@', 'zeu@@', 'g', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:59:05,113 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:59:05,113 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:59:05,113 - INFO - joeynmt.training - 	Hypothesis: Und ich habe mich in der Lage gesagt, dass ich nicht nur ein paar Minuten in einem Flugzeug zu erreichen.
2025-05-29 19:59:05,113 - INFO - joeynmt.training - Example #3
2025-05-29 19:59:05,113 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:59:05,113 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:59:05,113 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'ein', 'kl@@', 'eines', 'T@@', 'ag@@', 'es', 'in', 'der', 'L@@', 'age', 'in', 'der', 'L@@', 'age', 'in', 'der', 'L@@', 'age', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:59:05,113 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:59:05,113 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:59:05,113 - INFO - joeynmt.training - 	Hypothesis: Es ist ein kleines Tages in der Lage in der Lage in der Lage zu erreichen.
2025-05-29 19:59:05,113 - INFO - joeynmt.training - Example #4
2025-05-29 19:59:05,113 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:59:05,113 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:59:05,113 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'eine', 'M@@', 'en@@', 'ge', 'S@@', 'ache', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:59:05,113 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:59:05,113 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:59:05,114 - INFO - joeynmt.training - 	Hypothesis: Und ich habe eine Menge Sache zu erreichen.
2025-05-29 19:59:07,267 - INFO - joeynmt.training - Epoch  10, Step:    52100, Batch Loss:     2.132722, Batch Acc: 0.328796, Tokens per Sec:    31378, Lr: 0.000300
2025-05-29 19:59:10,402 - INFO - joeynmt.training - Epoch  10, Step:    52200, Batch Loss:     2.164464, Batch Acc: 0.328741, Tokens per Sec:    22630, Lr: 0.000300
2025-05-29 19:59:12,441 - INFO - joeynmt.training - Epoch  10, Step:    52300, Batch Loss:     2.253415, Batch Acc: 0.326019, Tokens per Sec:    34123, Lr: 0.000300
2025-05-29 19:59:14,464 - INFO - joeynmt.training - Epoch  10, Step:    52400, Batch Loss:     2.131059, Batch Acc: 0.324120, Tokens per Sec:    35543, Lr: 0.000300
2025-05-29 19:59:16,340 - INFO - joeynmt.training - Epoch  10, Step:    52500, Batch Loss:     2.173562, Batch Acc: 0.328166, Tokens per Sec:    38014, Lr: 0.000300
2025-05-29 19:59:16,340 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:59:16,340 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:59:29,560 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.18, ppl:   8.86, acc:   0.34, generation: 13.2095[sec], evaluation: 0.0000[sec]
2025-05-29 19:59:29,560 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:59:29,637 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/48000.ckpt
2025-05-29 19:59:29,643 - INFO - joeynmt.training - Example #0
2025-05-29 19:59:29,643 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:59:29,643 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:59:29,643 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'er@@', 'ste', 'ist', 'die', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'die', 'ich', 'Ihnen', 'zeig@@', 'en', 'm@@', '<unk>', 'ss@@', 'en,', 'dass', 'die', 'K@@', '<unk>', 'r@@', 'per@@', 't@@', 'o@@', 'te', 'K@@', 'ont@@', 'in@@', 'ent', 'der', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'in', 'der', 'L@@', 'age', 'f@@', '<unk>', 'r', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'L@@', 'and@@', 'wir@@', 't@@', 'schaft', 'in', 'der', 'L@@', 'age', 'f@@', '<unk>', 'r', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'K@@', 'ont@@', 'in@@', 'ent@@', 'i@@', 'al@@', 'it@@', '<unk>', 't', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'Ver@@', 'ein@@', 'ig@@', 'ten', 'St@@', 'a@@', 'aten', 'in', 'die', 'L@@', 'age', 'der', 'ver@@', 'k@@', 'auf@@', 'en', 'und', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'der', 'Ver@@', 'ein@@', 'ig@@', 'ten']
2025-05-29 19:59:29,643 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:59:29,644 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:59:29,644 - INFO - joeynmt.training - 	Hypothesis: Die erste ist die K<unk> rper, die ich Ihnen zeigen m<unk> ssen, dass die K<unk> rpertote Kontinent der M<unk> glichkeiten in der Lage f<unk> r die M<unk> glichkeit der Landwirtschaft in der Lage f<unk> r die M<unk> glichkeit der Kontinentialit<unk> t und die M<unk> glichkeit der Vereinigten Staaten in die Lage der verkaufen und die M<unk> glichkeit der Vereinigten
2025-05-29 19:59:29,644 - INFO - joeynmt.training - Example #1
2025-05-29 19:59:29,644 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:59:29,644 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:59:29,644 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'm@@', '<unk>', 'chte', 'Ihnen', 'ein', 'paar', 'Bei@@', 'spiel@@', 'e', 'von', 'der', 'M@@', '<unk>', 'glich@@', 'kei@@', 'ten', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:59:29,644 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:59:29,644 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:59:29,644 - INFO - joeynmt.training - 	Hypothesis: Und ich m<unk> chte Ihnen ein paar Beispiele von der M<unk> glichkeiten zu erreichen.
2025-05-29 19:59:29,644 - INFO - joeynmt.training - Example #2
2025-05-29 19:59:29,644 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:59:29,644 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:59:29,644 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'm@@', '<unk>', 'chte', 'Ihnen', 'ein', 'paar', 'Bei@@', 'spiel@@', 'e', 'von', 'einem', 'K@@', 'li@@', 'ma@@', 'w@@', 'an@@', 'del', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:59:29,644 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:59:29,644 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:59:29,644 - INFO - joeynmt.training - 	Hypothesis: Und ich m<unk> chte Ihnen ein paar Beispiele von einem Klimawandel zu erreichen.
2025-05-29 19:59:29,644 - INFO - joeynmt.training - Example #3
2025-05-29 19:59:29,644 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:59:29,644 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:59:29,645 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'ein', 'sch@@', 're@@', 'ck@@', 'lich@@', 'es', 'Pro@@', 'bl@@', 'em', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:59:29,645 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:59:29,645 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:59:29,645 - INFO - joeynmt.training - 	Hypothesis: Es ist ein schreckliches Problem zu ver<unk> ndern.
2025-05-29 19:59:29,645 - INFO - joeynmt.training - Example #4
2025-05-29 19:59:29,645 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:59:29,645 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:59:29,645 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'er@@', 'ste', 'ist', 'also', 'ein', 'paar', 'M@@', 'in@@', 'ut@@', 'en', 'der', 'K@@', '<unk>', 'r@@', 'per@@', 't@@', 'eil', 'der', 'K@@', '<unk>', 'r@@', 'per@@', 't@@', 'eil', 'der', 'K@@', '<unk>', 'r@@', 'per@@', 't@@', 'eil', 'der', 'K@@', '<unk>', 'r@@', 'per@@', ',', 'die', 'ich', 'in', 'der', 'L@@', 'age', 'f@@', '<unk>', 'r', 'die', 'K@@', '<unk>', 'r@@', 'per@@', 't@@', 'eil', 'der', 'K@@', '<unk>', 'r@@', 'per@@', 't@@', 'eil', 'der', 'K@@', '<unk>', 'r@@', 'per@@', 't@@', 'eil', 'der', 'K@@', '<unk>', 'r@@', 'per@@', 't@@', 'eil', 'der', 'Welt', 'zu', 'ver@@', '<unk>', 'n@@', 'der@@', 'n.', '</s>']
2025-05-29 19:59:29,645 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:59:29,645 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:59:29,645 - INFO - joeynmt.training - 	Hypothesis: Die erste ist also ein paar Minuten der K<unk> rperteil der K<unk> rperteil der K<unk> rperteil der K<unk> rper, die ich in der Lage f<unk> r die K<unk> rperteil der K<unk> rperteil der K<unk> rperteil der K<unk> rperteil der Welt zu ver<unk> ndern.
2025-05-29 19:59:31,650 - INFO - joeynmt.training - Epoch  10, Step:    52600, Batch Loss:     2.077631, Batch Acc: 0.324104, Tokens per Sec:    32937, Lr: 0.000300
2025-05-29 19:59:33,714 - INFO - joeynmt.training - Epoch  10, Step:    52700, Batch Loss:     2.113089, Batch Acc: 0.329167, Tokens per Sec:    33141, Lr: 0.000300
2025-05-29 19:59:35,707 - INFO - joeynmt.training - Epoch  10, Step:    52800, Batch Loss:     2.187921, Batch Acc: 0.327579, Tokens per Sec:    35870, Lr: 0.000300
2025-05-29 19:59:37,510 - INFO - joeynmt.training - Epoch  10, Step:    52900, Batch Loss:     2.109601, Batch Acc: 0.327713, Tokens per Sec:    38441, Lr: 0.000300
2025-05-29 19:59:39,461 - INFO - joeynmt.training - Epoch  10, Step:    53000, Batch Loss:     2.200985, Batch Acc: 0.326318, Tokens per Sec:    36026, Lr: 0.000300
2025-05-29 19:59:39,461 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:59:39,461 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:59:51,473 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.18, ppl:   8.86, acc:   0.34, generation: 12.0045[sec], evaluation: 0.0000[sec]
2025-05-29 19:59:51,556 - INFO - joeynmt.helpers - delete models/transformer_bpe_2000/50500.ckpt
2025-05-29 19:59:51,561 - INFO - joeynmt.training - Example #0
2025-05-29 19:59:51,562 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'mili@@', 'oni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:59:51,562 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'f@@', 'ü@@', 'r', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:59:51,562 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'mir', 'eine', 'M@@', 'en@@', 'ge', 'an', 'und', 'ich', 'habe', 'die', 'M@@', '<unk>', 'glich@@', 'keit', 'von', 'der', 'M@@', '<unk>', 'glich@@', 'keit', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:59:51,562 - INFO - joeynmt.training - 	Source:     L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:59:51,562 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:59:51,562 - INFO - joeynmt.training - 	Hypothesis: Und ich habe mir eine Menge an und ich habe die M<unk> glichkeit von der M<unk> glichkeit zu erreichen.
2025-05-29 19:59:51,562 - INFO - joeynmt.training - Example #1
2025-05-29 19:59:51,562 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'it@@', 'à', 'del', 'problema', 'per@@', 'ch@@', 'é', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:59:51,562 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ü@@', 'ck@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:59:51,562 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'm@@', '<unk>', 'chte', 'Ihnen', 'ein', 'paar', 'Bei@@', 'spiel@@', 'e', 'von', 'der', 'M@@', '<unk>', 'glich@@', 'keit', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:59:51,562 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:59:51,562 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:59:51,562 - INFO - joeynmt.training - 	Hypothesis: Und ich m<unk> chte Ihnen ein paar Beispiele von der M<unk> glichkeit zu erreichen.
2025-05-29 19:59:51,562 - INFO - joeynmt.training - Example #2
2025-05-29 19:59:51,562 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:59:51,562 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'ge@@', 'wiss@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'k@@', 't@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'y@@', 'stem@@', 's.']
2025-05-29 19:59:51,562 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'einen', 'M@@', 'om@@', 'ent', 'in', 'einem', 'F@@', 'all', 'ist', 'ein', 'M@@', 'ann', 'in', 'einem', 'K@@', 'li@@', 'ma@@', 'w@@', 'andel@@', 't.', '</s>']
2025-05-29 19:59:51,563 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:59:51,563 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:59:51,563 - INFO - joeynmt.training - 	Hypothesis: Und ich habe einen Moment in einem Fall ist ein Mann in einem Klimawandelt.
2025-05-29 19:59:51,563 - INFO - joeynmt.training - Example #3
2025-05-29 19:59:51,563 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:59:51,563 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:59:51,563 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'ein', 'g@@', 'ro@@', '<unk>', 'ar@@', 'tig@@', 'es', 'Pro@@', 'bl@@', 'em', 'zu', 'mach@@', 'en.', '</s>']
2025-05-29 19:59:51,563 - INFO - joeynmt.training - 	Source:     Si espande d'inverno e si ritira d'estate.
2025-05-29 19:59:51,563 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:59:51,563 - INFO - joeynmt.training - 	Hypothesis: Es ist ein gro<unk> artiges Problem zu machen.
2025-05-29 19:59:51,563 - INFO - joeynmt.training - Example #4
2025-05-29 19:59:51,563 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:59:51,563 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'n@@', 'ä@@', 'ch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'ei@@', 'tr@@', 'aff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:59:51,563 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'es', 'in', 'der', 'L@@', 'age', 'ges@@', 'ag@@', 't,', 'dass', 'ich', 'eine', 'M@@', 'en@@', 'ge', 'S@@', 'ache', 'zu', 'er@@', 'rei@@', 'ch@@', 'en.', '</s>']
2025-05-29 19:59:51,563 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:59:51,563 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:59:51,563 - INFO - joeynmt.training - 	Hypothesis: Und ich habe es in der Lage gesagt, dass ich eine Menge Sache zu erreichen.
2025-05-29 19:59:53,959 - INFO - joeynmt.training - Epoch  10, Step:    53100, Batch Loss:     2.261810, Batch Acc: 0.329646, Tokens per Sec:    27971, Lr: 0.000300
2025-05-29 19:59:56,039 - INFO - joeynmt.training - Epoch  10, Step:    53200, Batch Loss:     2.242805, Batch Acc: 0.330724, Tokens per Sec:    34033, Lr: 0.000300
2025-05-29 19:59:58,068 - INFO - joeynmt.training - Epoch  10, Step:    53300, Batch Loss:     2.288235, Batch Acc: 0.323305, Tokens per Sec:    35749, Lr: 0.000300
2025-05-29 20:00:00,189 - INFO - joeynmt.training - Epoch  10, Step:    53400, Batch Loss:     2.210699, Batch Acc: 0.327824, Tokens per Sec:    33752, Lr: 0.000300
2025-05-29 20:00:01,684 - INFO - joeynmt.training - Epoch  10: total training loss 11657.68
2025-05-29 20:00:01,684 - INFO - joeynmt.training - Training ended after  10 epochs.
2025-05-29 20:00:01,684 - INFO - joeynmt.training - Best validation result (greedy) at step    52500:   8.86 ppl.
2025-05-29 20:00:01,695 - INFO - joeynmt.model - Building an encoder-decoder model...
2025-05-29 20:00:01,724 - INFO - joeynmt.model - Enc-dec model built.
2025-05-29 20:00:01,789 - INFO - joeynmt.helpers - Load model from /home/miwiy/mt-exercise-4/models/transformer_bpe_2000/52500.ckpt.
2025-05-29 20:00:01,802 - INFO - joeynmt.prediction - Model(
	encoder=TransformerEncoder(num_layers=4, num_heads=2, alpha=1.0, layer_norm="pre", activation=ReLU()),
	decoder=TransformerDecoder(num_layers=1, num_heads=2, alpha=1.0, layer_norm="post", activation=ReLU()),
	src_embed=Embeddings(embedding_dim=256, vocab_size=1797),
	trg_embed=Embeddings(embedding_dim=256, vocab_size=1797),
	loss_function=None)
2025-05-29 20:00:01,804 - INFO - joeynmt.prediction - Decoding on dev set...
2025-05-29 20:00:01,804 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 20:00:01,804 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Beam search with beam_size=5, beam_alpha=1.0, n_best=1, min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 20:01:17,280 - INFO - joeynmt.prediction - Evaluation result (beam search) , generation: 75.4712[sec], evaluation: 0.0000[sec]
2025-05-29 20:01:17,280 - INFO - joeynmt.prediction - Translations saved to: /home/miwiy/mt-exercise-4/models/transformer_bpe_2000/00052500.hyps.dev.
2025-05-29 20:01:17,280 - INFO - joeynmt.prediction - Decoding on test set...
2025-05-29 20:01:17,280 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 20:01:17,280 - INFO - joeynmt.prediction - Predicting 1567 example(s)... (Beam search with beam_size=5, beam_alpha=1.0, n_best=1, min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 20:03:27,881 - INFO - joeynmt.prediction - Evaluation result (beam search) , generation: 130.5943[sec], evaluation: 0.0000[sec]
2025-05-29 20:03:27,882 - INFO - joeynmt.prediction - Translations saved to: /home/miwiy/mt-exercise-4/models/transformer_bpe_2000/00052500.hyps.test.
